#!/usr/bin/env python3
"""
DeepFloorplan æˆ¿é—´æ£€æµ‹ - é‡æ„ç‰ˆæœ¬ (å¸¦åæ ‡è½´)
============================================

æœ¬æ–‡ä»¶æ˜¯ demo.py çš„å®Œå…¨é‡æ„ç‰ˆæœ¬ï¼Œä¸»è¦æ”¹è¿›ï¼š
1. é¢å‘å¯¹è±¡è®¾è®¡æ›¿ä»£è¿‡ç¨‹å¼ç¼–ç¨‹
2. æ¶ˆé™¤90%é‡å¤ä»£ç 
3. ç»Ÿä¸€é…ç½®ç®¡ç†
4. æ¸…æ™°çš„èŒè´£åˆ†ç¦»
5. ç°ä»£åŒ–ä»£ç é£æ ¼
6. åæ ‡è½´æ˜¾ç¤ºå’Œæˆ¿é—´åæ ‡ä¿¡æ¯

åŠŸèƒ½å®Œå…¨ç­‰åŒäºåŸç‰ˆæœ¬ï¼Œä½†ä»£ç æ›´ç®€æ´ã€ä¼˜é›…ã€æ˜“ç»´æŠ¤ã€‚
"""

import os
import sys
import subprocess
import platform
import argparse
import numpy as np
from pathlib import Path
import json
from datetime import datetime

# é…ç½®ç¯å¢ƒ
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"
import warnings

warnings.filterwarnings("ignore")

try:
    import tensorflow.compat.v1 as tf  # type: ignore
except Exception as _tf_err:
    class _DummyTF:
        def __getattr__(self, item):
            raise ImportError(f"TensorFlow æœªå®‰è£…ï¼Œæ— æ³•è®¿é—® {item}: {_tf_err}")
    tf = _DummyTF()  # fallback
import matplotlib.pyplot as plt
import matplotlib
from matplotlib import font_manager
from matplotlib.font_manager import FontProperties
from PIL import ImageFont, ImageDraw, Image
import cv2
from PIL import Image

CH_FONT_PATH = None

def _init_chinese_font():
    """åˆå§‹åŒ–ä¸­æ–‡å­—ä½“ï¼Œé˜²æ­¢å‡ºç° ? å·ã€‚è¿”å›å¯ç”¨ FontProperties æˆ– Noneã€‚"""
    candidate_fonts = [
        "Microsoft YaHei", "SimHei", "SimSun", "Source Han Sans CN",
        "Noto Sans CJK SC", "WenQuanYi Micro Hei", "Arial Unicode MS", "DejaVu Sans"
    ]
    for name in candidate_fonts:
        try:
            path = font_manager.findfont(name, fallback_to_default=False)
            if path and os.path.isfile(path):
                print(f"ğŸˆ¶ ä½¿ç”¨ä¸­æ–‡å­—ä½“: {name} -> {path}")
                matplotlib.rcParams["font.sans-serif"] = [name]
                matplotlib.rcParams["axes.unicode_minus"] = False
                global CH_FONT_PATH
                CH_FONT_PATH = path
                return FontProperties(fname=path)
        except Exception:
            continue
    print("âš ï¸ æœªæ‰¾åˆ°é€‚é…çš„ä¸­æ–‡å­—ä½“ï¼Œå¯èƒ½å‡ºç° ? å·ï¼Œè¯·å®‰è£…å¾®è½¯é›…é»‘/é»‘ä½“ã€‚")
    return None

CH_FONT = _init_chinese_font()


tf.disable_v2_behavior()
tf.logging.set_verbosity(tf.logging.ERROR)

# å¯¼å…¥åŸæœ‰å·¥å…·æ¨¡å—
from utils.ocr_enhanced import extract_room_text, fuse_ocr_and_segmentation, text_to_label
from utils.rgb_ind_convertor import floorplan_fuse_map_figure
from room_detection_manager import RefactoredRoomDetectionManager


# ============================================================
# å››å±‚æ™ºèƒ½å†³ç­–æ¶æ„
# ============================================================

class AISegmentationEngine:
    """ç¬¬ä¸€å±‚ï¼šAIè¯­ä¹‰åˆ†å‰²å™¨"""
    
    def __init__(self, model_path="pretrained"):
        self.model_path = model_path
        self.session = None
        self.inputs = None
        self.room_type_logit = None
        self.room_boundary_logit = None
    
    def load_model(self):
        """åŠ è½½ç¥ç»ç½‘ç»œæ¨¡å‹"""
        print("ğŸ”§ [ç¬¬1å±‚-AIåˆ†å‰²å™¨] åŠ è½½DeepFloorplanæ¨¡å‹...")
        config = tf.ConfigProto()
        config.gpu_options.allow_growth = True
        config.allow_soft_placement = True

        self.session = tf.Session(config=config)
        saver = tf.train.import_meta_graph(f"{self.model_path}/pretrained_r3d.meta")
        saver.restore(self.session, f"{self.model_path}/pretrained_r3d")

        graph = tf.get_default_graph()
        self.inputs = graph.get_tensor_by_name("inputs:0")
        self.room_type_logit = graph.get_tensor_by_name("Cast:0")
        self.room_boundary_logit = graph.get_tensor_by_name("Cast_1:0")
        print("âœ… [ç¬¬1å±‚-AIåˆ†å‰²å™¨] æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def segment_image(self, img_array):
        """æ‰§è¡Œè¯­ä¹‰åˆ†å‰²"""
        print("ğŸ¤– [ç¬¬1å±‚-AIåˆ†å‰²å™¨] è¿è¡Œç¥ç»ç½‘ç»œæ¨ç†...")
        input_batch = np.expand_dims(img_array, axis=0)

        # åŸç½‘ç»œå›¾ä¸­ Cast/Cast_1 èŠ‚ç‚¹å·²ç»è¾“å‡ºç±»åˆ«ç´¢å¼•ï¼Œæ­¤å¤„æ— éœ€å†æ¬¡ argmax
        room_type, room_boundary = self.session.run(
            [self.room_type_logit, self.room_boundary_logit],
            feed_dict={self.inputs: input_batch},
        )

        room_type = np.squeeze(room_type)
        room_boundary = np.squeeze(room_boundary)

        # å°†è¾¹ç•Œç±»åˆ«æ˜ å°„åˆ° 9/10ï¼Œä¾›åç»­èåˆæµç¨‹è¯†åˆ«å¢™ä½“
        floorplan = room_type.copy()
        floorplan[room_boundary == 1] = 9
        floorplan[room_boundary == 2] = 10

        print("âœ… [ç¬¬1å±‚-AIåˆ†å‰²å™¨] ç¥ç»ç½‘ç»œæ¨ç†å®Œæˆ")
        return floorplan


class OCRRecognitionEngine:
    """ç¬¬äºŒå±‚ï¼šOCRæ–‡å­—è¯†åˆ«å™¨"""
    
    def __init__(self):
        pass
    
    def recognize_text(self, original_img):
        """è¯†åˆ«å›¾åƒä¸­çš„æ–‡å­—"""
        print("ğŸ” [ç¬¬2å±‚-OCRè¯†åˆ«å™¨] æå–OCRæ–‡å­—ä¿¡æ¯...")
        
        # OCRå¤„ç†ï¼ˆæ”¾å¤§2å€æé«˜è¯†åˆ«ç‡ï¼‰
        ocr_img = cv2.resize(original_img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
        print(f"ğŸ” [ç¬¬2å±‚-OCRè¯†åˆ«å™¨] å¤„ç†å›¾åƒ: {ocr_img.shape[1]} x {ocr_img.shape[0]} (æ”¾å¤§2å€)")
        
        room_text_items = extract_room_text(ocr_img)
        print(f"ğŸ“Š [ç¬¬2å±‚-OCRè¯†åˆ«å™¨] æ£€æµ‹åˆ° {len(room_text_items)} ä¸ªæ–‡å­—åŒºåŸŸ")

        # ä¿å­˜OCRæ”¾å¤§å›¾å°ºå¯¸ï¼Œä¾¿äºåç»­å¯è§†åŒ–/åæ ‡è¿˜åŸ
        for it in room_text_items:
            it['ocr_width'] = ocr_img.shape[1]
            it['ocr_height'] = ocr_img.shape[0]
        
        return room_text_items, ocr_img.shape


class FusionDecisionEngine:
    """ç¬¬ä¸‰å±‚ï¼šèåˆå†³ç­–å™¨"""
    
    def __init__(self):
        self.room_manager = RefactoredRoomDetectionManager()
        # è®°å½•OCRé©±åŠ¨åŒºåŸŸæ‰©æ•£çš„ç§å­ç‚¹ (label -> [(x,y), ...])
        self._seed_centers_by_label = {}
    
    def fuse_results(self, ai_prediction, ocr_results, ocr_shape):
        """æ™ºèƒ½èåˆAIåˆ†å‰²å’ŒOCRè¯†åˆ«ç»“æœ"""
        print("ğŸ”— [ç¬¬3å±‚-èåˆå†³ç­–å™¨] èåˆAIå’ŒOCRç»“æœ...")

        # 1. è®¡ç®— OCR -> 512 ç¼©æ”¾æ¯”ä¾‹ï¼ˆå½“å‰ OCR æ˜¯æ”¾å¤§2å€åçš„å°ºå¯¸ï¼‰
        ocr_to_512_x = 512.0 / ocr_shape[1]
        ocr_to_512_y = 512.0 / ocr_shape[0]
        print(f"   ğŸ”„ [ç¬¬3å±‚-èåˆå†³ç­–å™¨] OCRåæ ‡è½¬æ¢åˆ°512x512:")
        print(f"      OCRå›¾åƒ({ocr_shape[1]}x{ocr_shape[0]}) -> 512x512")
        print(f"      è½¬æ¢æ¯”ä¾‹: X={ocr_to_512_x:.3f}, Y={ocr_to_512_y:.3f}")

        # 2. å¤åˆ¶åŸå§‹OCRç»“æœï¼ˆä¿æŒæ”¾å¤§å›¾åæ ‡ï¼Œåç»­éœ€è¦ç”¨æ¯”ä¾‹æ˜ å°„ï¼‰
        original_ocr_results = [item.copy() for item in ocr_results]
        for item in original_ocr_results:
            item['ocr_width'] = ocr_shape[1]
            item['ocr_height'] = ocr_shape[0]

        # 3. ç”Ÿæˆ 512 åæ ‡ç³»ç‰ˆæœ¬ä¾›ç›´æ¥èåˆä¸æˆ¿é—´æ£€æµ‹
        converted_items = self._convert_ocr_coordinates(original_ocr_results, ocr_to_512_x, ocr_to_512_y)

        # 4. è¯†åˆ«å¼€æ”¾å¼å¨æˆ¿ï¼ˆå¨æˆ¿æ–‡å­—è½åœ¨å®¢å…åŒºåŸŸï¼‰
        processed_items = []
        open_kitchens = []
        for item in converted_items:
            label = text_to_label(item['text'])
            if label == 7:  # å¨æˆ¿
                x, y, w, h = item['bbox']
                cx, cy = x + w // 2, y + h // 2
                if ai_prediction[cy, cx] == 3:  # å®¢å…æ ‡ç­¾
                    open_kitchens.append(item)
                    print(f"   ğŸ³ è¯†åˆ«åˆ°å¼€æ”¾å¼å¨æˆ¿å€™é€‰: {item['text']}")
                else:
                    processed_items.append(item)
            else:
                processed_items.append(item)

        # 5. èåˆ OCR æ ‡ç­¾ï¼ˆä¸å«å¼€æ”¾å¼å¨æˆ¿ï¼‰
        enhanced = fuse_ocr_and_segmentation(ai_prediction.copy(), processed_items)

        # 6. å¼€æ”¾å¼å¨æˆ¿åŒºåŸŸä¼°ç®—
        enhanced = self._estimate_open_kitchen(enhanced, open_kitchens)

        # 7. OCR ä¸»å¯¼åŒºåŸŸæ‰©æ•£ï¼ˆä½¿ç”¨åŸå§‹åæ ‡ + æ¯”ä¾‹ï¼‰
        enhanced = self._ocr_driven_region_growing(enhanced, original_ocr_results, ocr_to_512_x, ocr_to_512_y)

        # 8. æˆ¿é—´æ£€æµ‹ï¼ˆä½¿ç”¨å·²ç¼©æ”¾çš„ converted_itemsï¼Œé¿å…å† clamp 511ï¼‰
        enhanced = self.room_manager.detect_all_rooms(enhanced, converted_items)

        # 9. åŸºç¡€æ¸…ç†ï¼ˆè·ç¦»è®¡ç®—ä»éœ€åŸå§‹åæ ‡ + æ¯”ä¾‹ï¼‰
        enhanced = self._basic_cleanup(enhanced, original_ocr_results, ocr_to_512_x, ocr_to_512_y)

        print("âœ… [ç¬¬3å±‚-èåˆå†³ç­–å™¨] èåˆå®Œæˆ")
        return enhanced
    
    def _convert_ocr_coordinates(self, room_text_items, scale_x, scale_y):
        """è½¬æ¢OCRåæ ‡åˆ°512x512åæ ‡ç³»"""
        converted_items = []
        for item in room_text_items:
            converted_item = item.copy()
            x, y, w, h = item["bbox"]
            new_x = max(0, min(int(x * scale_x), 511))
            new_y = max(0, min(int(y * scale_y), 511))
            new_w = max(1, min(int(w * scale_x), 512 - new_x))
            new_h = max(1, min(int(h * scale_y), 512 - new_y))
            converted_item["bbox"] = [new_x, new_y, new_w, new_h]
            converted_items.append(converted_item)
        return converted_items

    def _estimate_open_kitchen(self, enhanced, kitchen_items, size=60):
        """å¼€æ”¾å¼å¨æˆ¿åŒºåŸŸä¼°ç®—ï¼šå½“å¨æˆ¿æ–‡å­—è½åœ¨å®¢å…åŒºåŸŸä¸­æ—¶ä¼°è®¡å…¶èŒƒå›´"""
        if not kitchen_items:
            return enhanced
        print("ğŸ³ [ç¬¬3å±‚-èåˆå†³ç­–å™¨] ä¼°ç®—å¼€æ”¾å¼å¨æˆ¿åŒºåŸŸ...")
        for item in kitchen_items:
            x, y, w, h = item['bbox']
            cx, cy = x + w // 2, y + h // 2
            half = size // 2
            x1 = max(0, cx - half)
            y1 = max(0, cy - half)
            x2 = min(enhanced.shape[1] - 1, cx + half)
            y2 = min(enhanced.shape[0] - 1, cy + half)
            print(f"   â• å¼€æ”¾å¼å¨æˆ¿åŒºåŸŸ: ({x1}, {y1}) -> ({x2}, {y2})")
            patch = enhanced[y1:y2, x1:x2]
            mask = ~np.isin(patch, [9, 10])  # é¿å¼€å¢™ä½“
            patch[mask] = 7
        return enhanced
    
    def _ocr_driven_region_growing(self, enhanced, original_ocr_results, scale_x, scale_y):
        """OCRä¸»å¯¼çš„åŒºåŸŸç”Ÿé•¿ç®—æ³• - ä»OCRä½ç½®å‘å¤–æ‰©æ•£è‡³è¾¹ç•Œå¹¶ä¸Šè‰²"""
        print("ğŸŒ± [ç¬¬3å±‚-èåˆå†³ç­–å™¨] OCRä¸»å¯¼åŒºåŸŸæ‰©æ•£...")
        
        # å¤„ç†æ¯ä¸ªOCRæ£€æµ‹åˆ°çš„æˆ¿é—´æ–‡å­—
        for item in original_ocr_results:
            text = item["text"].lower().strip()
            confidence = item.get("confidence", 1.0)
            
            # ç¡®å®šæˆ¿é—´ç±»å‹
            room_label = None
            room_name = ""
            
            if any(keyword in text for keyword in ["å¨æˆ¿", "kitchen", "å¨"]):
                room_label = 7  # å¨æˆ¿
                room_name = "å¨æˆ¿"
            elif any(keyword in text for keyword in ["å«ç”Ÿé—´", "bathroom", "å«", "æ´—æ‰‹é—´", "æµ´å®¤"]):
                room_label = 2  # å«ç”Ÿé—´  
                room_name = "å«ç”Ÿé—´"
            elif any(keyword in text for keyword in ["å®¢å…", "living", "å…", "èµ·å±…å®¤"]):
                room_label = 3  # å®¢å…
                room_name = "å®¢å…"
            elif any(keyword in text for keyword in ["å§å®¤", "bedroom", "ä¸»å§", "æ¬¡å§"]):
                room_label = 4  # å§å®¤
                room_name = "å§å®¤"
                print(f"ğŸ” [è°ƒè¯•] OCRæ£€æµ‹åˆ°å§å®¤å…³é”®è¯: '{text}' -> å§å®¤(4)")
            elif any(keyword in text for keyword in ["ä¹¦æˆ¿", "study", "åŠå…¬å®¤", "office"]):
                room_label = 8  # ä¹¦æˆ¿
                room_name = "ä¹¦æˆ¿"
                print(f"ğŸ” [è°ƒè¯•] OCRæ£€æµ‹åˆ°ä¹¦æˆ¿å…³é”®è¯: '{text}' -> ä¹¦æˆ¿(8)")
            elif any(keyword in text for keyword in ["é˜³å°", "balcony", "é˜³å…®", "é˜³åˆ", "é˜³å›Š"]):
                room_label = 6  # é˜³å°
                room_name = "é˜³å°"
                if text == "é˜³å…®":
                    print(f"ğŸ”§ [OCRä¿®æ­£] è¯¯è¯†åˆ«'{text}' -> 'é˜³å°'")
            
            if room_label is None:
                continue
                
            print(f"   ğŸ¯ å¤„ç†æˆ¿é—´: '{text}' -> {room_name}({room_label}) (ç½®ä¿¡åº¦: {confidence:.3f})")
            
            # è½¬æ¢OCRåæ ‡åˆ°512x512åæ ‡ç³»
            x, y, w, h = item["bbox"]
            center_x_512 = int((x + w//2) * scale_x)
            center_y_512 = int((y + h//2) * scale_y)

            # è®¡ç®—å¹¶è£å‰ªOCRæ¡†åœ¨512åæ ‡ç³»ä¸‹çš„èŒƒå›´
            x1_512 = max(0, min(int(x * scale_x), 511))
            y1_512 = max(0, min(int(y * scale_y), 511))
            x2_512 = max(0, min(int((x + w) * scale_x), 512))
            y2_512 = max(0, min(int((y + h) * scale_y), 512))

            # ç¡®ä¿ä¸­å¿ƒåæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
            center_x_512 = max(0, min(center_x_512, 511))
            center_y_512 = max(0, min(center_y_512, 511))

            # ä»OCRä½ç½®å¼€å§‹åŒºåŸŸç”Ÿé•¿
            room_mask = self._region_growing_from_seed(
                enhanced, center_x_512, center_y_512, room_label, (x1_512, y1_512, x2_512, y2_512)
            )

            # è®°å½•ç§å­ç‚¹ï¼Œä¾›åç»­æ¸…ç†é˜¶æ®µåˆ¤å®šä¸»åŒºåŸŸ
            self._seed_centers_by_label.setdefault(room_label, []).append((center_x_512, center_y_512))
            
            if room_mask is not None:
                room_pixels = np.sum(room_mask)
                print(f"   âœ… {room_name}åŒºåŸŸæ‰©æ•£å®Œæˆ: {room_pixels} åƒç´ ï¼Œä¸­å¿ƒ({center_x_512}, {center_y_512})")
                
                # åº”ç”¨åŒºåŸŸç”Ÿé•¿ç»“æœ
                enhanced[room_mask] = room_label
            else:
                print(f"   âš ï¸ {room_name}åŒºåŸŸæ‰©æ•£å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
                # å¤‡ç”¨æ–¹æ³•ï¼šåˆ›å»ºå°çš„å›ºå®šåŒºåŸŸ
                self._create_fallback_room_region(enhanced, center_x_512, center_y_512, room_label, room_name)
        
        return enhanced
    
    def _region_growing_from_seed(self, floorplan, seed_x, seed_y, target_label, bbox=None):
        """ä»ç§å­ç‚¹å¼€å§‹åŒºåŸŸç”Ÿé•¿ï¼Œç›´åˆ°é‡åˆ°è¾¹ç•Œï¼ˆå¢™ä½“æˆ–å…¶ä»–æˆ¿é—´ï¼‰"""
        h, w = floorplan.shape
        
        # æ£€æŸ¥ç§å­ç‚¹æ˜¯å¦æœ‰æ•ˆ
        if (seed_x < 0 or seed_x >= w or seed_y < 0 or seed_y >= h):
            return None
            
        # å¦‚æœç§å­ç‚¹åœ¨å¢™ä¸Šï¼Œå°è¯•å¯»æ‰¾é™„è¿‘çš„éå¢™åŒºåŸŸ
        if floorplan[seed_y, seed_x] in [9, 10]:  # å¢™ä½“
            seed_x, seed_y = self._find_nearby_non_wall(floorplan, seed_x, seed_y, bbox)
            if seed_x is None:
                print("      âŒ æ— æ³•åœ¨é™„è¿‘æ‰¾åˆ°éå¢™åƒç´ ï¼ŒåŒºåŸŸæ‰©æ•£ç»ˆæ­¢")
                return None
        
        print(f"      ğŸŒ± å¼€å§‹ä»ç§å­ç‚¹({seed_x}, {seed_y})æ‰©æ•£ï¼Œåˆå§‹å€¼: {floorplan[seed_y, seed_x]}")
        
        # åŒºåŸŸç”Ÿé•¿ç®—æ³•ï¼ˆBFSï¼‰
        from collections import deque
        
        visited = np.zeros((h, w), dtype=bool)
        room_mask = np.zeros((h, w), dtype=bool)
        queue = deque([(seed_x, seed_y)])
        
        # ğŸ¯ ä¸¥æ ¼è¾¹ç•Œç­–ç•¥ï¼šé¿å¼€å¢™ä½“å’Œå·²æœ‰æˆ¿é—´
        wall_barriers = {9, 10}  # å¢™ä½“
        room_barriers = {2, 3, 4, 6, 7, 8}  # å…¶ä»–æˆ¿é—´ç±»å‹
        
        expand_count = 0
        # æ ¹æ®å›¾åƒå¤§å°åŠ¨æ€ç¡®å®šæœ€å¤§æ‰©æ•£æ¬¡æ•°ï¼Œè¿›ä¸€æ­¥æ”¾å®½æˆ¿é—´æ‰©æ•£é™åˆ¶
        total_pixels = h * w
        # ğŸ¯ ä¼˜åŒ–æ‰©æ•£é™åˆ¶ï¼šæŒ‰æˆ¿é—´ç±»å‹è®¾ç½®ä¸åŒçš„æ‰©æ•£ç³»æ•°
        expansion_factor = {
            2: 0.7,   # å«ç”Ÿé—´éœ€è¦é€‚åº¦æ‰©æ•£
            3: 0.8,   # å®¢å…éœ€è¦å¤§èŒƒå›´æ‰©æ•£
            4: 0.75,  # å§å®¤éœ€è¦ä¸­ç­‰æ‰©æ•£
            6: 0.75,  # é˜³å°æå‡æ‰©æ•£ï¼ˆä¹‹å‰å¯èƒ½ä¸è¶³ï¼‰
            7: 0.7,   # å¨æˆ¿é€‚åº¦æ‰©æ•£
            8: 0.5,   # ä¹¦æˆ¿æ§åˆ¶æ‰©æ•£ï¼ˆé˜²æ­¢è¯¯è¯†åˆ«ï¼‰
        }.get(target_label, 0.6)
        expansion_limit = int(total_pixels * expansion_factor)
        encountered_wall = False

        # ğŸ”’ è¾¹ç•Œæ£€æµ‹ï¼šé€‚åº¦çš„å®‰å…¨è¾¹è·
        safe_margin = 2  # å‡å°‘åˆ°2åƒç´ çš„å®‰å…¨è¾¹è·

        while queue:
            x, y = queue.popleft()
            expand_count += 1
            
            # ğŸš« é€‚åº¦è¾¹ç•Œæ£€æŸ¥ï¼šåŒ…æ‹¬å›¾åƒè¾¹ç•Œå’Œå®‰å…¨è¾¹è·
            if (x < safe_margin or x >= w - safe_margin or 
                y < safe_margin or y >= h - safe_margin or 
                visited[y, x]):
                continue
                
            visited[y, x] = True
            current_pixel = floorplan[y, x]
            
            # ğŸš« ç»å¯¹è¾¹ç•Œï¼šå¢™ä½“ - ç»ä¸è¶Šè¿‡
            if current_pixel in wall_barriers:
                encountered_wall = True
                continue

            # ğŸ¤” æ™ºèƒ½è¾¹ç•Œåˆ¤æ–­ï¼šé¿å…è¦†ç›–å…¶ä»–å·²ç¡®å®šçš„æˆ¿é—´ï¼ˆå¸¦å°ç»„ä»¶å®½å®¹ï¼‰
            if current_pixel in room_barriers and current_pixel != target_label:
                distance_to_seed = max(abs(x - seed_x), abs(y - seed_y))
                max_override_distance = {
                    2: 15,  # å«ç”Ÿé—´å…è®¸15åƒç´ è¦†ç›–
                    3: 25,  # å®¢å…å…è®¸25åƒç´ è¦†ç›–
                    4: 20,  # å§å®¤å…è®¸20åƒç´ è¦†ç›–
                    6: 12,  # é˜³å°å…è®¸12åƒç´ è¦†ç›–
                    7: 18,  # å¨æˆ¿å…è®¸18åƒç´ è¦†ç›–
                    8: 20,  # ä¹¦æˆ¿å…è®¸20åƒç´ è¦†ç›–
                }.get(target_label, 15)
                small_area_thresh = 30
                near_seed_thresh = 5
                component_area = self._compute_component_area(floorplan, x, y, current_pixel)
                if (component_area >= small_area_thresh and
                        distance_to_seed > near_seed_thresh and
                        distance_to_seed > max_override_distance):
                    continue  # è¢«è¾ƒå¤§ç»„ä»¶é˜»æŒ¡ä¸”è·ç¦»è¾ƒè¿œï¼Œåœæ­¢è¦†ç›–
            
            # æ·»åŠ åˆ°æˆ¿é—´æ©ç 
            room_mask[y, x] = True
            
            # ğŸ¯ é’ˆå¯¹å®¢å…ä¼˜åŒ–ï¼šå¤šæ–¹å‘å‡åŒ€æ‰©æ•£
            if target_label == 3:  # å®¢å…
                # 8æ–¹å‘æ‰©æ•£ï¼ˆåŒ…æ‹¬å¯¹è§’çº¿ï¼‰ï¼Œç¡®ä¿å…¨æ–¹å‘è¦†ç›–
                for dx, dy in [(0, 1), (1, 0), (0, -1), (-1, 0), (1, 1), (-1, 1), (1, -1), (-1, -1)]:
                    queue.append((x + dx, y + dy))
            else:
                # å…¶ä»–æˆ¿é—´4æ–¹å‘æ‰©æ•£ï¼ˆé¿å…å¯¹è§’çº¿è¿‡åº¦æ‰©æ•£ï¼‰
                for dx, dy in [(0, 1), (1, 0), (0, -1), (-1, 0)]:
                    queue.append((x + dx, y + dy))
        
            if expand_count >= expansion_limit:
                if queue and not encountered_wall:
                    expansion_limit += int(total_pixels * 0.05)
                else:
                    print(f"      âš ï¸ è¾¾åˆ°æ‰©æ•£é™åˆ¶({expansion_limit})ï¼Œåœæ­¢æ‰©æ•£")
                    break
        
        # åŒºåŸŸç”Ÿé•¿å®Œæˆåï¼Œè¿›è¡Œé—­è¿ç®—å»é™¤å™ªç‚¹å¹¶æ‹Ÿåˆè§„æ•´å½¢çŠ¶
        room_mask = self._refine_room_mask(room_mask)

        # æ£€æŸ¥ç”Ÿæˆçš„åŒºåŸŸæ˜¯å¦åˆç†
        room_pixels = np.sum(room_mask)
        room_ratio = room_pixels / total_pixels

        # ğŸ¯ æ ¹æ®å¢™ä½“æ£€æµ‹åŠ¨æ€è°ƒæ•´æœ€å¤§é¢ç§¯æ¯”ä¾‹
        wall_area = np.sum(np.isin(floorplan, list(wall_barriers)))
        building_area = max(total_pixels - wall_area, 1)
        base_max_ratio = {
            2: 0.30,  # å«ç”Ÿé—´æœ€å¤š30%
            3: 0.70,  # å®¢å…æœ€å¤š70%
            4: 0.50,  # å§å®¤æœ€å¤š50%
            6: 0.28,  # é˜³å°æ”¾å®½åˆ°28%
            7: 0.35,  # å¨æˆ¿æœ€å¤š35%
            8: 0.25,  # ä¹¦æˆ¿æœ€å¤š25%
        }.get(target_label, 0.50)
        max_ratio = base_max_ratio * (building_area / total_pixels)
        
        min_pixels = {
            2: 150,   # å«ç”Ÿé—´æœ€å°‘150åƒç´ 
            3: 300,   # å®¢å…æœ€å°‘300åƒç´ 
            4: 200,   # å§å®¤æœ€å°‘200åƒç´ 
            6: 60,    # é˜³å°é™ä½æœ€å°åƒç´ é—¨æ§›
            7: 150,   # å¨æˆ¿æœ€å°‘150åƒç´ 
            8: 200,   # ä¹¦æˆ¿æœ€å°‘200åƒç´ 
        }.get(target_label, 150)
        
        if room_ratio > max_ratio:  # è¶…è¿‡æˆ¿é—´æœ€å¤§æ¯”ä¾‹
            print(f"      âš ï¸ æ‰©æ•£åŒºåŸŸè¿‡å¤§({room_ratio:.1%} > {max_ratio:.1%})ï¼Œè¿›è¡Œè£å‰ª")
            room_mask = self._clip_oversized_region(room_mask, floorplan, seed_x, seed_y, target_label)
            room_mask = self._refine_room_mask(room_mask)
            return room_mask
        elif room_pixels < min_pixels:  # å¤ªå°ä¹Ÿä¸åˆç†
            print(f"      âš ï¸ æ‰©æ•£åŒºåŸŸè¿‡å°({room_pixels}åƒç´  < {min_pixels}åƒç´ )")
            return None
        
        return room_mask
    
    def _find_nearby_non_wall(self, floorplan, center_x, center_y, bbox=None):
        """å¯»æ‰¾é™„è¿‘çš„éå¢™åŒºåŸŸ"""
        h, w = floorplan.shape

        # å¯¹å¢™ä½“è¿›è¡Œè†¨èƒ€ï¼Œå‡å°‘å¢™ä½“å°ç¼ºå£çš„å½±å“
        wall_mask = np.isin(floorplan, [9, 10]).astype(np.uint8)
        dilated_walls = cv2.dilate(wall_mask, np.ones((3, 3), np.uint8), iterations=1)

        # åœ¨æ›´å¤§èŒƒå›´å†…æœç´¢å¯ç”¨èµ·ç‚¹ï¼ŒåŠå¾„æ‰©å¤§åˆ°10-15
        for radius in range(10, 16):
            for dy in range(-radius, radius + 1):
                for dx in range(-radius, radius + 1):
                    nx, ny = center_x + dx, center_y + dy
                    if 0 <= nx < w and 0 <= ny < h and not dilated_walls[ny, nx]:
                        return nx, ny

        # è‹¥ä»æœªæ‰¾åˆ°ï¼Œä¸”æä¾›äº†OCRæ¡†ï¼Œåˆ™åœ¨æ¡†å†…ç»†è‡´æœç´¢
        if bbox is not None:
            x1, y1, x2, y2 = bbox
            x1 = max(0, min(x1, w))
            y1 = max(0, min(y1, h))
            x2 = max(0, min(x2, w))
            y2 = max(0, min(y2, h))
            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
            best_pt = None
            best_dist = None
            for ny in range(y1, y2):
                for nx in range(x1, x2):
                    if not dilated_walls[ny, nx]:
                        dist = (nx - cx) ** 2 + (ny - cy) ** 2
                        if best_dist is None or dist < best_dist:
                            best_dist = dist
                            best_pt = (nx, ny)
            if best_pt is not None:
                print(f"      ğŸ” åœ¨OCRæ¡†å†…æ‰¾åˆ°æ›¿ä»£èµ·ç‚¹: {best_pt}")
                return best_pt

        print("      âš ï¸ æœªæ‰¾åˆ°å¯ç”¨çš„éå¢™èµ·ç‚¹")
        return None, None

    def _compute_component_area(self, floorplan, start_x, start_y, label, max_check=100):
        """è®¡ç®—ä»æŒ‡å®šåƒç´ å¼€å§‹çš„è¿é€šåŒºåŸŸé¢ç§¯ï¼Œç”¨äºåˆ¤æ–­å°ç»„ä»¶"""
        from collections import deque
        h, w = floorplan.shape
        visited = set()
        q = deque([(start_x, start_y)])
        area = 0
        while q and area <= max_check:
            x, y = q.popleft()
            if (x, y) in visited:
                continue
            visited.add((x, y))
            if x < 0 or x >= w or y < 0 or y >= h:
                continue
            if floorplan[y, x] != label:
                continue
            area += 1
            q.extend([(x + 1, y), (x - 1, y), (x, y + 1), (x, y - 1)])
        return area

    def _refine_room_mask(self, room_mask):
        """å¯¹æˆ¿é—´æ©ç åšé—­è¿ç®—å¹¶æ‹Ÿåˆå¤šè¾¹å½¢ï¼Œä½¿å½¢çŠ¶æ›´è§„æ•´"""
        mask_uint8 = (room_mask.astype(np.uint8) * 255)
        kernel = np.ones((5, 5), np.uint8)
        closed = cv2.morphologyEx(mask_uint8, cv2.MORPH_CLOSE, kernel)

        contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        refined = np.zeros_like(closed)
        if contours:
            largest = max(contours, key=cv2.contourArea)
            eps = 0.01 * cv2.arcLength(largest, True)
            approx = cv2.approxPolyDP(largest, eps, True)
            cv2.fillPoly(refined, [approx], 255)
        else:
            refined = closed

        return refined.astype(bool)
    
    def _clip_oversized_region(self, room_mask, floorplan, seed_x, seed_y, target_label):
        """è£å‰ªè¿‡å¤§çš„åŒºåŸŸï¼Œåˆ©ç”¨å‡¸åŒ…/æœ€å°å¤–æ¥çŸ©å½¢å¹¶å‚è€ƒå¢™ä½“ä¿¡æ¯"""
        mask_uint8 = (room_mask.astype(np.uint8) * 255)
        contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours:
            return room_mask

        # ä½¿ç”¨æœ€å¤§è½®å»“è®¡ç®—æœ€å°å¤–æ¥çŸ©å½¢å’Œå‡¸åŒ…
        cnt = max(contours, key=cv2.contourArea)
        hull = cv2.convexHull(cnt)
        rect = cv2.minAreaRect(cnt)
        box = cv2.boxPoints(rect).astype(np.int32)

        hull_mask = np.zeros_like(mask_uint8)
        cv2.fillConvexPoly(hull_mask, hull, 255)
        box_mask = np.zeros_like(mask_uint8)
        cv2.fillPoly(box_mask, [box], 255)

        candidate = cv2.bitwise_and(hull_mask, box_mask)

        # å‚è€ƒå¢™ä½“ï¼šé¿å…ç©¿è¿‡å¢™ä½“
        if floorplan is not None:
            non_wall = (~np.isin(floorplan, [9, 10])).astype(np.uint8) * 255
            candidate = cv2.bitwise_and(candidate, non_wall)

        clipped = np.logical_and(room_mask, candidate.astype(bool))

        # è‹¥è£å‰ªåä¸åŒ…å«ç§å­ç‚¹ï¼Œåˆ™ä¿ç•™ç§å­é™„è¿‘çš„å°åŒºåŸŸ
        if not clipped[seed_y, seed_x]:
            circle = np.zeros_like(room_mask, dtype=np.uint8)
            cv2.circle(circle, (seed_x, seed_y), 20, 1, -1)
            clipped = np.logical_or(clipped, circle.astype(bool))

        return clipped
    
    def _create_fallback_room_region(self, enhanced, center_x, center_y, room_label, room_name):
        """åˆ›å»ºå¤‡ç”¨çš„å›ºå®šå¤§å°æˆ¿é—´åŒºåŸŸ"""
        h, w = enhanced.shape
        
        # æ ¹æ®æˆ¿é—´ç±»å‹ç¡®å®šå¤§å°
        room_size = {
            2: 35,   # å«ç”Ÿé—´è¾ƒå°
            3: 70,   # å®¢å…è¾ƒå¤§
            4: 55,   # å§å®¤ä¸­ç­‰
            7: 45,   # å¨æˆ¿ä¸­ç­‰
            8: 50,   # ä¹¦æˆ¿ä¸­ç­‰
        }.get(room_label, 40)
        
        half_size = room_size // 2
        
        x1 = max(0, center_x - half_size)
        x2 = min(w - 1, center_x + half_size)  
        y1 = max(0, center_y - half_size)
        y2 = min(h - 1, center_y + half_size)
        
        # åªåœ¨éå¢™åŒºåŸŸè®¾ç½®æˆ¿é—´æ ‡ç­¾
        for y in range(y1, y2 + 1):
            for x in range(x1, x2 + 1):
                if enhanced[y, x] not in [9, 10]:  # éå¢™ä½“
                    enhanced[y, x] = room_label
        
        area = (y2 - y1 + 1) * (x2 - x1 + 1)
        print(f"      âœ… åˆ›å»ºå¤‡ç”¨{room_name}åŒºåŸŸ: {area} åƒç´ ")
    
    def _basic_cleanup(self, enhanced, original_ocr_results, scale_x, scale_y):
        """åŸºç¡€æ¸…ç†ï¼šè·ç¦»é˜ˆå€¼æ¸…ç†"""
        print("ğŸ§¹ [ç¬¬3å±‚-èåˆå†³ç­–å™¨] åŸºç¡€æ¸…ç†...")
        
        # è·å–OCRéªŒè¯çš„æˆ¿é—´ä½ç½®ï¼ˆä½¿ç”¨åŸå§‹åæ ‡è½¬æ¢åˆ°512x512ï¼‰
        ocr_rooms = self._extract_ocr_rooms_for_cleanup(original_ocr_results, scale_x, scale_y)
        
        # âš ï¸ è·³è¿‡å«ç”Ÿé—´æ¸…ç†ï¼Œä¿ç•™OCRæ‰©æ•£ç»“æœ
        # æ¸…ç†è¯¯è¯†åˆ«åŒºåŸŸ - æ’é™¤å«ç”Ÿé—´ï¼Œä¿ç•™OCRæ‰©æ•£ç»“æœ
        for room_label, room_positions in ocr_rooms.items():
            if room_label in [3, 4, 7]:  # åªå¤„ç†å®¢å…ã€å§å®¤å’Œå¨æˆ¿ï¼Œè·³è¿‡å«ç”Ÿé—´
                enhanced = self._clean_room_type(enhanced, room_label, room_positions)
        
        return enhanced
    
    def _extract_ocr_rooms_for_cleanup(self, room_text_items, scale_x, scale_y):
        """ä¸ºæ¸…ç†ç®—æ³•æå–OCRéªŒè¯çš„æˆ¿é—´ä½ç½®ï¼ˆä½¿ç”¨åŸå§‹åæ ‡è½¬æ¢åˆ°512x512ï¼‰"""
        ocr_rooms = {}
        for item in room_text_items:
            text = item["text"].lower().strip()
            room_type = None
            
            if any(keyword in text for keyword in ["å¨æˆ¿", "kitchen", "å¨"]):
                room_type = 7
            elif any(keyword in text for keyword in ["å«ç”Ÿé—´", "bathroom", "å«", "æ´—æ‰‹é—´", "æµ´å®¤"]):
                room_type = 2
            elif any(keyword in text for keyword in ["å§å®¤", "bedroom", "ä¸»å§", "æ¬¡å§"]):
                room_type = 4
            elif any(keyword in text for keyword in ["å®¢å…", "living", "å®¢", "å¤§å…"]):
                room_type = 3
            
            if room_type:
                if room_type not in ocr_rooms:
                    ocr_rooms[room_type] = []
                
                # ä½¿ç”¨OCRçš„åŸå§‹åæ ‡å¹¶è½¬æ¢åˆ°512x512
                x, y, w, h = item["bbox"]  # è¿™æ˜¯åŸå§‹OCRåæ ‡ï¼ˆ2å€æ”¾å¤§å›¾åƒä¸Šçš„ï¼‰
                
                center_512_x = int((x + w//2) * scale_x)
                center_512_y = int((y + h//2) * scale_y)
                
                # ç¡®ä¿åæ ‡åœ¨512x512èŒƒå›´å†…
                center_512_x = max(0, min(center_512_x, 511))
                center_512_y = max(0, min(center_512_y, 511))
                
                ocr_rooms[room_type].append((center_512_x, center_512_y, item["confidence"]))
                print(f"   ğŸ¯ [ç¬¬3å±‚-èåˆå†³ç­–å™¨] {text}({room_type}) OCRä½ç½®è½¬æ¢: åŸå§‹({x+w//2}, {y+h//2}) -> 512x512({center_512_x}, {center_512_y})")
        
        return ocr_rooms
    
    def _extract_ocr_rooms(self, room_text_items):
        """æå–OCRéªŒè¯çš„æˆ¿é—´ä½ç½®"""
        ocr_rooms = {}
        for item in room_text_items:
            text = item["text"].lower().strip()
            room_type = None
            
            if any(keyword in text for keyword in ["å¨æˆ¿", "kitchen", "å¨"]):
                room_type = 7
            elif any(keyword in text for keyword in ["å«ç”Ÿé—´", "bathroom", "å«", "æ´—æ‰‹é—´", "æµ´å®¤"]):
                room_type = 2
            # å¯ä»¥ç»§ç»­æ·»åŠ å…¶ä»–æˆ¿é—´ç±»å‹...
            
            if room_type:
                if room_type not in ocr_rooms:
                    ocr_rooms[room_type] = []
                
                # æ³¨æ„ï¼šè¿™é‡Œçš„item["bbox"]å·²ç»æ˜¯è½¬æ¢åçš„512x512åæ ‡ç³»çš„åæ ‡
                x, y, w, h = item["bbox"]
                center_x = int(x + w//2)
                center_y = int(y + h//2)
                ocr_rooms[room_type].append((center_x, center_y, item["confidence"]))
        
        return ocr_rooms
    
    def _clean_room_type(self, enhanced, room_label, room_positions):
        """æ¸…ç†ç‰¹å®šæˆ¿é—´ç±»å‹çš„è¯¯è¯†åˆ«ï¼ˆä¿ç•™åŒ…å«OCRæ‰©æ•£ç§å­çš„ä¸»åŒºåŸŸï¼‰"""
        room_names = {2: "å«ç”Ÿé—´", 3: "å®¢å…", 4: "å§å®¤", 7: "å¨æˆ¿"}
        room_name = room_names.get(room_label, "æˆ¿é—´")
        print(f"ğŸ§¹ [ç¬¬3å±‚-èåˆå†³ç­–å™¨] æ¸…ç†{room_name}è¯¯è¯†åˆ«ï¼Œä¿ç•™{len(room_positions)}ä¸ªOCRéªŒè¯ä½ç½®")

        mask = (enhanced == room_label).astype(np.uint8)
        num_labels, labels_im, stats, centroids = cv2.connectedComponentsWithStats(mask, connectivity=4)
        if num_labels <= 1:
            return enhanced  # æ— éœ€æ¸…ç†

        cleaned_mask = np.zeros_like(mask)
        seed_points = self._seed_centers_by_label.get(room_label, [])
        if seed_points:
            print(f"   ğŸ§ª è°ƒè¯•: {room_name} è®°å½•æ‰©æ•£ç§å­ {len(seed_points)} ä¸ª -> {seed_points[:5]}{'...' if len(seed_points)>5 else ''}")

        # é¢„è®¡ç®—ç§å­æ‰€å±è¿é€šåŸŸ ID
        seed_component_ids = set()
        h_labels, w_labels = labels_im.shape
        for (sx, sy) in seed_points:
            if 0 <= sx < w_labels and 0 <= sy < h_labels:
                cid = labels_im[sy, sx]
                if cid != 0:
                    seed_component_ids.add(cid)
        if seed_component_ids:
            print(f"   ğŸ” å«ç§å­è¿é€šåŸŸ IDs: {sorted(seed_component_ids)}")

        for comp_id in range(1, num_labels):
            comp_centroid = centroids[comp_id]
            comp_center_x, comp_center_y = int(comp_centroid[0]), int(comp_centroid[1])
            comp_area = stats[comp_id, cv2.CC_STAT_AREA]

            # è®¡ç®—åˆ°æœ€è¿‘OCRä¸­å¿ƒçš„è·ç¦»
            min_distance = float('inf')
            for ocr_x, ocr_y, _ in room_positions:
                d = np.hypot(comp_center_x - ocr_x, comp_center_y - ocr_y)
                if d < min_distance:
                    min_distance = d

            # é˜ˆå€¼ç­–ç•¥ï¼ˆæ”¾å®½ï¼Œé¿å…è¯¯åˆ æ‰©æ•£ç»“æœï¼‰
            if room_label == 3:           # å®¢å…
                distance_threshold = 260
                max_area_threshold = 90000
            elif room_label == 4:         # å§å®¤
                distance_threshold = 200
                max_area_threshold = 50000
            elif room_label == 2:         # å«ç”Ÿé—´
                distance_threshold = 220
                max_area_threshold = 30000
            elif room_label == 7:         # å¨æˆ¿
                distance_threshold = 200
                max_area_threshold = 35000
            else:                         # å…¶ä»–
                distance_threshold = 180
                max_area_threshold = 40000

            # å¼ºåˆ¶ä¿ç•™ï¼šç»„ä»¶IDå«ç§å­
            if comp_id in seed_component_ids:
                cleaned_mask[labels_im == comp_id] = 1
                print(f"   âœ… ä¿ç•™{room_name}åŒºåŸŸ(ç§å­ç»„ä»¶#{comp_id}): é¢ç§¯:{comp_area}")
                continue

            # äºŒæ¬¡ç¡®è®¤ï¼šç»„ä»¶å†…éƒ¨æ˜¯å¦åŒ…å«ä»»ä¸€å®é™…ç§å­åƒç´ 
            contains_seed = False
            if seed_points and comp_id not in seed_component_ids:
                component_mask = (labels_im == comp_id)
                for (sx, sy) in seed_points:
                    if 0 <= sx < w_labels and 0 <= sy < h_labels and component_mask[sy, sx]:
                        contains_seed = True
                        break
            if contains_seed:
                cleaned_mask[labels_im == comp_id] = 1
                print(f"   âœ… ä¿ç•™{room_name}åŒºåŸŸ(å«ç§å­åƒç´ #{comp_id}): é¢ç§¯:{comp_area}")
                continue

            if min_distance < distance_threshold and comp_area < max_area_threshold:
                cleaned_mask[labels_im == comp_id] = 1
                print(f"   âœ… ä¿ç•™{room_name}åŒºåŸŸï¼šè·OCR:{min_distance:.1f}px, é¢ç§¯:{comp_area}")
            else:
                print(f"   âŒ ç§»é™¤{room_name}åŒºåŸŸï¼šè·OCR:{min_distance:.1f}px, é¢ç§¯:{comp_area}")

        # æ¸…ç†ä¸é‡å»º
        enhanced[mask == 1] = 0
        enhanced[cleaned_mask == 1] = room_label
        # å…œåº•ï¼šè‹¥å…¨éƒ¨åˆ é™¤ä½†æœ‰ç§å­è¿é€šåŸŸï¼Œæ¢å¤
        if np.sum(cleaned_mask) == 0 and seed_component_ids:
            print(f"   âš ï¸ å…œåº•è§¦å‘: {room_name} æ‰€æœ‰ç»„ä»¶è¢«åˆ ä½†å­˜åœ¨ç§å­, æ¢å¤ç§å­è¿é€šåŸŸ")
            for comp_id in seed_component_ids:
                enhanced[labels_im == comp_id] = room_label
        elif np.sum(cleaned_mask) == 0 and seed_points:
            print(f"   âš ï¸ å…œåº•2: {room_name} æ— ä¿ç•™ç»„ä»¶; åœ¨ç§å­ç‚¹å‘¨å›´åˆ›å»ºæœ€å°ä¿æŠ¤å—")
            for (sx, sy) in seed_points:
                x1 = max(0, sx-5); x2 = min(w_labels-1, sx+5)
                y1 = max(0, sy-5); y2 = min(h_labels-1, sy+5)
                enhanced[y1:y2+1, x1:x2+1] = room_label
        kept_pixels = np.sum(enhanced == room_label)
        print(f"   ğŸ“Š æ¸…ç†å{room_name}æ€»åƒç´ : {kept_pixels}")
        return enhanced


class ReasonablenessValidator:
    """ç¬¬å››å±‚ï¼šåˆç†æ€§éªŒè¯å™¨"""
    
    def __init__(self):
        self.spatial_rules = SpatialRuleEngine()
        self.size_constraints = SizeConstraintEngine()
        self.boundary_detector = BuildingBoundaryDetector()
    
    def validate_and_correct(self, fused_results, ocr_results, original_size):
        """éªŒè¯å¹¶ä¿®æ­£ä¸åˆç†çš„è¯†åˆ«ç»“æœ"""
        print("ğŸ” [ç¬¬4å±‚-åˆç†æ€§éªŒè¯å™¨] å¼€å§‹åˆç†æ€§éªŒè¯...")
        
        # 1. ç©ºé—´åˆç†æ€§æ£€æŸ¥
        validated_results = self.spatial_rules.validate_spatial_logic(fused_results, ocr_results)
        
        # 2. å°ºå¯¸çº¦æŸéªŒè¯
        validated_results = self.size_constraints.validate_size_constraints(validated_results, original_size)
        
        # 3. è¾¹ç•ŒèŒƒå›´æ£€æŸ¥
        validated_results = self.boundary_detector.validate_building_boundary(validated_results, original_size)
        
        print("âœ… [ç¬¬4å±‚-åˆç†æ€§éªŒè¯å™¨] åˆç†æ€§éªŒè¯å®Œæˆ")
        return validated_results


class SpatialRuleEngine:
    """ç©ºé—´é€»è¾‘è§„åˆ™å¼•æ“"""
    
    def validate_spatial_logic(self, results, ocr_results):
        """éªŒè¯ç©ºé—´é€»è¾‘åˆç†æ€§"""
        print("ğŸ§  [ç©ºé—´è§„åˆ™å¼•æ“] éªŒè¯ç©ºé—´é€»è¾‘...")
        
        # è§„åˆ™1: æ£€æŸ¥å§å®¤å†…çš„é‡å¤æˆ¿é—´æ ‡è®°
        results = self._check_nested_rooms(results, ocr_results)
        
        # è§„åˆ™2: æ£€æŸ¥æˆ¿é—´é‡å å†²çª
        results = self._check_room_overlap(results, ocr_results)
        
        # è§„åˆ™3: æ£€æŸ¥å¨æˆ¿ä½ç½®åˆç†æ€§ï¼ˆä¸åº”åœ¨å®¢å…ä¸­å¤®ï¼‰
        results = self._check_kitchen_position(results, ocr_results)
        
        return results
    
    def _check_nested_rooms(self, results, ocr_results):
        """æ£€æŸ¥å¹¶æ¸…ç†åµŒå¥—æˆ¿é—´ï¼ˆå¦‚å§å®¤å†…çš„é¢å¤–å§å®¤ï¼‰"""
        print("   ğŸ  [ç©ºé—´è§„åˆ™å¼•æ“] æ£€æŸ¥åµŒå¥—æˆ¿é—´...")
        
        # è·å–OCRæ ‡æ³¨çš„æˆ¿é—´åŒºåŸŸ
        ocr_room_regions = {}
        for item in ocr_results:
            text = item["text"].lower().strip()
            if any(keyword in text for keyword in ["å§å®¤", "bedroom"]):
                x, y, w, h = item["bbox"]
                
                # OCR bboxæ˜¯åœ¨2å€æ”¾å¤§å›¾åƒä¸Šçš„ï¼Œéœ€è¦è½¬æ¢åˆ°512x512åæ ‡ç³»
                # OCRå›¾åƒå°ºå¯¸å¯ä»¥ä»itemä¸­è·å–ï¼Œæˆ–è€…é€šè¿‡åŸå§‹å›¾åƒå°ºå¯¸è®¡ç®—
                ocr_to_512_scale_x = 512.0 / (item.get('ocr_width', 1158))  # é»˜è®¤å€¼åŸºäºdemo1.jpg
                ocr_to_512_scale_y = 512.0 / (item.get('ocr_height', 866))
                
                # è½¬æ¢åæ ‡åˆ°512x512
                x_512 = int(x * ocr_to_512_scale_x)
                y_512 = int(y * ocr_to_512_scale_y)
                w_512 = int(w * ocr_to_512_scale_x)
                h_512 = int(h * ocr_to_512_scale_y)
                
                # æ‰©å¤§OCRåŒºåŸŸèŒƒå›´ç”¨äºæ£€æµ‹ï¼ˆæ‰©å¤§åˆ°2å€ï¼‰
                expanded_region = {
                    'x1': max(0, x_512 - w_512),
                    'y1': max(0, y_512 - h_512), 
                    'x2': min(512, x_512 + w_512 + w_512),
                    'y2': min(512, y_512 + h_512 + h_512),
                    'text': text,
                    'center_x': x_512 + w_512//2,
                    'center_y': y_512 + h_512//2
                }
                ocr_room_regions[text] = expanded_region
                print(f"   ğŸ“ [ç©ºé—´è§„åˆ™å¼•æ“] OCRæˆ¿é—´ '{text}': ä¸­å¿ƒ({expanded_region['center_x']}, {expanded_region['center_y']}), åŒºåŸŸ({expanded_region['x1']}, {expanded_region['y1']}) -> ({expanded_region['x2']}, {expanded_region['y2']})")
        
        # æ£€æŸ¥æ¯ä¸ªOCRå§å®¤åŒºåŸŸå†…æ˜¯å¦æœ‰AIåˆ†å‰²çš„å…¶ä»–å§å®¤
        bedroom_mask = (results == 4).astype(np.uint8)
        num_labels, labels_im, stats, centroids = cv2.connectedComponentsWithStats(bedroom_mask, connectivity=4)
        
        print(f"   ğŸ” [ç©ºé—´è§„åˆ™å¼•æ“] å‘ç° {num_labels-1} ä¸ªAIåˆ†å‰²çš„å§å®¤è¿é€šåŸŸ")
        
        for room_name, region in ocr_room_regions.items():
            print(f"   ğŸ“ [ç©ºé—´è§„åˆ™å¼•æ“] æ£€æŸ¥ '{room_name}' åŒºåŸŸå†…çš„åµŒå¥—æˆ¿é—´...")
            
            # åœ¨OCRåŒºåŸŸå†…æŸ¥æ‰¾AIåˆ†å‰²çš„å§å®¤å—
            nested_components = []
            for comp_id in range(1, num_labels):
                centroid_x, centroid_y = centroids[comp_id]
                area = stats[comp_id, cv2.CC_STAT_AREA]
                
                print(f"   ğŸ” [ç©ºé—´è§„åˆ™å¼•æ“] AIå§å®¤ç»„ä»¶{comp_id}: ä¸­å¿ƒ({centroid_x:.1f}, {centroid_y:.1f}), é¢ç§¯:{area}")
                
                # æ£€æŸ¥è´¨å¿ƒæ˜¯å¦åœ¨OCRåŒºåŸŸå†…
                if (region['x1'] <= centroid_x <= region['x2'] and 
                    region['y1'] <= centroid_y <= region['y2']):
                    nested_components.append(comp_id)
                    print(f"   âœ… [ç©ºé—´è§„åˆ™å¼•æ“] ç»„ä»¶{comp_id}åœ¨ '{room_name}' åŒºåŸŸå†…")
                else:
                    print(f"   âŒ [ç©ºé—´è§„åˆ™å¼•æ“] ç»„ä»¶{comp_id}åœ¨ '{room_name}' åŒºåŸŸå¤–")
            
            # å¦‚æœæ‰¾åˆ°å¤šä¸ªç»„ä»¶ï¼Œä¿ç•™æœ€å¤§çš„ï¼Œç§»é™¤è¾ƒå°çš„
            if len(nested_components) > 1:
                print(f"   âš ï¸ [ç©ºé—´è§„åˆ™å¼•æ“] å‘ç° '{room_name}' å†…æœ‰ {len(nested_components)} ä¸ªå§å®¤ç»„ä»¶ï¼Œéœ€è¦æ¸…ç†åµŒå¥—")
                
                # æ‰¾åˆ°æœ€å¤§çš„ç»„ä»¶
                largest_comp = max(nested_components, key=lambda comp_id: stats[comp_id, cv2.CC_STAT_AREA])
                largest_area = stats[largest_comp, cv2.CC_STAT_AREA]
                
                print(f"   ğŸ“ [ç©ºé—´è§„åˆ™å¼•æ“] ä¿ç•™æœ€å¤§ç»„ä»¶{largest_comp} (é¢ç§¯:{largest_area})")
                
                # ç§»é™¤å…¶ä»–è¾ƒå°çš„ç»„ä»¶
                for comp_id in nested_components:
                    if comp_id != largest_comp:
                        area = stats[comp_id, cv2.CC_STAT_AREA]
                        results[labels_im == comp_id] = 0  # æ¸…é™¤è¯¥ç»„ä»¶
                        print(f"   ğŸ—‘ï¸ [ç©ºé—´è§„åˆ™å¼•æ“] ç§»é™¤ '{room_name}' å†…åµŒå¥—å§å®¤ç»„ä»¶{comp_id} (é¢ç§¯:{area})")
            elif len(nested_components) == 1:
                print(f"   âœ… [ç©ºé—´è§„åˆ™å¼•æ“] '{room_name}' å†…åªæœ‰1ä¸ªå§å®¤ç»„ä»¶ï¼Œæ— éœ€æ¸…ç†")
            else:
                print(f"   âš ï¸ [ç©ºé—´è§„åˆ™å¼•æ“] '{room_name}' å†…æ²¡æœ‰AIåˆ†å‰²çš„å§å®¤ç»„ä»¶")
        
        return results
    
    def _check_room_overlap(self, results, ocr_results):
        """æ£€æŸ¥æˆ¿é—´é‡å å†²çªï¼Œä¼˜å…ˆä¿ç•™æœ‰OCRæ”¯æŒçš„æˆ¿é—´"""
        print("   ğŸ” [ç©ºé—´è§„åˆ™å¼•æ“] æ£€æŸ¥æˆ¿é—´é‡å å†²çª...")
        
        # è·å–æ‰€æœ‰OCRæ”¯æŒçš„æˆ¿é—´ä¿¡æ¯
        ocr_rooms = {}
        room_type_map = {
            "å¨æˆ¿": 7, "kitchen": 7,
            "å«ç”Ÿé—´": 2, "bathroom": 2, "washroom": 2,
            "å®¢å…": 3, "living": 3,
            "å§å®¤": 4, "bedroom": 4,
            "é˜³å°": 6, "balcony": 6,
            "ä¹¦æˆ¿": 8, "study": 8
        }
        
        for item in ocr_results:
            text = item["text"].lower().strip()
            room_type = None
            
            for keyword, label in room_type_map.items():
                if keyword in text:
                    room_type = label
                    break
            
            if room_type:
                x, y, w, h = item["bbox"]
                # è½¬æ¢åˆ°512x512åæ ‡ç³»
                ocr_to_512_scale_x = 512.0 / (item.get('ocr_width', 1158))
                ocr_to_512_scale_y = 512.0 / (item.get('ocr_height', 866))
                
                center_x_512 = int((x + w//2) * ocr_to_512_scale_x)
                center_y_512 = int((y + h//2) * ocr_to_512_scale_y)
                
                if room_type not in ocr_rooms:
                    ocr_rooms[room_type] = []
                ocr_rooms[room_type].append({
                    'center': (center_x_512, center_y_512),
                    'text': text,
                    'confidence': item.get('confidence', 1.0)
                })
        
        # æ£€æŸ¥æ— OCRæ”¯æŒçš„å¤§é¢ç§¯åŒºåŸŸ
        room_labels = [2, 3, 4, 6, 7, 8]  # æ‰€æœ‰æˆ¿é—´ç±»å‹
        for label in room_labels:
            mask = (results == label)
            if not np.any(mask):
                continue
                
            # å¦‚æœæœ‰OCRæ”¯æŒï¼Œè·³è¿‡æ£€æŸ¥
            if label in ocr_rooms and len(ocr_rooms[label]) > 0:
                continue
                
            # è®¡ç®—æ— OCRæ”¯æŒåŒºåŸŸçš„é¢ç§¯
            area = np.sum(mask)
            total_area = results.shape[0] * results.shape[1]
            area_ratio = area / total_area
            
            # å¦‚æœæ— OCRæ”¯æŒçš„åŒºåŸŸè¿‡å¤§ï¼Œç§»é™¤å®ƒ
            if area_ratio > 0.08:  # è¶…è¿‡8%çš„æ— OCRæ”¯æŒåŒºåŸŸï¼ˆä»15%è°ƒæ•´ï¼‰
                room_name = {2: "å«ç”Ÿé—´", 3: "å®¢å…", 4: "å§å®¤", 6: "é˜³å°", 7: "å¨æˆ¿", 8: "ä¹¦æˆ¿"}[label]
                print(f"   ğŸ—‘ï¸ [ç©ºé—´è§„åˆ™å¼•æ“] ç§»é™¤è¿‡å¤§çš„æ— OCRæ”¯æŒ{room_name}åŒºåŸŸ: {area_ratio:.1%}")
                results[mask] = 0  # æ¸…é™¤è¯¥åŒºåŸŸ
        
        # æ£€æŸ¥æˆ¿é—´é‡å å†²çª
        results = self._check_room_overlap_conflicts(results)
        
        return results
    
    def _check_kitchen_position(self, results, ocr_results):
        """æ£€æŸ¥å¨æˆ¿ä½ç½®åˆç†æ€§"""
        print("   ğŸ³ [ç©ºé—´è§„åˆ™å¼•æ“] æ£€æŸ¥å¨æˆ¿ä½ç½®åˆç†æ€§...")
        
        # è·å–å®¢å…å’Œå¨æˆ¿çš„OCRä½ç½®
        living_room_centers = []
        kitchen_centers = []
        
        for item in ocr_results:
            text = item["text"].lower().strip()
            x, y, w, h = item["bbox"]
            center_x, center_y = x + w//2, y + h//2
            
            if any(keyword in text for keyword in ["å®¢å…", "living"]):
                living_room_centers.append((center_x, center_y))
            elif any(keyword in text for keyword in ["å¨æˆ¿", "kitchen"]):
                kitchen_centers.append((center_x, center_y))
        
        # å¦‚æœæœ‰å®¢å…ï¼Œæ£€æŸ¥å¨æˆ¿æ˜¯å¦åœ¨å®¢å…ä¸­å¤®
        if living_room_centers and kitchen_centers:
            for lr_x, lr_y in living_room_centers:
                for kit_x, kit_y in kitchen_centers:
                    distance = np.sqrt((lr_x - kit_x)**2 + (lr_y - kit_y)**2)
                    if distance < 50:  # è·ç¦»å¤ªè¿‘ï¼Œå¯èƒ½æ˜¯é”™è¯¯è¯†åˆ«
                        print(f"   âš ï¸ [ç©ºé—´è§„åˆ™å¼•æ“] å¨æˆ¿è·å®¢å…è¿‡è¿‘ (è·ç¦»:{distance:.1f}px)ï¼Œéœ€è¦éªŒè¯")
        
        return results
    
    def _check_room_overlap_conflicts(self, results):
        """æ£€æŸ¥æˆ¿é—´é‡å å†²çªï¼Œç§»é™¤ä¸åˆç†çš„å¤§é¢ç§¯é‡å åŒºåŸŸ"""
        print("   ğŸ” [ç©ºé—´è§„åˆ™å¼•æ“] æ£€æŸ¥æˆ¿é—´é‡å å†²çª...")
        
        room_labels = [2, 3, 4, 6, 7, 8]  # å«ç”Ÿé—´ã€å®¢å…ã€å§å®¤ã€é˜³å°ã€å¨æˆ¿ã€ä¹¦æˆ¿
        room_names = {2: "å«ç”Ÿé—´", 3: "å®¢å…", 4: "å§å®¤", 6: "é˜³å°", 7: "å¨æˆ¿", 8: "ä¹¦æˆ¿"}
        
        # æ£€æŸ¥æ¯ç§æˆ¿é—´ç±»å‹çš„è¿é€šåŸŸ
        for label in room_labels:
            mask = (results == label).astype(np.uint8)
            if not np.any(mask):
                continue
                
            num_labels, labels_im, stats, centroids = cv2.connectedComponentsWithStats(mask, connectivity=4)
            
            for comp_id in range(1, num_labels):
                area = stats[comp_id, cv2.CC_STAT_AREA]
                total_area = results.shape[0] * results.shape[1]
                area_ratio = area / total_area
                
                # æ£€æŸ¥å¤§é¢ç§¯æˆ¿é—´ä¸å…¶ä»–æˆ¿é—´çš„é‡å 
                if area_ratio > 0.15:  # é¢ç§¯è¶…è¿‡15%çš„æˆ¿é—´éœ€è¦é‡å æ£€æŸ¥
                    component_mask = (labels_im == comp_id)
                    overlap_count = 0
                    overlap_types = []
                    
                    # æ£€æŸ¥ä¸å…¶ä»–æˆ¿é—´ç±»å‹çš„é‡å 
                    for other_label in room_labels:
                        if other_label == label:
                            continue
                            
                        other_mask = (results == other_label)
                        if not np.any(other_mask):
                            continue
                            
                        # è®¡ç®—é‡å åŒºåŸŸ
                        overlap_area = np.sum(component_mask & other_mask)
                        overlap_ratio = overlap_area / area if area > 0 else 0
                        
                        if overlap_ratio > 0.1:  # é‡å è¶…è¿‡10%
                            overlap_count += 1
                            overlap_types.append(room_names[other_label])
                    
                    # å¦‚æœä¸å¤šä¸ªæˆ¿é—´é‡å ï¼Œç§»é™¤è¯¥åŒºåŸŸ
                    if overlap_count >= 2:
                        print(f"   ğŸ—‘ï¸ [ç©ºé—´è§„åˆ™å¼•æ“] ç§»é™¤å¤šé‡å {room_names[label]}åŒºåŸŸ (é¢ç§¯:{area_ratio:.1%}, é‡å :{overlap_count}ä¸ªæˆ¿é—´: {', '.join(overlap_types)})")
                        results[component_mask] = 0
                    elif overlap_count == 1 and area_ratio > 0.25:  # å•ä¸ªé‡å ä½†é¢ç§¯è¿‡å¤§
                        print(f"   ğŸ—‘ï¸ [ç©ºé—´è§„åˆ™å¼•æ“] ç§»é™¤è¿‡å¤§çš„é‡å {room_names[label]}åŒºåŸŸ (é¢ç§¯:{area_ratio:.1%}, ä¸{overlap_types[0]}é‡å )")
                        results[component_mask] = 0
        
        return results


class SizeConstraintEngine:
    """å°ºå¯¸çº¦æŸå¼•æ“"""
    
    def validate_size_constraints(self, results, original_size):
        """éªŒè¯å°ºå¯¸çº¦æŸ"""
        print("ğŸ“ [å°ºå¯¸çº¦æŸå¼•æ“] éªŒè¯æˆ¿é—´å°ºå¯¸...")
        
        # è®¡ç®—åƒç´ åˆ°å®é™…å°ºå¯¸çš„è½¬æ¢æ¯”ä¾‹ï¼ˆåŸºäºå¸¸è§æˆ·å‹å›¾ï¼‰
        # å‡è®¾å›¾åƒå®½åº¦å¯¹åº”å®é™…10-15ç±³
        pixel_to_meter = 12.0 / original_size[0]  # ç²—ç•¥ä¼°ç®—
        
        # é¦–å…ˆæ£€æŸ¥å¤§é¢ç§¯åŒºåŸŸçš„åˆç†æ€§
        results = self._validate_large_area_rooms(results)
        
        # æ£€æŸ¥å„æˆ¿é—´ç±»å‹çš„å°ºå¯¸åˆç†æ€§
        room_names = {2: "å«ç”Ÿé—´", 3: "å®¢å…", 4: "å§å®¤", 6: "é˜³å°", 7: "å¨æˆ¿", 8: "ä¹¦æˆ¿"}
        
        for room_label, room_name in room_names.items():
            if room_label in [2, 7]:  # é‡ç‚¹æ£€æŸ¥å«ç”Ÿé—´å’Œå¨æˆ¿
                results = self._check_room_size(results, room_label, room_name, pixel_to_meter)
        
        return results
    
    def _check_room_size(self, results, room_label, room_name, pixel_to_meter):
        """æ£€æŸ¥ç‰¹å®šæˆ¿é—´ç±»å‹çš„å°ºå¯¸"""
        print(f"   ğŸ“ [å°ºå¯¸çº¦æŸå¼•æ“] æ£€æŸ¥{room_name}å°ºå¯¸...")
        
        mask = (results == room_label).astype(np.uint8)
        num_labels, labels_im, stats, centroids = cv2.connectedComponentsWithStats(mask, connectivity=4)
        
        # è®¾å®šåˆç†çš„é¢ç§¯èŒƒå›´ï¼ˆå¹³æ–¹ç±³ï¼‰
        if room_label == 2:  # å«ç”Ÿé—´
            min_area_m2, max_area_m2 = 2, 15  # 2-15å¹³æ–¹ç±³
        elif room_label == 7:  # å¨æˆ¿
            min_area_m2, max_area_m2 = 3, 20  # 3-20å¹³æ–¹ç±³
        else:
            return results
        
        for comp_id in range(1, num_labels):
            area_pixels = stats[comp_id, cv2.CC_STAT_AREA]
            area_m2 = area_pixels * (pixel_to_meter ** 2)
            
            if area_m2 > max_area_m2:
                print(f"   âš ï¸ [å°ºå¯¸çº¦æŸå¼•æ“] {room_name}è¿‡å¤§: {area_m2:.1f}mÂ² (>{max_area_m2}mÂ²), éœ€è¦ä¿®æ­£")
                # ç§»é™¤è¿‡å¤§çš„åŒºåŸŸ
                results[labels_im == comp_id] = 0
                print(f"   ğŸ—‘ï¸ [å°ºå¯¸çº¦æŸå¼•æ“] ç§»é™¤è¿‡å¤§{room_name}åŒºåŸŸ")
            elif area_m2 < min_area_m2:
                print(f"   âš ï¸ [å°ºå¯¸çº¦æŸå¼•æ“] {room_name}è¿‡å°: {area_m2:.1f}mÂ² (<{min_area_m2}mÂ²), å¯èƒ½æ˜¯è¯¯è¯†åˆ«")
        
        return results
    
    def _validate_large_area_rooms(self, results):
        """éªŒè¯å¤§é¢ç§¯æˆ¿é—´çš„åˆç†æ€§"""
        print("   ğŸ“ [å°ºå¯¸çº¦æŸå¼•æ“] æ£€æŸ¥å¤§é¢ç§¯åŒºåŸŸåˆç†æ€§...")
        
        total_area = results.shape[0] * results.shape[1]
        room_names = {2: "å«ç”Ÿé—´", 3: "å®¢å…", 4: "å§å®¤", 6: "é˜³å°", 7: "å¨æˆ¿", 8: "ä¹¦æˆ¿"}
        
        # ä¸åŒæˆ¿é—´ç±»å‹çš„åˆç†é¢ç§¯ä¸Šé™ï¼ˆé¢ç§¯æ¯”ä¾‹ï¼‰
        max_ratios = {
            2: 0.10,    # å«ç”Ÿé—´æœ€å¤š10%
            3: 0.40,    # å®¢å…æœ€å¤š40%
            4: 0.30,    # å•ä¸ªå§å®¤æœ€å¤š30%
            6: 0.15,    # é˜³å°æœ€å¤š15%
            7: 0.15,    # å¨æˆ¿æœ€å¤š15%
            8: 0.30     # ä¹¦æˆ¿æœ€å¤š5%ï¼ˆä¸¥æ ¼é™åˆ¶ï¼‰
        }
        
        for label, room_name in room_names.items():
            mask = (results == label).astype(np.uint8)
            if not np.any(mask):
                continue
                
            num_labels, labels_im, stats, centroids = cv2.connectedComponentsWithStats(mask, connectivity=4)
            max_ratio = max_ratios.get(label, 0.25)
            
            for comp_id in range(1, num_labels):
                area = stats[comp_id, cv2.CC_STAT_AREA]
                area_ratio = area / total_area
                
                if area_ratio > max_ratio:
                    print(f"   ğŸ—‘ï¸ [å°ºå¯¸çº¦æŸå¼•æ“] ç§»é™¤è¿‡å¤§{room_name}åŒºåŸŸ: {area_ratio:.1%} > {max_ratio:.1%}")
                    results[labels_im == comp_id] = 0
        
        return results


class BuildingBoundaryDetector:
    """å»ºç­‘è¾¹ç•Œæ£€æµ‹å™¨"""
    
    def validate_building_boundary(self, results, original_size):
        """éªŒè¯å»ºç­‘è¾¹ç•Œ"""
        print("ğŸ—ï¸ [è¾¹ç•Œæ£€æµ‹å™¨] éªŒè¯å»ºç­‘è¾¹ç•Œ...")
        
        # æ£€æµ‹å›¾åƒè¾¹ç¼˜çš„æˆ¿é—´æ ‡è®°ï¼ˆå¯èƒ½æ˜¯å¤–éƒ¨æ ‡å°ºè¯¯è¯†åˆ«ï¼‰
        results = self._remove_edge_misidentifications(results)
        
        return results
    
    def _remove_edge_misidentifications(self, results):
        """ç§»é™¤è¾¹ç¼˜ä½ç½®çš„è¯¯è¯†åˆ«"""
        print("   ğŸš« [è¾¹ç•Œæ£€æµ‹å™¨] æ£€æŸ¥è¾¹ç¼˜è¯¯è¯†åˆ«...")
        
        h, w = results.shape
        edge_threshold = 20  # è¾¹ç¼˜é˜ˆå€¼åƒç´ 
        
        # æ£€æŸ¥å››ä¸ªè¾¹ç¼˜åŒºåŸŸ
        edges = [
            (0, edge_threshold, 0, w),  # ä¸Šè¾¹ç¼˜
            (h-edge_threshold, h, 0, w),  # ä¸‹è¾¹ç¼˜  
            (0, h, 0, edge_threshold),  # å·¦è¾¹ç¼˜
            (0, h, w-edge_threshold, w)  # å³è¾¹ç¼˜
        ]
        
        for y1, y2, x1, x2 in edges:
            edge_region = results[y1:y2, x1:x2]
            unique_labels = np.unique(edge_region)
            
            # ç§»é™¤è¾¹ç¼˜åŒºåŸŸçš„æˆ¿é—´æ ‡è®°ï¼ˆé™¤äº†èƒŒæ™¯0å’Œå¢™ä½“1ï¼‰
            for label in unique_labels:
                if label > 1:  # æˆ¿é—´æ ‡ç­¾
                    room_pixels = np.sum(edge_region == label)
                    if room_pixels > 50:  # å¦‚æœè¾¹ç¼˜åŒºåŸŸæœ‰è¾ƒå¤šè¯¥æˆ¿é—´åƒç´ 
                        print(f"   ğŸ—‘ï¸ [è¾¹ç•Œæ£€æµ‹å™¨] ç§»é™¤è¾¹ç¼˜åŒºåŸŸæˆ¿é—´æ ‡è®° (æ ‡ç­¾:{label}, åƒç´ :{room_pixels})")
                        results[results == label] = 0
        
        return results


class FloorplanProcessor:
    """æˆ·å‹å›¾å¤„ç†å™¨ - å››å±‚æ™ºèƒ½å†³ç­–æ¶æ„ç»Ÿä¸€ç®¡ç†å™¨"""

    def __init__(self, model_path="pretrained"):
        """åˆå§‹åŒ–å››å±‚æ¶æ„å¤„ç†å™¨"""
        print("ğŸ  DeepFloorplan æˆ¿é—´æ£€æµ‹ - å››å±‚æ™ºèƒ½å†³ç­–æ¶æ„")
        print("=" * 60)

        # åˆå§‹åŒ–å››å±‚æ¶æ„ç»„ä»¶
        self.ai_engine = AISegmentationEngine(model_path)
        self.ocr_engine = OCRRecognitionEngine()
        self.fusion_engine = FusionDecisionEngine()
        self.validator = ReasonablenessValidator()

        # è¿è¡Œæ—¶ç¼“å­˜/çŠ¶æ€
        self.last_enhanced = None  # æœ€è¿‘ä¸€æ¬¡å¢å¼ºåçš„ label å›¾ (512x512)
        self._boundary_cache = {}  # {md5: å¢å¼ºåå«å¢™ä½“ç»“æœ}

    def load_model(self):
        """åŠ è½½AIåˆ†å‰²æ¨¡å‹"""
        self.ai_engine.load_model()

    def preprocess_image(self, image_path):
        """å›¾åƒé¢„å¤„ç†"""
        print(f"ğŸ“¸ å¤„ç†å›¾åƒ: {image_path}")

        # è¯»å–å›¾åƒ
        img = Image.open(image_path).convert("RGB")
        original_size = img.size

        print(f"ğŸ“ åŸå§‹å›¾åƒå°ºå¯¸: {original_size[0]} x {original_size[1]} (å®½xé«˜)")

        # è°ƒæ•´åˆ°æ¨¡å‹è¾“å…¥å°ºå¯¸ (512x512)
        img_resized = img.resize((512, 512), Image.LANCZOS)
        img_array = np.array(img_resized, dtype=np.float32) / 255.0

        print(f"ğŸ”„ ç¥ç»ç½‘ç»œè¾“å…¥: 512 x 512 (å›ºå®šå°ºå¯¸)")

        return img_array, original_size, np.array(img)

    def process_with_four_layer_architecture(self, img_array, original_img, original_size):
        """ä½¿ç”¨å››å±‚æ¶æ„å¤„ç†å›¾åƒ"""
        print("\nğŸ—ï¸ å¼€å§‹å››å±‚æ™ºèƒ½å†³ç­–å¤„ç†æµç¨‹...")
        
        # ç¬¬ä¸€å±‚ï¼šAIè¯­ä¹‰åˆ†å‰²
        ai_prediction = self.ai_engine.segment_image(img_array)
        
        # ç¬¬äºŒå±‚ï¼šOCRæ–‡å­—è¯†åˆ«
        ocr_results, ocr_shape = self.ocr_engine.recognize_text(original_img)
        
        # ç¬¬ä¸‰å±‚ï¼šèåˆå†³ç­–
        fused_results = self.fusion_engine.fuse_results(ai_prediction, ocr_results, ocr_shape)
        
        # ç¬¬å››å±‚ï¼šåˆç†æ€§éªŒè¯
        validated_results = self.validator.validate_and_correct(fused_results, ocr_results, original_size)
        
        # ä¿å­˜ç»“æœç”¨äºç»Ÿè®¡
        self.last_enhanced = validated_results
        
        print("ğŸ‰ å››å±‚æ™ºèƒ½å†³ç­–å¤„ç†å®Œæˆï¼")
        return {
            'ai_raw': ai_prediction,
            'ocr_results': ocr_results, 
            'fusion_result': fused_results,
            'final_result': validated_results
        }

    # ä¿ç•™åŸæœ‰æ¥å£ä»¥ä¿æŒå…¼å®¹æ€§
    def run_inference(self, img_array):
        """è¿è¡Œç¥ç»ç½‘ç»œæ¨ç†ï¼ˆå…¼å®¹æ¥å£ï¼‰"""
        return self.ai_engine.segment_image(img_array)

    def extract_ocr_info(self, original_img):
        """æå–OCRæ–‡å­—ä¿¡æ¯ï¼ˆå…¼å®¹æ¥å£ï¼‰"""
        return self.ocr_engine.recognize_text(original_img)

    def fuse_predictions(self, prediction, room_text_items, ocr_shape):
        """èåˆé¢„æµ‹ç»“æœï¼ˆå…¼å®¹æ¥å£ï¼‰"""
        return self.fusion_engine.fuse_results(prediction, room_text_items, ocr_shape)

    def detect_rooms(self, enhanced, room_text_items, original_size):
        """æ£€æµ‹å„ç±»æˆ¿é—´ï¼ˆå…¼å®¹æ¥å£ï¼‰"""
        # ç°åœ¨è¿™ä¸ªåŠŸèƒ½å·²ç»æ•´åˆåˆ°å››å±‚æ¶æ„ä¸­
        return enhanced
        
    def _clean_misidentified_regions(self, enhanced, room_text_items, original_size):
        """æ¸…ç†AIåˆ†å‰²ä¸­çš„è¯¯è¯†åˆ«åŒºåŸŸï¼Œåªä¿ç•™OCRéªŒè¯çš„æˆ¿é—´åŒºåŸŸ"""
        print("ğŸ§¹ æ¸…ç†AIåˆ†å‰²è¯¯è¯†åˆ«åŒºåŸŸ...")
        
        # è·å–OCRéªŒè¯çš„æˆ¿é—´ä½ç½®
        ocr_rooms = {}
        for item in room_text_items:
            text = item["text"].lower().strip()
            room_type = None
            
            if any(keyword in text for keyword in ["å¨æˆ¿", "kitchen", "å¨"]):
                room_type = 7  # å¨æˆ¿
            elif any(keyword in text for keyword in ["å«ç”Ÿé—´", "bathroom", "å«", "æ´—æ‰‹é—´", "æµ´å®¤", "æ·‹æµ´é—´", "shower", "æ·‹æµ´", "ç›¥æ´—å®¤"]):
                room_type = 2  # å«ç”Ÿé—´
            elif any(keyword in text for keyword in ["å®¢å…", "living", "å…", "èµ·å±…å®¤"]):
                room_type = 3  # å®¢å…
            elif any(keyword in text for keyword in ["å§å®¤", "bedroom", "ä¸»å§", "æ¬¡å§"]):
                room_type = 4  # å§å®¤
            elif any(keyword in text for keyword in ["é˜³å°", "balcony", "é˜³å…®", "é˜³åˆ", "é˜³å›Š"]):
                room_type = 6  # é˜³å°
            elif any(keyword in text for keyword in ["ä¹¦æˆ¿", "study", "åŠå…¬å®¤", "office"]):
                room_type = 8  # ä¹¦æˆ¿
                
            if room_type:
                if room_type not in ocr_rooms:
                    ocr_rooms[room_type] = []
                
                # è½¬æ¢OCRåæ ‡åˆ°512x512åæ ‡ç³»
                x, y, w, h = item["bbox"]
                # OCRæ˜¯åœ¨2å€æ”¾å¤§å›¾åƒä¸Šï¼Œéœ€è¦è½¬æ¢åˆ°512x512
                ocr_to_512_x = 512.0 / (original_size[0] * 2)
                ocr_to_512_y = 512.0 / (original_size[1] * 2) 
                
                center_512_x = int((x + w//2) * ocr_to_512_x)
                center_512_y = int((y + h//2) * ocr_to_512_y)
                ocr_rooms[room_type].append((center_512_x, center_512_y, item["confidence"]))
        
        # å¯¹äºæ¯ä¸ªæˆ¿é—´ç±»å‹ï¼Œåªä¿ç•™OCRéªŒè¯ä½ç½®é™„è¿‘çš„åˆ†å‰²åŒºåŸŸ
        for room_label, room_positions in ocr_rooms.items():
            if room_label in [2, 7]:  # å¤„ç†å«ç”Ÿé—´å’Œå¨æˆ¿çš„è¯¯è¯†åˆ«é—®é¢˜
                room_name = "å«ç”Ÿé—´" if room_label == 2 else "å¨æˆ¿"
                print(f"ğŸ§¹ æ¸…ç†{room_name}è¯¯è¯†åˆ«åŒºåŸŸï¼Œä¿ç•™{len(room_positions)}ä¸ªOCRéªŒè¯ä½ç½®")
                
                # è·å–æ‰€æœ‰æŒ‡å®šæ ‡ç­¾çš„åƒç´ 
                mask = (enhanced == room_label).astype(np.uint8)
                
                # ä½¿ç”¨è¿é€šåŸŸåˆ†ææ‰¾åˆ°æ‰€æœ‰åŒºåŸŸ
                num_labels, labels_im, stats, centroids = cv2.connectedComponentsWithStats(mask, connectivity=4)
                
                # åˆ›å»ºæ–°çš„æ¸…ç†åçš„mask
                cleaned_mask = np.zeros_like(mask)
                
                for comp_id in range(1, num_labels):  # è·³è¿‡èƒŒæ™¯(0)
                    comp_centroid = centroids[comp_id]
                    comp_center_x, comp_center_y = int(comp_centroid[0]), int(comp_centroid[1])
                    comp_area = stats[comp_id, cv2.CC_STAT_AREA]
                    
                    # æ£€æŸ¥è¿™ä¸ªè¿é€šåŸŸæ˜¯å¦æ¥è¿‘ä»»ä½•OCRéªŒè¯çš„ä½ç½®
                    is_valid = False
                    min_distance = float('inf')
                    closest_confidence = 0
                    
                    for ocr_x, ocr_y, confidence in room_positions:
                        distance = np.sqrt((comp_center_x - ocr_x)**2 + (comp_center_y - ocr_y)**2)
                        if distance < min_distance:
                            min_distance = distance
                            closest_confidence = confidence
                    
                    # è®¾ç½®è·ç¦»é˜ˆå€¼ï¼šæ ¹æ®OCRéªŒè¯ä½ç½®æ•°é‡åŠ¨æ€è°ƒæ•´
                    if len(room_positions) > 1:
                        # å¤šä¸ªOCRä½ç½®æ—¶ï¼Œä½¿ç”¨æ›´å®½æ¾çš„é˜ˆå€¼
                        distance_threshold = 120 if room_label == 7 else 100
                    else:
                        # å•ä¸ªOCRä½ç½®æ—¶ï¼Œä½¿ç”¨æ ‡å‡†é˜ˆå€¼  
                        distance_threshold = 100 if room_label == 7 else 80
                    
                    # è®¾ç½®é¢ç§¯é˜ˆå€¼ï¼šé˜²æ­¢å·¨å¤§çš„è¯¯è¯†åˆ«åŒºåŸŸ
                    max_area_threshold = 15000 if room_label == 7 else 10000  # é€‚å½“æ”¾å®½é¢ç§¯é™åˆ¶
                    
                    # å¦‚æœè·ç¦»åœ¨åˆç†èŒƒå›´å†…ä¸”é¢ç§¯ä¸è¶…æ ‡ï¼Œè®¤ä¸ºæ˜¯æœ‰æ•ˆçš„
                    if min_distance < distance_threshold and comp_area < max_area_threshold:  
                        is_valid = True
                        print(f"   âœ… ä¿ç•™{room_name}åŒºåŸŸï¼šä¸­å¿ƒ({comp_center_x}, {comp_center_y}), è·OCR: {min_distance:.1f}åƒç´ , é¢ç§¯: {comp_area}, ç½®ä¿¡åº¦: {closest_confidence:.3f}")
                    else:
                        reasons = []
                        if min_distance >= distance_threshold:
                            reasons.append("è·ç¦»è¿‡è¿œ")
                        if comp_area >= max_area_threshold:
                            reasons.append("é¢ç§¯è¿‡å¤§")
                        print(f"   âŒ ç§»é™¤è¯¯è¯†åˆ«åŒºåŸŸï¼šä¸­å¿ƒ({comp_center_x}, {comp_center_y}), è·OCR: {min_distance:.1f}åƒç´ , é¢ç§¯: {comp_area} ({', '.join(reasons)})")
                    
                    if is_valid:
                        # ä¿ç•™è¿™ä¸ªè¿é€šåŸŸ
                        component_mask = (labels_im == comp_id)
                        cleaned_mask[component_mask] = 1
                
                # ç”¨æ¸…ç†åçš„maskæ›´æ–°enhanced
                enhanced[mask == 1] = 0  # å…ˆæ¸…é™¤æ‰€æœ‰åŸæ¥çš„æ ‡è®°
                enhanced[cleaned_mask == 1] = room_label  # ç„¶åè®¾ç½®éªŒè¯è¿‡çš„åŒºåŸŸ
                
                removed_pixels = np.sum(mask) - np.sum(cleaned_mask)
                print(f"   ğŸ“Š æ¸…ç†ç»“æœï¼šç§»é™¤äº† {removed_pixels} ä¸ªè¯¯è¯†åˆ«åƒç´ ")
        
        return enhanced

    def _apply_color_mapping(self, result_array, original_size):
        """å°†åˆ†å‰²ç»“æœåº”ç”¨é¢œè‰²æ˜ å°„"""
        # è°ƒæ•´åˆ°åŸå§‹å°ºå¯¸
        result_resized = cv2.resize(result_array, original_size, interpolation=cv2.INTER_NEAREST)

        # ä½¿ç”¨ç¼“å­˜çš„è¾¹ç•Œå¢å¼ºï¼Œé¿å…é‡å¤å¤šæ¬¡ç»†åŒ–ç ´åç»“æ„
        result_with_boundaries = self._add_boundary_detection_cached(result_resized)

        # ç”Ÿæˆå½©è‰²å›¾
        h, w = result_with_boundaries.shape
        colored_result = np.zeros((h, w, 3), dtype=np.uint8)
        # ä¸å›¾ä¾‹ç»Ÿä¸€: ä½¿ç”¨ floorplan_fuse_map_figure
        from utils.rgb_ind_convertor import floorplan_fuse_map_figure as _COLOR_MAP
        for label_value, color in _COLOR_MAP.items():
            if label_value > 10:  # å®‰å…¨è¿‡æ»¤ï¼ˆç°ç”¨åˆ°0-10ï¼‰
                continue
            mask = (result_with_boundaries == label_value)
            colored_result[mask] = color

        return colored_result

    def _visualize_ocr_results(self, original_img, room_text_items):
        """å¯è§†åŒ–OCRè¯†åˆ«ç»“æœï¼ˆæ˜¾ç¤ºä¿®æ­£åçš„æ–‡æœ¬ï¼‰"""
        ocr_img = original_img.copy()

        # å®šä¹‰æˆ¿é—´ç±»å‹é¢œè‰²
        room_colors = {
            "å¨æˆ¿": (0, 255, 0),      # ç»¿è‰²
            "å«ç”Ÿé—´": (255, 0, 0),    # è“è‰²
            "å®¢å…": (0, 165, 255),    # æ©™è‰²
            "å§å®¤": (128, 0, 128),    # ç´«è‰²
            "é˜³å°": (255, 255, 0),    # é’è‰²
            "ä¹¦æˆ¿": (165, 42, 42),    # æ£•è‰²
        }

        # OCRä¿®æ­£æ˜ å°„ - ä¿®æ­£å¸¸è§çš„OCRè¯†åˆ«é”™è¯¯
        ocr_corrections = {
            # é˜³å°ç›¸å…³ä¿®æ­£
            "é˜³å…®": "é˜³å°",
            "é˜³å°": "é˜³å°",
            "é™½å°": "é˜³å°",
            "é˜³åˆ": "é˜³å°",
            "é˜³èˆ": "é˜³å°",
            "é˜³å¤": "é˜³å°",

            # å¨æˆ¿ç›¸å…³ä¿®æ­£
            "å¨æˆ¿": "å¨æˆ¿",
            "å»šæˆ¿": "å¨æˆ¿",
            "å¨æˆ·": "å¨æˆ¿",
            "å¨åº": "å¨æˆ¿",
            "åºæˆ¿": "å¨æˆ¿",

            # å«ç”Ÿé—´ç›¸å…³ä¿®æ­£
            "å«ç”Ÿé—´": "å«ç”Ÿé—´",
            "è¡›ç”Ÿé–“": "å«ç”Ÿé—´",
            "å«ç”Ÿé—¬": "å«ç”Ÿé—´",
            "å«ç”Ÿé—¨": "å«ç”Ÿé—´",
            "æµ´å®¤": "å«ç”Ÿé—´",
            "æ´—æ‰‹é—´": "å«ç”Ÿé—´",
            "å•æ‰€": "å«ç”Ÿé—´",

            # å®¢å…ç›¸å…³ä¿®æ­£
            "å®¢å…": "å®¢å…",
            "å®¢å»³": "å®¢å…",
            "å®¢åº”": "å®¢å…",
            "å®¢å¹¿": "å®¢å…",
            "èµ·å±…å®¤": "å®¢å…",
            "ä¼šå®¢å…": "å®¢å…",

            # å§å®¤ç›¸å…³ä¿®æ­£
            "å§å®¤": "å§å®¤",
            "è‡¥å®¤": "å§å®¤",
            "å§å®": "å§å®¤",
            "å§çª’": "å§å®¤",
            "ä¸»å§": "ä¸»å§",
            "æ¬¡å§": "æ¬¡å§",

            # ä¹¦æˆ¿ç›¸å…³ä¿®æ­£
            "ä¹¦æˆ¿": "ä¹¦æˆ¿",
            "æ›¸æˆ¿": "ä¹¦æˆ¿",
            "ä¹¦æˆ·": "ä¹¦æˆ¿",
            "ä¹¦åº": "ä¹¦æˆ¿",
            "å­¦ä¹ å®¤": "ä¹¦æˆ¿",
            "å·¥ä½œå®¤": "ä¹¦æˆ¿",

            # é¤å…ç›¸å…³ä¿®æ­£
            "é¤å…": "é¤å…",
            "é¤å»³": "é¤å…",
            "é¥­å…": "é¤å…",
            "ç”¨é¤åŒº": "é¤å…",

            # å…¥æˆ·ç›¸å…³ä¿®æ­£
            "å…¥æˆ·": "å…¥æˆ·",
            "ç„å…³": "å…¥æˆ·",
            "é—¨å…": "å…¥æˆ·",

            # èµ°å»Šç›¸å…³ä¿®æ­£
            "èµ°å»Š": "èµ°å»Š",
            "è¿‡é“": "èµ°å»Š",
            "é€šé“": "èµ°å»Š",

            # å‚¨ç‰©ç›¸å…³ä¿®æ­£
            "å‚¨ç‰©é—´": "å‚¨ç‰©é—´",
            "å‚¨è—å®¤": "å‚¨ç‰©é—´",
            "æ‚ç‰©é—´": "å‚¨ç‰©é—´",
            "è¡£å¸½é—´": "è¡£å¸½é—´",

            # æ¸…ç†å•å­—ç¬¦å™ªéŸ³ï¼ˆå¸¸è§OCRé”™è¯¯è¯†åˆ«ï¼‰
            "é—¨": "",
            "æˆ·": "",
            "å£": "",
            "äºº": "",
            "å¤§": "",
            "å°": "",
            "ä¸­": "",
            "ä¸Š": "",
            "ä¸‹": "",
            "å·¦": "",
            "å³": "",
            "ä¸€": "",
            "äºŒ": "",
            "ä¸‰": "",
            "å››": "",
            "äº”": "",
            "1": "",
            "2": "",
            "3": "",
            "4": "",
            "5": "",
            "6": "",
            "7": "",
            "8": "",
            "9": "",
            "0": "",
            "m": "",
            "M": "",
            "ã¡": "",
            "å¹³": "",
            "æ–¹": "",
            "ç±³": "",
        }

        for item in room_text_items:
            original_text = item["text"]
            bbox = item["bbox"]
            confidence = item.get("confidence", 1.0)

            # ===== åæ ‡ç¼©æ”¾ä¿®æ­£ =====
            # OCRé˜¶æ®µå›¾åƒè¢«æ”¾å¤§2å€(æˆ–å…¶ä»–æ¯”ä¾‹)ï¼Œå½“å‰bboxä»å¤„äºOCRåæ ‡ç³»ï¼Œéœ€è¦æ˜ å°„å›åŸå›¾
            ocr_w = item.get('ocr_width')
            ocr_h = item.get('ocr_height')
            if ocr_w and ocr_h:
                scale_x = ocr_w / original_img.shape[1]
                scale_y = ocr_h / original_img.shape[0]
            else:
                # å›é€€ï¼šå¦‚æœåæ ‡æ˜æ˜¾è¶…å‡ºåŸå›¾å°ºå¯¸ï¼Œå‡è®¾æ”¾å¤§2å€
                scale_x = scale_y = 2.0 if (bbox[0] > original_img.shape[1] or bbox[1] > original_img.shape[0]) else 1.0

            x, y, w, h = bbox
            if scale_x != 1.0 or scale_y != 1.0:
                x = int(x / scale_x)
                y = int(y / scale_y)
                w = max(1, int(w / scale_x))
                h = max(1, int(h / scale_y))
            # ä½¿ç”¨ç¼©æ”¾åçš„å±€éƒ¨å˜é‡ï¼Œä¸ä¿®æ”¹åŸå§‹æ•°æ®

            # 1. è·³è¿‡ç©ºæ–‡æœ¬æˆ–çº¯ç©ºç™½
            if not original_text or not original_text.strip():
                continue

            # 2. è·³è¿‡ä½ç½®ä¿¡åº¦çš„å•å­—ç¬¦ï¼ˆè¿™äº›é€šå¸¸æ˜¯å™ªéŸ³ï¼‰
            if len(original_text.strip()) == 1 and confidence < 0.8:
                continue

            # 3. è·³è¿‡çº¯æ•°å­—ã€çº¯ç¬¦å·æ–‡æœ¬
            cleaned_for_check = original_text.strip()
            if cleaned_for_check.isdigit() or not any(c.isalpha() or c in 'å¨æˆ¿å®¢å…å§å®¤å«ç”Ÿé—´é˜³å°ä¹¦é¤å‚¨è¡£ç„èµ°å»Šè¿‡é“å…¥æˆ·' for c in cleaned_for_check):
                continue

            # 4. è·³è¿‡é•¿åº¦è¿‡çŸ­ä¸”ä¸åŒ…å«æˆ¿é—´å…³é”®è¯çš„æ–‡æœ¬
            if len(cleaned_for_check) < 2 and not any(keyword in cleaned_for_check for keyword in ['å¨', 'å«', 'å®¢', 'å§', 'é˜³', 'ä¹¦', 'é¤']):
                continue

            # 5. è·³è¿‡åŒ…å«æ˜æ˜¾ä¹±ç å­—ç¬¦çš„æ–‡æœ¬
            garbage_chars = {'ï¿½', 'â–¡', 'â– ', 'â–²', 'â–¼', 'â—†', 'â—', 'â—‹', 'â€»', 'â˜…', 'â˜†'}
            if any(char in original_text for char in garbage_chars):
                continue

            # 6. åº”ç”¨OCRä¿®æ­£
            display_text = ocr_corrections.get(original_text, original_text)

            # 7. å¦‚æœä¿®æ­£åä¸ºç©ºï¼Œåˆ™è·³è¿‡
            if not display_text or not display_text.strip():
                continue

            # 8. æœ€åæ£€æŸ¥ï¼šå¦‚æœä¿®æ­£åä»ç„¶æ˜¯å•å­—ç¬¦ä¸”ç½®ä¿¡åº¦ä¸é«˜ï¼Œè·³è¿‡
            if len(display_text.strip()) == 1 and confidence < 0.9:
                continue

            # ç¡®å®šæˆ¿é—´ç±»å‹å’Œé¢œè‰²
            color = (255, 255, 255)  # é»˜è®¤ç™½è‰²
            for room_type, room_color in room_colors.items():
                if any(keyword in display_text.lower() for keyword in [room_type.lower(),
                      {"å¨æˆ¿": "kitchen", "å«ç”Ÿé—´": "bathroom", "å®¢å…": "living",
                       "å§å®¤": "bedroom", "é˜³å°": "balcony", "ä¹¦æˆ¿": "study"}.get(room_type, "")]):
                    color = room_color
                    break

            # ç»˜åˆ¶æ–‡å­—è¾¹ç•Œæ¡†
            cv2.rectangle(ocr_img, (x, y), (x + w, y + h), color, 2)

            # æ ‡ç­¾æ–‡æœ¬å¤„ç†
            if original_text != display_text and display_text:
                label = f"{display_text} (ä¿®æ­£:{original_text})"
                label_color = (255, 165, 0)
            elif display_text:
                label = f"{display_text}"
                label_color = color
            else:
                continue

            font_scale = max(0.5, min(1.0, w / 100))
            thickness = max(1, int(font_scale * 2))

            has_chinese = any('\u4e00' <= c <= '\u9fff' for c in label)
            if has_chinese and CH_FONT_PATH:
                # PIL è·¯å¾„ï¼šåªæè¾¹ + åŠé€æ˜èƒŒæ™¯ï¼ˆé¿å…çº¯ç™½å—ï¼‰
                font_size = max(12, min(32, int(w * 0.5)))
                try:
                    pil_font = ImageFont.truetype(CH_FONT_PATH, font_size)
                except Exception:
                    pil_font = ImageFont.load_default()
                # è½¬ RGBA ä»¥å®ç°åŠé€æ˜
                pil_img = Image.fromarray(ocr_img)
                if pil_img.mode != 'RGBA':
                    pil_img = pil_img.convert('RGBA')
                draw = ImageDraw.Draw(pil_img, 'RGBA')
                text_bbox = draw.textbbox((0, 0), label, font=pil_font)
                tw = text_bbox[2] - text_bbox[0]
                th = text_bbox[3] - text_bbox[1]
                place_above = y - th - 6 >= 0
                if place_above:
                    text_x = x
                    text_y = y - th - 4
                else:
                    text_x = x
                    text_y = y + 2
                bg_x1 = text_x - 3
                bg_y1 = text_y - 2
                bg_x2 = text_x + tw + 3
                bg_y2 = text_y + th + 2
                # åŠé€æ˜èƒŒæ™¯ (ç™½ 30% é€æ˜)
                draw.rectangle([bg_x1, bg_y1, bg_x2, bg_y2], fill=(255, 255, 255, 70), outline=label_color + (255,), width=1)
                draw.text((text_x, text_y), label, font=pil_font, fill=label_color + (255,))
                # å›åˆ°BGR
                ocr_img = np.array(pil_img.convert('RGB'))
            else:
                # OpenCV è·¯å¾„ï¼šç”¨ alpha æ··åˆç”ŸæˆåŠé€æ˜èƒŒæ™¯
                text_size, baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)
                tw, th = text_size
                place_above = y - th - 6 >= 0
                if place_above:
                    text_x = x
                    text_y = y - 4
                    box_y1 = y - th - 6
                    box_y2 = y - 2
                else:
                    text_x = x
                    text_y = y + th + 2
                    box_y1 = y
                    box_y2 = y + th + 8
                box_x1 = x - 2
                box_x2 = x + tw + 4
                # è¾¹ç•Œè£å‰ª
                h_img, w_img = ocr_img.shape[:2]
                box_x1_c = max(0, box_x1); box_y1_c = max(0, box_y1)
                box_x2_c = min(w_img - 1, box_x2); box_y2_c = min(h_img - 1, box_y2)
                if box_x2_c > box_x1_c and box_y2_c > box_y1_c:
                    roi = ocr_img[box_y1_c:box_y2_c, box_x1_c:box_x2_c]
                    overlay = roi.copy()
                    overlay[:] = (255, 255, 255)
                    cv2.addWeighted(overlay, 0.3, roi, 0.7, 0, roi)
                    ocr_img[box_y1_c:box_y2_c, box_x1_c:box_x2_c] = roi
                cv2.rectangle(ocr_img, (box_x1, box_y1), (box_x2, box_y2), label_color, 1)
                cv2.putText(ocr_img, label, (text_x, text_y - 6 if place_above else text_y - 4), cv2.FONT_HERSHEY_SIMPLEX,
                            font_scale, label_color, thickness, cv2.LINE_AA)

        return ocr_img

    def _add_room_annotations(self, ax, room_info):
        """åœ¨å›¾ä¸Šæ·»åŠ æˆ¿é—´æ ‡æ³¨"""
        for room_type, room_list in room_info.items():
            for i, coords in enumerate(room_list):
                if coords["pixels"] > 0:
                    center_x, center_y = coords["center"]
                    bbox = coords["bbox"]

                    # æ ‡æ³¨æˆ¿é—´ä¸­å¿ƒç‚¹
                    ax.plot(center_x, center_y, "o", markersize=10, color="white",
                           markeredgecolor="black", markeredgewidth=2)

                    # æˆ¿é—´æ ‡æ³¨
                    if len(room_list) > 1:
                        label_text = f"{room_type}{i+1}\n({center_x},{center_y})"
                    else:
                        label_text = f"{room_type}\n({center_x},{center_y})"

                    ax.annotate(label_text, xy=(center_x, center_y), xytext=(10, 10),
                                textcoords="offset points", fontsize=10, fontweight="bold",
                                fontproperties=CH_FONT,
                                bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8),
                                arrowprops=dict(arrowstyle="->", connectionstyle="arc3,rad=0"))

                    # ç»˜åˆ¶è¾¹ç•Œæ¡†
                    x1, y1, x2, y2 = bbox
                    rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False,
                                       edgecolor="red", linewidth=2, linestyle="--")
                    ax.add_patch(rect)

    def _add_color_legend(self, fig):
        """æ·»åŠ é¢œè‰²å›¾ä¾‹ï¼ˆä¸å®é™…ç€è‰²ä¸¥æ ¼ä¸€è‡´ï¼‰

        ä¹‹å‰ç‰ˆæœ¬å›¾ä¾‹é¢œè‰²æ˜¯æ‰‹å†™/ç¤ºæ„è‰²ï¼Œå¯¼è‡´ä¸å®é™… floorplan_fuse_map_figure ä¸­çš„é¢œè‰²ä¸ä¸€è‡´ã€‚
        è¿™é‡Œç›´æ¥è¯»å– utils.rgb_ind_convertor.floorplan_fuse_map_figureï¼Œç¡®ä¿å®Œå…¨åŒæ­¥ã€‚
        """
        from utils.rgb_ind_convertor import floorplan_fuse_map_figure as _COLOR_MAP

        # æ ‡ç­¾ -> ä¸­æ–‡åç§°æ˜ å°„ï¼ˆåªå±•ç¤ºä¸»è¦æˆ¿å‹ + å¢™ä½“/å¼€å£ï¼‰
        label_name_map = {
            7: "å¨æˆ¿",
            2: "å«ç”Ÿé—´",
            3: "å®¢å…",
            4: "å§å®¤",
            6: "é˜³å°",
            8: "ä¹¦æˆ¿",
            9: "å¼€å£",
            10: "å¢™ä½“",
        }

        legend_elements = []
        ordered_labels = [7,2,3,4,6,8,9,10]
        print("ğŸ¨ å›¾ä¾‹åŒæ­¥æ£€æŸ¥: ")
        for label_id in ordered_labels:  # å›ºå®šæ’åºï¼Œæ–¹ä¾¿é˜…è¯»
            if label_id not in _COLOR_MAP:
                continue
            name = label_name_map.get(label_id, str(label_id))
            rgb = _COLOR_MAP[label_id]
            print(f"   - {name} (label {label_id}) é¢œè‰² RGB={rgb}")
            # è½¬ 0-1 èŒƒå›´ (matplotlib éœ€è¦ RGB é¡ºåºï¼›åŸæ˜ å°„å°±æ˜¯ RGB)
            color = np.array(rgb) / 255.0
            legend_elements.append(plt.Rectangle((0, 0), 1, 1, facecolor=color, label=name))

        fig.legend(
            handles=legend_elements,
            loc='upper center',
            bbox_to_anchor=(0.5, 0.02),
            ncol=len(legend_elements),
            fontsize=12,
            prop=CH_FONT,
            frameon=True,
        )

    def generate_results(self, ai_raw_result, ocr_result, fusion_result, final_result,
                         original_img, original_size, output_path, room_text_items):
        """ç”Ÿæˆå››å®«æ ¼å¯¹æ¯”ç»“æœå›¾åƒï¼ˆä¿®æ­£ä¸­æ–‡å­—ä½“æ˜¾ç¤ºä¸º ? çš„é—®é¢˜ï¼‰ã€‚"""
        print("ğŸ¨ ç”Ÿæˆå››å®«æ ¼å¯¹æ¯”ç»“æœå›¾åƒ...")

        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 16))

        room_info = self._extract_room_coordinates(final_result, original_size, room_text_items)
        self.last_room_info = room_info

        # AI åˆ†å‰²
        ai_colored = self._apply_color_mapping(ai_raw_result, original_size)
        ax1.imshow(cv2.addWeighted(original_img, 0.5, ai_colored, 0.5, 0))
        ax1.set_title("ğŸ¤– AIè¯­ä¹‰åˆ†å‰²ç»“æœ", fontsize=14, fontweight="bold", fontproperties=CH_FONT)
        ax1.grid(True, alpha=0.3)
        ax1.set_xlabel("Xåæ ‡ (åƒç´ )", fontsize=12, fontproperties=CH_FONT)
        ax1.set_ylabel("Yåæ ‡ (åƒç´ )", fontsize=12, fontproperties=CH_FONT)

        # OCR
        ocr_colored = self._visualize_ocr_results(original_img, room_text_items)
        ax2.imshow(ocr_colored)
        ax2.set_title("ğŸ” OCRæ–‡å­—è¯†åˆ«ç»“æœ", fontsize=14, fontweight="bold", fontproperties=CH_FONT)
        ax2.grid(True, alpha=0.3)
        ax2.set_xlabel("Xåæ ‡ (åƒç´ )", fontsize=12, fontproperties=CH_FONT)
        ax2.set_ylabel("Yåæ ‡ (åƒç´ )", fontsize=12, fontproperties=CH_FONT)

        # èåˆ
        fusion_colored = self._apply_color_mapping(fusion_result, original_size)
        ax3.imshow(cv2.addWeighted(original_img, 0.5, fusion_colored, 0.5, 0))
        ax3.set_title("ğŸ”— AI+OCRèåˆç»“æœ", fontsize=14, fontweight="bold", fontproperties=CH_FONT)
        ax3.grid(True, alpha=0.3)
        ax3.set_xlabel("Xåæ ‡ (åƒç´ )", fontsize=12, fontproperties=CH_FONT)
        ax3.set_ylabel("Yåæ ‡ (åƒç´ )", fontsize=12, fontproperties=CH_FONT)

        # æœ€ç»ˆ
        final_colored = self._apply_color_mapping(final_result, original_size)
        final_overlay = cv2.addWeighted(original_img, 0.5, final_colored, 0.5, 0)
        ax4.imshow(final_overlay)
        ax4.set_title("âœ… åˆç†æ€§éªŒè¯åæœ€ç»ˆç»“æœ", fontsize=14, fontweight="bold", fontproperties=CH_FONT)
        ax4.grid(True, alpha=0.3)
        ax4.set_xlabel("Xåæ ‡ (åƒç´ )", fontsize=12, fontproperties=CH_FONT)
        ax4.set_ylabel("Yåæ ‡ (åƒç´ )", fontsize=12, fontproperties=CH_FONT)

        self._add_room_annotations(ax4, room_info)
        self._add_color_legend(fig)
        plt.tight_layout()

        os.makedirs("output", exist_ok=True)
        comparison_output = f"output/{output_path}_coordinate_result.png"
        plt.savefig(comparison_output, dpi=300, bbox_inches="tight")
        print(f"ğŸ“Š å››å®«æ ¼å¯¹æ¯”ç»“æœå·²ä¿å­˜: {comparison_output}")

        # å•ç‹¬æœ€ç»ˆç»“æœ
        plt.figure(figsize=(12, 8))
        plt.imshow(final_overlay)
        plt.title("æˆ¿é—´æ£€æµ‹æœ€ç»ˆç»“æœ", fontsize=16, fontweight="bold", fontproperties=CH_FONT)
        plt.grid(True, alpha=0.3)
        plt.xlabel("Xåæ ‡ (åƒç´ )", fontsize=12, fontproperties=CH_FONT)
        plt.ylabel("Yåæ ‡ (åƒç´ )", fontsize=12, fontproperties=CH_FONT)
        for room_type, room_list in room_info.items():
            for i, coords in enumerate(room_list):
                if coords["pixels"] <= 0:
                    continue
                center_x, center_y = coords["center"]
                x1, y1, x2, y2 = coords["bbox"]
                plt.plot(center_x, center_y, "o", markersize=10, color="white",
                         markeredgecolor="black", markeredgewidth=2)
                if len(room_list) > 1:
                    label_text = f"{room_type}{i+1}\n({center_x},{center_y})"
                else:
                    label_text = f"{room_type}\n({center_x},{center_y})"
                plt.annotate(label_text, xy=(center_x, center_y), xytext=(10, 10),
                             textcoords="offset points", fontsize=10, fontweight="bold",
                             fontproperties=CH_FONT,
                             bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8),
                             arrowprops=dict(arrowstyle="->", connectionstyle="arc3,rad=0"))
                rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False,
                                     edgecolor="red", linewidth=2, linestyle="--")
                plt.gca().add_patch(rect)
        standard_output = f"output/{output_path}_result.png"
        plt.savefig(standard_output, dpi=300, bbox_inches="tight")
        print(f"ğŸ“¸ æ ‡å‡†ç»“æœå·²ä¿å­˜: {standard_output}")
        plt.close('all')

        # ====== å¯¼å‡ºè¾¹ç•Œæ–‡ä»¶ï¼ˆå•ç‹¬ï¼‰======
        try:
            boundary_labeled = self._add_boundary_detection_cached(final_result.copy())  # åœ¨ 512x512 ç©ºé—´
            # æå–ä»…åŒ…å« 9/10 æ ‡ç­¾çš„è¾¹ç•Œæ©è†œ
            boundary_only = np.zeros_like(boundary_labeled)
            boundary_only[np.isin(boundary_labeled, [9, 10])] = boundary_labeled[np.isin(boundary_labeled, [9, 10])]

            # ç”Ÿæˆå½©è‰²è¾¹ç•Œå›¾ (ç™½åº• + å¼€å£æ´‹çº¢ + å¢™ä½“é»‘)
            boundary_color = np.full((boundary_only.shape[0], boundary_only.shape[1], 3), 255, dtype=np.uint8)
            boundary_color[boundary_only == 9] = [255, 60, 128]   # openings
            boundary_color[boundary_only == 10] = [0, 0, 0]       # walls

            # æ”¾å¤§å›åŸå§‹å°ºå¯¸
            boundary_color_resized = cv2.resize(boundary_color, original_size, interpolation=cv2.INTER_NEAREST)
            boundary_mask_binary = np.zeros((boundary_only.shape[0], boundary_only.shape[1]), dtype=np.uint8)
            boundary_mask_binary[boundary_only == 10] = 255  # å¢™ä½“
            boundary_mask_binary[boundary_only == 9] = 128   # å¼€å£
            boundary_mask_resized = cv2.resize(boundary_mask_binary, original_size, interpolation=cv2.INTER_NEAREST)

            boundary_png = f"output/{output_path}_boundary.png"
            boundary_mask_png = f"output/{output_path}_boundary_mask.png"
            cv2.imwrite(boundary_png, cv2.cvtColor(boundary_color_resized, cv2.COLOR_RGB2BGR))
            cv2.imwrite(boundary_mask_png, boundary_mask_resized)
            print(f"ğŸ§± è¾¹ç•Œå½©è‰²å›¾å·²ä¿å­˜: {boundary_png}")
            print(f"ğŸ§± è¾¹ç•Œæ©è†œå›¾å·²ä¿å­˜: {boundary_mask_png}")

            # è¿½åŠ ï¼šå¢™ä½“ + å¼€å£ çŸ¢é‡åŒ– & SVG/DXF å¯¼å‡º
            try:
                vec_data = self._vectorize_walls(boundary_mask_binary, original_size)
                svg_out = f"output/{output_path}_walls.svg"
                dxf_out = f"output/{output_path}_walls.dxf"
                self._export_walls_svg(svg_out, vec_data, original_size)
                self._export_walls_dxf(dxf_out, vec_data, original_size)
                print(f"ğŸ—ºï¸ çŸ¢é‡å¢™ä½“å¯¼å‡º: SVG {len(vec_data['walls_segments'])} æ®µ / DXF å¤šæ®µçº¿ {len(vec_data['walls_polylines'])}")
            except Exception as _ve:
                print(f"âš ï¸ çŸ¢é‡å¢™ä½“å¯¼å‡ºå¤±è´¥: {_ve}")
        except Exception as e:
            print(f"âš ï¸ è¾¹ç•Œå¯¼å‡ºå¤±è´¥: {e}")

        # ç»“æ„åŒ–JSONå¯¼å‡º
        try:
            json_path = f"output/{output_path}_result.json"
            self._export_room_json(room_info, original_size, json_path, room_text_items, image_output=standard_output)
            print(f"ğŸ§¾ ç»“æ„åŒ–æˆ¿é—´æ•°æ®å·²ä¿å­˜: {json_path}")
        except Exception as e:
            print(f"âš ï¸ JSONå¯¼å‡ºå¤±è´¥: {e}")
        return standard_output

    def _export_room_json(self, room_info, original_size, json_path, ocr_items, image_output=None):
        """å¯¼å‡ºæˆ¿é—´è¯†åˆ«ç»“æœä¸ºJSONï¼Œä¾¿äºåç»­é£æ°´/ç©ºé—´åˆ†æã€‚

        JSONç»“æ„:
        {
          "meta": { åŸå›¾å°ºå¯¸/æ—¶é—´/è¾“å‡ºå›¾åƒç­‰ },
          "rooms": [
             {
               "type": "å§å®¤",
               "index": 1,              # åŒç±»å‹åºå·ï¼ˆä»1èµ·ï¼‰
               "label_id": 4,
               "center": {"x":123, "y":245},
               "center_normalized": {"x":0.35, "y":0.62},
               "bbox": {"x1":..,"y1":..,"x2":..,"y2":..,"width":..,"height":..},
               "area_pixels": 3456,      # ç›®å‰åŸºäºbboxåƒç´ ä¼°è®¡ï¼ˆè‹¥éœ€çœŸå®maské¢ç§¯å¯åç»­æ‰©å±•ï¼‰
               "text_raw": "å§å®¤",
               "confidence": 0.91,
               "distance_to_center": 210.4,
               "direction_8": "ä¸œåŒ—"     # ä»¥å›¾åƒä¸Šæ–¹ä¸ºåŒ—ï¼Œå·¦ä¸ºè¥¿
             }, ...
          ]
        }
        """
        orig_w, orig_h = original_size
        img_cx, img_cy = orig_w / 2.0, orig_h / 2.0

        # æˆ¿é—´ä¸­æ–‡åˆ°labelæ˜ å°„ï¼ˆä¸ _extract_room_coordinates ä¸­ä¸€è‡´ï¼‰
        name_to_label = {"å¨æˆ¿":7, "å«ç”Ÿé—´":2, "å®¢å…":3, "å§å®¤":4, "é˜³å°":6, "ä¹¦æˆ¿":8}

        def direction_from_vector(dx, dy):
            # å›¾åƒåæ ‡: yå‘ä¸‹ -> åŒ—åœ¨ä¸Šæ–¹ => dy<0 ä¸ºåŒ—
            angle = (np.degrees(np.arctan2(-dy, dx)) + 360) % 360  # 0=ä¸œ, 90=åŒ—
            dirs = ["ä¸œ", "ä¸œåŒ—", "åŒ—", "è¥¿åŒ—", "è¥¿", "è¥¿å—", "å—", "ä¸œå—"]
            idx = int(((angle + 22.5) % 360) / 45)
            return dirs[idx]

        rooms_json = []
        for room_type, room_list in room_info.items():
            for idx, info in enumerate(room_list, start=1):
                if info.get('pixels', 0) <= 0:
                    continue
                cx, cy = info['center']
                x1, y1, x2, y2 = info['bbox']
                width = info.get('width', x2 - x1 + 1)
                height = info.get('height', y2 - y1 + 1)
                # ä½¿ç”¨bboxé¢ç§¯ä½œä¸ºè¿‘ä¼¼
                area_pixels = width * height
                dx = cx - img_cx
                dy = cy - img_cy
                dist = float(np.hypot(dx, dy))
                direction = direction_from_vector(dx, dy)
                rooms_json.append({
                    "type": room_type,
                    "index": idx,
                    "label_id": name_to_label.get(room_type, -1),
                    "center": {"x": int(cx), "y": int(cy)},
                    "center_normalized": {"x": round(cx / orig_w, 4), "y": round(cy / orig_h, 4)},
                    "bbox": {"x1": int(x1), "y1": int(y1), "x2": int(x2), "y2": int(y2), "width": int(width), "height": int(height)},
                    "area_pixels": int(area_pixels),
                    "text_raw": info.get('text', ''),
                    "confidence": round(float(info.get('confidence', 0.0)), 4),
                    "distance_to_center": round(dist, 2),
                    "direction_8": direction,
                })

        data = {
            "meta": {
                "timestamp": datetime.utcnow().isoformat() + 'Z',
                "image_width": orig_w,
                "image_height": orig_h,
                "rooms_detected": len(rooms_json),
                "output_image": image_output,
                "note": "æ–¹å‘åŸºäºå›¾åƒä¸ŠåŒ—ä¸‹å—å·¦è¥¿å³ä¸œçš„é»˜è®¤å‡è®¾; è‹¥å›¾çº¸æœå‘ä¸åŒéœ€è°ƒæ•´ã€‚"
            },
            "rooms": rooms_json
        }

        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    def _add_boundary_detection(self, enhanced):
        """æ”¹è¿›ç‰ˆå¢™ä½“/è¾¹ç•Œæå– (V2+ æ‰©å±•)"""
        print("ğŸ”² è¾¹ç•Œé‡æ„(V2+ æ‰©å±•: è½®å»“ç®€åŒ– + ç›´çº¿æ‹Ÿåˆ)...")
        arr = enhanced.copy()
        room_labels = {2,3,4,6,7,8}
        wall_labels = {9,10}
        original_wall_mask = np.isin(arr, list(wall_labels))

        # 1) å¹³æ»‘ & æå°ç¢ç‰‡è¿‡æ»¤ + è½®å»“ç®€åŒ–
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))
        smoothed = arr.copy()
        MIN_ROOM_COMPONENT = 25
        for lbl in room_labels:
            mask = (arr==lbl).astype(np.uint8)
            if mask.sum()==0:
                continue
            num_c, lab_c, stats_c, _ = cv2.connectedComponentsWithStats(mask, connectivity=4)
            for cid in range(1, num_c):
                if stats_c[cid, cv2.CC_STAT_AREA] < MIN_ROOM_COMPONENT:
                    mask[lab_c==cid] = 0
            closed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=1)
            opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel, iterations=1)
            try:
                contours,_ = cv2.findContours(opened, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                simp = np.zeros_like(opened)
                for cnt in contours:
                    peri = cv2.arcLength(cnt, True)
                    eps = max(1.0, 0.005*peri)
                    approx = cv2.approxPolyDP(cnt, eps, True)
                    cv2.fillPoly(simp,[approx],1)
                opened = simp
            except Exception:
                pass
            smoothed[opened==1] = lbl
        smoothed[original_wall_mask] = arr[original_wall_mask]

        # 2) æ ‡ç­¾å·®åˆ†
        padded = np.pad(smoothed,1,mode='edge')
        center = padded[1:-1,1:-1]
        up = padded[0:-2,1:-1]; down = padded[2:,1:-1]; left = padded[1:-1,0:-2]; right = padded[1:-1,2:]
        def diff_mask(neigh):
            return (center!=neigh) & (np.isin(center,list(room_labels)) | np.isin(neigh,list(room_labels)) | (center==0) | (neigh==0))
        boundary_candidates = diff_mask(up)|diff_mask(down)|diff_mask(left)|diff_mask(right)
        candidate_mask = boundary_candidates.astype(np.uint8)

        # 3) ç»†åŒ–
        def zhang_suen_thinning(bin_img):
            img = bin_img.copy().astype(np.uint8)
            changed=True
            while changed:
                changed=False
                to_remove=[]
                for y in range(1,img.shape[0]-1):
                    for x in range(1,img.shape[1]-1):
                        if img[y,x]==1:
                            P2=img[y-1,x];P3=img[y-1,x+1];P4=img[y,x+1];P5=img[y+1,x+1];P6=img[y+1,x];P7=img[y+1,x-1];P8=img[y,x-1];P9=img[y-1,x-1]
                            nbr=[P2,P3,P4,P5,P6,P7,P8,P9]; cnt=sum(nbr)
                            if 2<=cnt<=6:
                                trans=0
                                for i in range(8):
                                    if nbr[i]==0 and nbr[(i+1)%8]==1: trans+=1
                                if trans==1 and (P2*P4*P6)==0 and (P4*P6*P8)==0: to_remove.append((y,x))
                if to_remove:
                    changed=True
                    for y,x in to_remove: img[y,x]=0
                to_remove=[]
                for y in range(1,img.shape[0]-1):
                    for x in range(1,img.shape[1]-1):
                        if img[y,x]==1:
                            P2=img[y-1,x];P3=img[y-1,x+1];P4=img[y,x+1];P5=img[y+1,x+1];P6=img[y+1,x];P7=img[y+1,x-1];P8=img[y,x-1];P9=img[y-1,x-1]
                            nbr=[P2,P3,P4,P5,P6,P7,P8,P9]; cnt=sum(nbr)
                            if 2<=cnt<=6:
                                trans=0
                                for i in range(8):
                                    if nbr[i]==0 and nbr[(i+1)%8]==1: trans+=1
                                if trans==1 and (P2*P4*P8)==0 and (P2*P6*P8)==0: to_remove.append((y,x))
                if to_remove:
                    changed=True
                    for y,x in to_remove: img[y,x]=0
            return img
        skeleton = zhang_suen_thinning(candidate_mask)

        # Hough è¡¥å¼º
        try:
            ls = (candidate_mask*255).astype(np.uint8)
            lines = cv2.HoughLinesP(ls,1,np.pi/180,threshold=18,minLineLength=14,maxLineGap=4)
            if lines is not None:
                hmask = np.zeros_like(skeleton)
                for l in lines[:1500]:
                    x1,y1,x2,y2 = l[0]; cv2.line(hmask,(x1,y1),(x2,y2),1,1)
                skeleton = ((skeleton==1)|(hmask==1)).astype(np.uint8)
                print(f"   ğŸ“ Hough ç›´çº¿è¡¥å¼º: {len(lines)} æ¡")
        except Exception as _e:
            print(f"   âš ï¸ Hough è·³è¿‡: {_e}")

        # 4) å¸é™„ä¸åŠ ç²—
        ORTHO_TOL=15; allow_diagonal=True
        skel_arr=skeleton.copy(); new_skel=np.zeros_like(skel_arr)
        num_s,lab_s,stats_s,_ = cv2.connectedComponentsWithStats(skel_arr.astype(np.uint8),connectivity=8)
        for sid in range(1,num_s):
            comp=(lab_s==sid); ys,xs=np.where(comp)
            if xs.size<3: new_skel[comp]=1; continue
            xc=xs.mean(); yc=ys.mean(); xz=xs-xc; yz=ys-yc
            cov=np.cov(np.vstack((xz,yz))); eigvals,eigvecs=np.linalg.eig(cov)
            vx,vy=eigvecs[:,np.argmax(eigvals)]; angle=(np.degrees(np.arctan2(vy,vx))+180)%180
            if angle<ORTHO_TOL or angle>180-ORTHO_TOL:
                yline=int(round(yc)); new_skel[yline, xs.min():xs.max()+1]=1
            elif abs(angle-90)<ORTHO_TOL:
                xline=int(round(xc)); new_skel[ys.min():ys.max()+1, xline]=1
            else:
                if allow_diagonal: new_skel[comp]=1
                else:
                    for ux in np.unique(xs):
                        yv=ys[xs==ux]; new_skel[int(np.median(yv)), ux]=1
        skeleton=new_skel

        if np.any(skeleton):
            dil=cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))
            thick=cv2.dilate(skeleton.astype(np.uint8),dil,iterations=1)
        else:
            thick=skeleton

        def merge_small_gaps(m):
            merged=m.copy()
            # è¡Œ
            for y in range(merged.shape[0]):
                xs=np.where(merged[y]==1)[0]
                if xs.size==0: continue
                pv=xs[0]
                for x in xs[1:]:
                    gap=x-pv-1
                    if 0<gap<=2: merged[y,pv+1:x]=1
                    pv=x
            # åˆ—
            for x in range(merged.shape[1]):
                ys=np.where(merged[:,x]==1)[0]
                if ys.size==0: continue
                pv=ys[0]
                for y in ys[1:]:
                    gap=y-pv-1
                    if 0<gap<=2: merged[pv+1:y,x]=1
                    pv=y
            return merged
        thick=merge_small_gaps(thick.astype(np.uint8))

        def close_endpoints(m):
            lm=m.copy(); H,W=lm.shape; dirs=[(1,0),(-1,0),(0,1),(0,-1)]
            endpoints=[]
            for y in range(H):
                for x in range(W):
                    if lm[y,x]==1:
                        deg=0
                        for dx,dy in dirs:
                            nx,ny=x+dx,y+dy
                            if 0<=nx<W and 0<=ny<H and lm[ny,nx]==1: deg+=1
                        if deg==1: endpoints.append((x,y))
            used=set()
            for i,(x1,y1) in enumerate(endpoints):
                if i in used: continue
                best=None; bestd=1e9
                for j,(x2,y2) in enumerate(endpoints):
                    if j<=i or j in used: continue
                    dx=abs(x2-x1); dy=abs(y2-y1)
                    if max(dx,dy)<=5 and ((y1==y2) or (x1==x2) or (dx+dy)<=5):
                        d=dx+dy
                        if d<bestd: bestd=d; best=j
                if best is not None:
                    x2,y2=endpoints[best]
                    if y1==y2: lm[y1,min(x1,x2):max(x1,x2)+1]=1
                    elif x1==x2: lm[min(y1,y2):max(y1,y2)+1,x1]=1
                    else:
                        lm[y1,min(x1,x2):max(x1,x2)+1]=1
                        lm[min(y1,y2):max(y1,y2)+1,x2]=1
                    used.add(i); used.add(best)
            return lm
        thick=close_endpoints(thick)

        # 5) å¢™ä½“ç˜¦èº« + éª¨æ¶èåˆ
        wall_mask_initial=(arr==10).astype(np.uint8)
        num,labels_im,stats,_=cv2.connectedComponentsWithStats(wall_mask_initial,connectivity=4)
        large_perimeter_mask=np.zeros_like(wall_mask_initial)
        for comp in range(1,num):
            area=stats[comp,cv2.CC_STAT_AREA]
            if area>400:
                comp_mask=(labels_im==comp).astype(np.uint8)
                eroded=cv2.erode(comp_mask,kernel,iterations=1)
                perimeter=comp_mask-eroded
                large_perimeter_mask[perimeter==1]=1
            else:
                large_perimeter_mask[labels_im==comp]=1

        new_arr=arr.copy()
        new_arr[new_arr==10]=0
        new_arr[large_perimeter_mask==1]=10
        add_mask=(thick==1) & (~np.isin(new_arr,[9,10]))
        new_arr[add_mask]=10

        # 6) å™ªç‚¹æ¸…ç†
        wall_mask_final=(new_arr==10).astype(np.uint8)
        num2,labels2,stats2,_=cv2.connectedComponentsWithStats(wall_mask_final,connectivity=8)
        removed=0
        for comp in range(1,num2):
            area=stats2[comp,cv2.CC_STAT_AREA]
            if area<3:
                removed+=area
                new_arr[labels2==comp]=0
        added=int(add_mask.sum())
        print(f"âœ… è¾¹ç•Œé‡æ„å®Œæˆ: æ–°å¢å¢™ä½“ {added} åƒç´ , æ¸…ç†å™ªç‚¹ {removed} åƒç´ , å¤§å—ç»„ä»¶ {num-1} -> {np.unique(labels2).size-1}")
        return new_arr

    def _add_boundary_detection_cached(self, enhanced):
        """å¸¦ç¼“å­˜åŒ…è£…ï¼Œé¿å…åŒä¸€ label å›¾å¤šæ¬¡ç»†åŒ–å¯¼è‡´ç¢è£‚"""
        try:
            import hashlib
            key = hashlib.md5(enhanced.tobytes()).hexdigest()
        except Exception:
            key = str(id(enhanced))
        if key in self._boundary_cache:
            return self._boundary_cache[key]
        result = self._add_boundary_detection(enhanced)
        self._boundary_cache[key] = result
        return result

    # ===== çŸ¢é‡åŒ–: ä»å¢™ä½“äºŒå€¼å›¾æå–çº¿æ®µå¹¶å¯¼å‡º SVG =====
    def _vectorize_walls(self, boundary_mask_binary, original_size):
        """è¿”å›å­—å…¸: {walls_segments, walls_polylines, openings_segments} (å‡å·²ç¼©æ”¾åˆ°åŸå°ºå¯¸)"""
        import numpy as np, cv2, math
        ow,oh = original_size
        wall_mask_512 = (boundary_mask_binary==255).astype(np.uint8)
        open_mask_512 = (boundary_mask_binary==128).astype(np.uint8)

        def skeletonize(mask):
            skel = mask.copy()
            def thin_once(img):
                h,w=img.shape; remove=[]
                for y in range(1,h-1):
                    for x in range(1,w-1):
                        if img[y,x]==1:
                            P2=img[y-1,x];P3=img[y-1,x+1];P4=img[y,x+1];P5=img[y+1,x+1];P6=img[y+1,x];P7=img[y+1,x-1];P8=img[y,x-1];P9=img[y-1,x-1]
                            nbr=[P2,P3,P4,P5,P6,P7,P8,P9]; cnt=sum(nbr)
                            if 2<=cnt<=6:
                                trans=0
                                for i in range(8):
                                    if nbr[i]==0 and nbr[(i+1)%8]==1: trans+=1
                                if trans==1 and (P2*P4*P6)==0 and (P4*P6*P8)==0:
                                    remove.append((y,x))
                for (y,x) in remove: img[y,x]=0
                return len(remove)>0
            it=0
            while thin_once(skel) and it<8: it+=1
            return skel

        def chains_from_skel(skel):
            h,w=skel.shape; visited=np.zeros_like(skel,bool)
            dirs=[(-1,0),(1,0),(0,-1),(0,1),(-1,-1),(-1,1),(1,-1),(1,1)]
            chains=[]
            for y in range(h):
                for x in range(w):
                    if skel[y,x]==1 and not visited[y,x]:
                        stack=[(x,y)]; visited[y,x]=True; pts=[]
                        while stack:
                            cx,cy=stack.pop(); pts.append((cx,cy))
                            for dx,dy in dirs:
                                nx,ny=cx+dx,cy+dy
                                if 0<=nx<w and 0<=ny<h and skel[ny,nx]==1 and not visited[ny,nx]:
                                    visited[ny,nx]=True; stack.append((nx,ny))
                        if len(pts)>=3: chains.append(pts)
            return chains

        def rdp(points, eps=1.8):
            if len(points)<3: return points
            x1,y1=points[0]; x2,y2=points[-1]; A=np.array([x2-x1,y2-y1]); L=np.linalg.norm(A)
            if L==0: dists=[0]*len(points)
            else:
                dists=[]
                for (x,y) in points:
                    v=np.array([x-x1,y-y1]); proj=(v@A)/L if L else 0
                    proj_pt=np.array([x1,y1]) + (proj/L)*A if L else np.array([x1,y1])
                    dists.append(np.linalg.norm(np.array([x,y])-proj_pt))
            idx=int(np.argmax(dists))
            if dists[idx]>eps:
                return rdp(points[:idx+1],eps)[:-1]+rdp(points[idx:],eps)
            return [points[0],points[-1]]

        def chains_to_segments(chains):
            segs=[]
            for c in chains:
                c_sorted=sorted(c)
                simp=rdp(c_sorted)
                for i in range(len(simp)-1):
                    x1,y1=simp[i]; x2,y2=simp[i+1]
                    if (x1,y1)!=(x2,y2): segs.append((x1,y1,x2,y2))
            return segs

        def merge_colinear(segments, ang_tol=6, dist_tol=4):
            segments=list(segments); merged=True
            def colinear(a,b):
                x1,y1,x2,y2=a; x3,y3,x4,y4=b
                v1=np.array([x2-x1,y2-y1]); v2=np.array([x4-x3,y4-y3])
                n1=np.linalg.norm(v1); n2=np.linalg.norm(v2)
                if n1==0 or n2==0: return False
                ang=math.degrees(math.acos(np.clip((v1@v2)/(n1*n2),-1,1)))
                if ang>ang_tol: return False
                for p in [(x1,y1),(x2,y2)]:
                    for q in [(x3,y3),(x4,y4)]:
                        if ( (p[0]-q[0])**2+(p[1]-q[1])**2 )**0.5 < dist_tol: return True
                return False
            while merged:
                merged=False; out=[]; used=[False]*len(segments)
                for i,a in enumerate(segments):
                    if used[i]: continue
                    ax1,ay1,ax2,ay2=a; vax=np.array([ax2-ax1, ay2-ay1])
                    for j,b in enumerate(segments):
                        if j<=i or used[j]: continue
                        if colinear(a,b):
                            bx1,by1,bx2,by2=b
                            pts=[(ax1,ay1),(ax2,ay2),(bx1,by1),(bx2,by2)]
                            if abs(vax[0])>=abs(vax[1]): pts=sorted(pts,key=lambda p:p[0])
                            else: pts=sorted(pts,key=lambda p:p[1])
                            ax1,ay1=pts[0]; ax2,ay2=pts[-1]
                            used[j]=True; merged=True
                    used[i]=True; out.append((ax1,ay1,ax2,ay2))
                segments=out
            return segments

        def angle_snap(segments, ang_set=(0,45,90,135), tol=12):
            snapped=[]
            for (x1,y1,x2,y2) in segments:
                dx=x2-x1; dy=y2-y1
                if dx==0 and dy==0: continue
                ang= (math.degrees(math.atan2(dy,dx)) + 180) % 180
                best=None; best_diff=999
                for a in ang_set:
                    diff=min(abs(ang-a), 180-abs(ang-a))
                    if diff<best_diff: best_diff=diff; best=a
                if best_diff<=tol:
                    # ä»¥ä¸­ç‚¹ & åŸé•¿åº¦é‡æ–°æ„é€ 
                    L=(dx*dx+dy*dy)**0.5
                    cx=(x1+x2)/2; cy=(y1+y2)/2
                    rad=math.radians(best)
                    hx=(L/2)*math.cos(rad); hy=(L/2)*math.sin(rad)
                    nx1=cx-hx; ny1=cy-hy; nx2=cx+hx; ny2=cy+hy
                    snapped.append((int(round(nx1)),int(round(ny1)),int(round(nx2)),int(round(ny2))))
                else:
                    snapped.append((x1,y1,x2,y2))
            return snapped

        def segments_to_polylines(segments, join_tol=4):
            # æ„é€ ç«¯ç‚¹å›¾
            pts=[]
            for (x1,y1,x2,y2) in segments: pts.extend([(x1,y1),(x2,y2)])
            # å»é‡
            uniq=[]
            for p in pts:
                if not any((abs(p[0]-q[0])<=1 and abs(p[1]-q[1])<=1) for q in uniq): uniq.append(p)
            # æ˜ å°„
            def find_idx(p):
                for i,q in enumerate(uniq):
                    if abs(p[0]-q[0])<=1 and abs(p[1]-q[1])<=1: return i
                uniq.append(p); return len(uniq)-1
            adj={i:set() for i in range(len(uniq))}
            for (x1,y1,x2,y2) in segments:
                i1=find_idx((x1,y1)); i2=find_idx((x2,y2))
                adj[i1].add(i2); adj[i2].add(i1)
            polylines=[]; visited=set()
            for start in adj:
                if start in visited: continue
                # çº¿æ€§é“¾/ç¯éå†
                stack=[start]; current=[]
                while stack:
                    v=stack.pop();
                    if v in visited: continue
                    visited.add(v); current.append(uniq[v])
                    for nb in adj[v]:
                        if nb not in visited: stack.append(nb)
                if len(current)>=2: polylines.append(sorted(current))
            return polylines

        def scale_segments(segs):
            scaled=[]
            for (x1,y1,x2,y2) in segs:
                sx1=int(round(x1/512*ow)); sy1=int(round(y1/512*oh))
                sx2=int(round(x2/512*ow)); sy2=int(round(y2/512*oh))
                if (sx1,sy1)!=(sx2,sy2): scaled.append((sx1,sy1,sx2,sy2))
            return scaled

        # ========== å¢™ä½“å¤„ç† ==========
        wall_skel = skeletonize(wall_mask_512)
        wall_chains = chains_from_skel(wall_skel)
        wall_segments = chains_to_segments(wall_chains)
        wall_segments = merge_colinear(angle_snap(wall_segments))
        wall_polylines = segments_to_polylines(wall_segments)
        wall_segments_scaled = scale_segments(wall_segments)

        # ========== å¼€å£å¤„ç†ï¼ˆç®€å•ï¼šç›´æ¥éª¨æ¶æå–ï¼‰ ==========
        open_skel = skeletonize(open_mask_512) if open_mask_512.sum()>0 else open_mask_512
        open_chains = chains_from_skel(open_skel) if open_mask_512.sum()>0 else []
        open_segments = chains_to_segments(open_chains)
        open_segments = merge_colinear(angle_snap(open_segments))
        open_segments_scaled = scale_segments(open_segments)

        return {
            'walls_segments': wall_segments_scaled,
            'walls_polylines': wall_polylines,  # æœªç¼©æ”¾ç‚¹é›†åˆ(512åæ ‡)å¯åç»­åˆ©ç”¨
            'openings_segments': open_segments_scaled
        }

    def _export_walls_svg(self, path, vec_data, original_size):
        ow,oh = original_size
        walls = vec_data['walls_segments']
        openings = vec_data['openings_segments']
        lines=[
            '<?xml version="1.0" encoding="UTF-8"?>',
            f'<svg xmlns="http://www.w3.org/2000/svg" width="{ow}" height="{oh}" viewBox="0 0 {ow} {oh}" stroke-linecap="round" stroke-linejoin="round">',
            '<g id="walls" stroke="#000" stroke-width="2" fill="none">'
        ]
        for (x1,y1,x2,y2) in walls:
            lines.append(f'<line x1="{x1}" y1="{y1}" x2="{x2}" y2="{y2}" />')
        lines.append('</g>')
        lines.append('<g id="openings" stroke="#FF3C80" stroke-width="2" fill="none">')
        for (x1,y1,x2,y2) in openings:
            lines.append(f'<line x1="{x1}" y1="{y1}" x2="{x2}" y2="{y2}" />')
        lines.append('</g></svg>')
        with open(path,'w',encoding='utf-8') as f: f.write('\n'.join(lines))

    def _export_walls_dxf(self, path, vec_data, original_size):
        ow,oh = original_size
        walls = vec_data['walls_segments']
        openings = vec_data['openings_segments']
        def dxf_header():
            return ["0","SECTION","2","HEADER","0","ENDSEC","0","SECTION","2","ENTITIES"]
        def dxf_footer():
            return ["0","ENDSEC","0","EOF"]
        lines=dxf_header()
        # å¢™ä½“ LINE
        for (x1,y1,x2,y2) in walls:
            lines += ["0","LINE","8","WALLS","10",str(x1),"20",str(y1),"11",str(x2),"21",str(y2)]
        # å¼€å£ LINE (å›¾å±‚ OPEN)
        for (x1,y1,x2,y2) in openings:
            lines += ["0","LINE","8","OPEN","10",str(x1),"20",str(y1),"11",str(x2),"21",str(y2)]
        lines += dxf_footer()
        with open(path,'w',encoding='utf-8') as f: f.write('\n'.join(lines))

    def _extract_room_coordinates(
        self, enhanced_resized, original_size, room_text_items
    ):
        """æå–å„æˆ¿é—´çš„åæ ‡ä¿¡æ¯ï¼Œä¼˜å…ˆä½¿ç”¨OCRæ–‡å­—ä½ç½®ï¼Œæ”¯æŒå¤šä¸ªåŒç±»å‹æˆ¿é—´"""
        room_info = {}

        # è®¡ç®—åæ ‡è½¬æ¢æ¯”ä¾‹
        original_width, original_height = original_size

        # å®šä¹‰æˆ¿é—´ç±»å‹åŠå…¶åœ¨åˆ†å‰²æ©ç ä¸­çš„æ ‡ç­¾
        room_types = ["å¨æˆ¿", "å«ç”Ÿé—´", "å®¢å…", "å§å®¤", "é˜³å°", "ä¹¦æˆ¿"]
        room_label_mapping = {
            "å¨æˆ¿": 7,
            "å«ç”Ÿé—´": 2,
            "å®¢å…": 3,
            "å§å®¤": 4,
            "é˜³å°": 6,
            "ä¹¦æˆ¿": 8,
        }

        # åˆå§‹åŒ–æ‰€æœ‰æˆ¿é—´ä¿¡æ¯ä¸ºç©ºåˆ—è¡¨ï¼Œæ”¯æŒå¤šä¸ªåŒç±»å‹æˆ¿é—´
        for room_type in room_types:
            room_info[room_type] = []

        # ä¼˜å…ˆä½¿ç”¨OCRæ–‡å­—ä½ç½®ç¡®å®šæˆ¿é—´åæ ‡
        for item in room_text_items:
            text = item["text"].lower().strip()

            # åŒ¹é…æˆ¿é—´ç±»å‹
            room_type = None
            if any(keyword in text for keyword in ["å¨æˆ¿", "kitchen", "å¨"]):
                room_type = "å¨æˆ¿"
            elif any(
                keyword in text
                for keyword in [
                    "å«ç”Ÿé—´",
                    "bathroom",
                    "å«",
                    "æ´—æ‰‹é—´",
                    "æµ´å®¤",
                    "æ·‹æµ´é—´",
                    "shower",
                    "æ·‹æµ´",
                    "ç›¥æ´—å®¤",
                ]
            ):
                room_type = "å«ç”Ÿé—´"
            elif any(keyword in text for keyword in ["å®¢å…", "living", "å…", "èµ·å±…å®¤"]):
                room_type = "å®¢å…"
            elif any(
                keyword in text for keyword in ["å§å®¤", "bedroom", "ä¸»å§", "æ¬¡å§"]
            ):
                room_type = "å§å®¤"
            elif any(keyword in text for keyword in ["é˜³å°", "balcony", "é˜³å…®", "é˜³åˆ", "é˜³å›Š"]):
                room_type = "é˜³å°"
                if text in ["é˜³å…®", "é˜³åˆ", "é˜³å›Š"]:
                    print(f"ğŸ”§ [OCRä¿®æ­£] è¯¯è¯†åˆ«'{text}' -> 'é˜³å°'")
            elif any(
                keyword in text
                for keyword in ["ä¹¦æˆ¿", "study", "åŠå…¬å®¤", "office"]
            ):
                room_type = "ä¹¦æˆ¿"
                print(f"ğŸ” [OCRéªŒè¯] ç¡®è®¤ä¹¦æˆ¿: '{text}' (OCRæ”¯æŒ)")

            if room_type and room_type in room_info:
                # ä½¿ç”¨OCRæ–‡å­—çš„ä¸­å¿ƒä½ç½®
                x, y, w, h = item["bbox"]

                # è®¡ç®—OCRæ–‡å­—ä¸­å¿ƒï¼ˆåœ¨OCRå¤„ç†çš„å›¾åƒåæ ‡ç³»ä¸­ï¼‰
                ocr_center_x = x + w // 2
                ocr_center_y = y + h // 2

                # OCRå›¾åƒæ˜¯æ”¾å¤§2å€çš„ï¼Œéœ€è¦å…ˆè½¬æ¢åˆ°åŸå§‹å›¾åƒåæ ‡
                orig_center_x = int(ocr_center_x / 2)
                orig_center_y = int(ocr_center_y / 2)

                # ä¼˜å…ˆä½¿ç”¨åˆ†å‰²æ©ç ç¡®å®šæ•´é—´æˆ¿çš„è¾¹ç•Œ
                min_x = max_x = min_y = max_y = None
                label = room_label_mapping.get(room_type)
                if label is not None:
                    mask = enhanced_resized == label
                    mask_h, mask_w = mask.shape
                    mask_x = int(orig_center_x * mask_w / original_width)
                    mask_y = int(orig_center_y * mask_h / original_height)
                    seed_x, seed_y, seed_found = mask_x, mask_y, False

                    if 0 <= mask_x < mask_w and 0 <= mask_y < mask_h:
                        if mask[mask_y, mask_x]:
                            seed_found = True
                        else:
                            # åœ¨é™„è¿‘å¯»æ‰¾æœ€è¿‘çš„åŒæ ‡ç­¾åƒç´ ï¼ˆ7x7é‚»åŸŸï¼‰
                            search_radius = 3
                            min_dist = None
                            for dy in range(-search_radius, search_radius + 1):
                                for dx in range(-search_radius, search_radius + 1):
                                    nx, ny = mask_x + dx, mask_y + dy
                                    if 0 <= nx < mask_w and 0 <= ny < mask_h and mask[ny, nx]:
                                        dist = dx * dx + dy * dy
                                        if min_dist is None or dist < min_dist:
                                            min_dist = dist
                                            seed_x, seed_y = nx, ny
                                            seed_found = True

                    if seed_found:
                        labeled_mask = mask.astype(np.uint8)
                        num_labels, labels_img = cv2.connectedComponents(labeled_mask)
                        region_label = labels_img[seed_y, seed_x]
                        if region_label != 0:
                            region = labels_img == region_label
                            y_coords, x_coords = np.where(region)
                            min_x_512, max_x_512 = x_coords.min(), x_coords.max()
                            min_y_512, max_y_512 = y_coords.min(), y_coords.max()
                            scale_x = original_width / float(mask_w)
                            scale_y = original_height / float(mask_h)
                            min_x = int(min_x_512 * scale_x)
                            max_x = int(max_x_512 * scale_x)
                            min_y = int(min_y_512 * scale_y)
                            max_y = int(max_y_512 * scale_y)

                if min_x is None:
                    # æœªæ‰¾åˆ°è¿é€šåŸŸï¼Œå›é€€åˆ°åŸºäºOCRæ–‡å­—çš„æœ€å°è¾¹ç•Œ
                    orig_w = int(w / 2)  # OCRå®½åº¦è½¬æ¢åˆ°åŸå§‹å›¾åƒ
                    orig_h = int(h / 2)  # OCRé«˜åº¦è½¬æ¢åˆ°åŸå§‹å›¾åƒ
                    half_width = max(20, orig_w // 2)
                    half_height = max(15, orig_h // 2)
                    min_x = max(0, orig_center_x - half_width)
                    max_x = min(original_width - 1, orig_center_x + half_width)
                    min_y = max(0, orig_center_y - half_height)
                    max_y = min(original_height - 1, orig_center_y + half_height)

                width = max_x - min_x + 1
                height = max_y - min_y + 1

                room_info[room_type].append({
                    'center': (orig_center_x, orig_center_y),
                    'bbox': (min_x, min_y, max_x, max_y),
                    'pixels': width * height,  # åŸºäºè¾¹ç•Œæ¡†çš„é¢ç§¯
                    'width': width,
                    'height': height,
                    'text': text,
                    'confidence': item.get('confidence', 0.0),
                })
        # å¯¹äºæ²¡æœ‰OCRæ£€æµ‹åˆ°çš„æˆ¿é—´ï¼Œå°è¯•ä»åˆ†å‰²ç»“æœä¸­æå–
        label_mapping = {v: k for k, v in room_label_mapping.items()}

        for label, room_type in label_mapping.items():
            if len(room_info[room_type]) == 0:  # OCRæ²¡æœ‰æ£€æµ‹åˆ°
                mask = enhanced_resized == label
                pixels = np.sum(mask)

                if pixels > 0:
                    # è®¡ç®—é¢ç§¯æ¯”ä¾‹ï¼Œé˜²æ­¢æ— OCRæ”¯æŒçš„è¿‡å¤§åŒºåŸŸ
                    total_pixels = enhanced_resized.shape[0] * enhanced_resized.shape[1]
                    area_ratio = pixels / total_pixels
                    
                    # å¯¹äºæ²¡æœ‰OCRæ”¯æŒçš„æˆ¿é—´ï¼Œé™åˆ¶æœ€å¤§é¢ç§¯
                    max_area_without_ocr = 0.05  # æœ€å¤š5% (ä»10%è°ƒæ•´)
                    if area_ratio > max_area_without_ocr:
                        print(f"âš ï¸ [ç¬¬3å±‚-èåˆå†³ç­–å™¨] è·³è¿‡è¿‡å¤§çš„æ— OCRæ”¯æŒ{room_type}åŒºåŸŸ: {area_ratio:.1%} > {max_area_without_ocr:.1%}")
                        continue
                    # æ‰¾åˆ°æˆ¿é—´åŒºåŸŸçš„åæ ‡
                    coords = np.where(mask)
                    y_coords, x_coords = coords

                    # è®¡ç®—è¾¹ç•Œæ¡†
                    min_x_512, max_x_512 = np.min(x_coords), np.max(x_coords)
                    min_y_512, max_y_512 = np.min(y_coords), np.max(y_coords)

                    # è®¡ç®—ä¸­å¿ƒç‚¹
                    center_x_512 = int(np.mean(x_coords))
                    center_y_512 = int(np.mean(y_coords))

                    # è½¬æ¢åˆ°åŸå§‹å›¾åƒå°ºå¯¸
                    scale_x = original_width / 512.0
                    scale_y = original_height / 512.0

                    center_x = int(center_x_512 * scale_x)
                    center_y = int(center_y_512 * scale_y)
                    min_x = int(min_x_512 * scale_x)
                    max_x = int(max_x_512 * scale_x)
                    min_y = int(min_y_512 * scale_y)
                    max_y = int(max_y_512 * scale_y)

                    width = max_x - min_x + 1
                    height = max_y - min_y + 1

                    room_info[room_type].append(
                        {
                            "center": (center_x, center_y),
                            "bbox": (min_x, min_y, max_x, max_y),
                            "pixels": pixels,
                            "width": width,
                            "height": height,
                            "text": "åˆ†å‰²æ£€æµ‹",
                            "confidence": 0.5,
                        }
                    )

        # åˆå¹¶ç›¸è¿‘çš„åŒç±»å‹æˆ¿é—´ï¼ˆå¦‚ä¸­è‹±æ–‡æ ‡è¯†çš„åŒä¸€æˆ¿é—´ï¼‰
        room_info = self._merge_nearby_rooms(room_info, original_size)
        
        # ğŸ”’ ä¸¥æ ¼è¿‡æ»¤ä¹¦æˆ¿ï¼šåªæœ‰OCRéªŒè¯çš„ä¹¦æˆ¿æ‰èƒ½ä¿ç•™
        if "ä¹¦æˆ¿" in room_info:
            ocr_verified_study_rooms = []
            for room in room_info["ä¹¦æˆ¿"]:
                # åªä¿ç•™æœ‰OCRæ–‡å­—éªŒè¯çš„ä¹¦æˆ¿ï¼ˆä¸æ˜¯"åˆ†å‰²æ£€æµ‹"ï¼‰
                if room.get("text", "") != "åˆ†å‰²æ£€æµ‹":
                    ocr_verified_study_rooms.append(room)
                    print(f"âœ… [ä¹¦æˆ¿éªŒè¯] ä¿ç•™OCRéªŒè¯çš„ä¹¦æˆ¿: '{room['text']}'")
                else:
                    print(f"ğŸš« [ä¹¦æˆ¿è¿‡æ»¤] ç§»é™¤æ— OCRæ”¯æŒçš„AIåˆ†å‰²ä¹¦æˆ¿åŒºåŸŸ")
            
            room_info["ä¹¦æˆ¿"] = ocr_verified_study_rooms
            if len(ocr_verified_study_rooms) == 0:
                print("ğŸ“‹ [ä¹¦æˆ¿è¿‡æ»¤] æ— OCRéªŒè¯çš„ä¹¦æˆ¿ï¼Œæœ€ç»ˆç»“æœä¸åŒ…å«ä¹¦æˆ¿")
        
        return room_info
        
    def _merge_nearby_rooms(self, room_info, original_size):
        """åˆå¹¶è·ç¦»å¾ˆè¿‘çš„åŒç±»å‹æˆ¿é—´"""
        print("ğŸ”„ æ£€æŸ¥å¹¶åˆå¹¶ç›¸è¿‘çš„åŒç±»å‹æˆ¿é—´...")
        
        # å®šä¹‰åˆå¹¶è·ç¦»é˜ˆå€¼ï¼ˆåƒç´ ï¼‰
        merge_threshold = 50  # ä¸­å¿ƒç‚¹è·ç¦»å°äº50åƒç´ çš„è®¤ä¸ºæ˜¯åŒä¸€æˆ¿é—´
        
        merged_room_info = {}
        
        for room_type, room_list in room_info.items():
            if len(room_list) <= 1:
                # åªæœ‰0æˆ–1ä¸ªæˆ¿é—´ï¼Œæ— éœ€åˆå¹¶
                merged_room_info[room_type] = room_list
                continue
                
            # å¯¹æœ‰å¤šä¸ªæˆ¿é—´çš„ç±»å‹è¿›è¡Œåˆå¹¶æ£€æŸ¥
            merged_list = []
            processed = set()
            
            for i, room1 in enumerate(room_list):
                if i in processed:
                    continue
                    
                # å¯»æ‰¾ä¸å½“å‰æˆ¿é—´è·ç¦»å¾ˆè¿‘çš„å…¶ä»–æˆ¿é—´
                to_merge = [room1]
                processed.add(i)
                
                for j, room2 in enumerate(room_list[i+1:], i+1):
                    if j in processed:
                        continue
                        
                    # è®¡ç®—ä¸¤æˆ¿é—´ä¸­å¿ƒç‚¹è·ç¦»
                    x1, y1 = room1['center']
                    x2, y2 = room2['center']
                    distance = ((x2-x1)**2 + (y2-y1)**2)**0.5
                    
                    if distance < merge_threshold:
                        to_merge.append(room2)
                        processed.add(j)
                        print(f"   ğŸ”— {room_type}åˆå¹¶ï¼š'{room1['text']}'({x1},{y1}) + '{room2['text']}'({x2},{y2}) è·ç¦»{distance:.1f}åƒç´ ")
                
                if len(to_merge) > 1:
                    # éœ€è¦åˆå¹¶å¤šä¸ªæˆ¿é—´
                    merged_room = self._merge_room_group(to_merge)
                    merged_list.append(merged_room)
                    print(f"   âœ… {room_type}åˆå¹¶å®Œæˆï¼š{len(to_merge)}ä¸ªåŒºåŸŸ -> 1ä¸ªåŒºåŸŸ")
                else:
                    # å•ä¸ªæˆ¿é—´ï¼Œç›´æ¥æ·»åŠ 
                    merged_list.append(room1)
            
            merged_room_info[room_type] = merged_list
            
            # è¾“å‡ºåˆå¹¶ç»“æœ
            if len(room_list) != len(merged_list):
                print(f"   ğŸ“Š {room_type}ï¼š{len(room_list)}ä¸ª -> {len(merged_list)}ä¸ª")
        
        return merged_room_info
    
    def _merge_room_group(self, room_group):
        """å°†å¤šä¸ªæˆ¿é—´åˆå¹¶ä¸ºä¸€ä¸ª"""
        # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„æˆ¿é—´ä½œä¸ºåŸºå‡†
        best_room = max(room_group, key=lambda r: r['confidence'])
        
        # è®¡ç®—åˆå¹¶åçš„ä¸­å¿ƒç‚¹ï¼ˆåŠ æƒå¹³å‡ï¼Œç½®ä¿¡åº¦ä½œä¸ºæƒé‡ï¼‰
        total_weight = sum(r['confidence'] for r in room_group)
        if total_weight > 0:
            weighted_x = sum(r['center'][0] * r['confidence'] for r in room_group) / total_weight
            weighted_y = sum(r['center'][1] * r['confidence'] for r in room_group) / total_weight
            merged_center = (int(weighted_x), int(weighted_y))
        else:
            # å¦‚æœæƒé‡ä¸º0ï¼Œä½¿ç”¨ç®€å•å¹³å‡
            avg_x = sum(r['center'][0] for r in room_group) / len(room_group)
            avg_y = sum(r['center'][1] for r in room_group) / len(room_group)
            merged_center = (int(avg_x), int(avg_y))
        
        # è®¡ç®—åˆå¹¶åçš„è¾¹ç•Œæ¡†ï¼ˆåŒ…å«æ‰€æœ‰æˆ¿é—´çš„è¾¹ç•Œï¼‰
        all_bbox = [r['bbox'] for r in room_group]
        min_x = min(bbox[0] for bbox in all_bbox)
        min_y = min(bbox[1] for bbox in all_bbox)
        max_x = max(bbox[2] for bbox in all_bbox)
        max_y = max(bbox[3] for bbox in all_bbox)
        
        merged_width = max_x - min_x + 1
        merged_height = max_y - min_y + 1
        
        # åˆå¹¶æ–‡æœ¬æè¿°
        texts = [r['text'] for r in room_group]
        merged_text = ' + '.join(texts)
        
        # ä½¿ç”¨æœ€é«˜ç½®ä¿¡åº¦
        max_confidence = max(r['confidence'] for r in room_group)
        
        return {
            'center': merged_center,
            'bbox': (min_x, min_y, max_x, max_y),
            'pixels': merged_width * merged_height,
            'width': merged_width,
            'height': merged_height,
            'text': merged_text,
            'confidence': max_confidence,
        }

        return room_info

    def _print_room_coordinates(self, room_info, original_size):
        """æ‰“å°æˆ¿é—´åæ ‡è¯¦ç»†ä¿¡æ¯ï¼Œæ”¯æŒå¤šä¸ªåŒç±»å‹æˆ¿é—´"""
        print("\n" + "=" * 60)
        print("ğŸ“ æˆ¿é—´åæ ‡è¯¦ç»†ä¿¡æ¯")
        print("=" * 60)
        print(f"ğŸ“ å›¾åƒå°ºå¯¸: {original_size[0]} x {original_size[1]} (å®½ x é«˜)")
        print("-" * 60)

        total_rooms = 0
        for room_type, room_list in room_info.items():
            if len(room_list) > 0:
                for i, info in enumerate(room_list):
                    if info["pixels"] > 0:
                        center_x, center_y = info["center"]
                        min_x, min_y, max_x, max_y = info["bbox"]

                        # å¦‚æœæœ‰å¤šä¸ªåŒç±»å‹æˆ¿é—´ï¼Œæ˜¾ç¤ºç¼–å·
                        if len(room_list) > 1:
                            display_name = f"{room_type}{i+1}"
                        else:
                            display_name = room_type

                        print(f"ğŸ  {display_name}:")
                        print(f"   ğŸ“ ä¸­å¿ƒåæ ‡: ({center_x}, {center_y})")
                        print(
                            f"   ğŸ“ è¾¹ç•Œæ¡†: å·¦ä¸Š({min_x}, {min_y}) -> å³ä¸‹({max_x}, {max_y})"
                        )
                        print(f"   ğŸ“ å°ºå¯¸: {info['width']} x {info['height']} åƒç´ ")
                        print(f"   ğŸ“Š é¢ç§¯: {info['pixels']} åƒç´ ")
                        print(
                            f"   ğŸ“„ è¯†åˆ«æ–‡æœ¬: '{info['text']}' (ç½®ä¿¡åº¦: {info['confidence']:.3f})"
                        )
                        print(f"   ğŸ”— åæ ‡èŒƒå›´: X[{min_x}-{max_x}], Y[{min_y}-{max_y}]")
                        print("-" * 60)
                        total_rooms += 1

            # å¦‚æœè¯¥ç±»å‹æˆ¿é—´æœªæ£€æµ‹åˆ°
            if len(room_list) == 0:
                print(f"âŒ {room_type}: æœªæ£€æµ‹åˆ°")
                print("-" * 60)

        print("ğŸ’¡ åæ ‡ç³»è¯´æ˜:")
        print("   â€¢ åŸç‚¹(0,0)åœ¨å›¾åƒå·¦ä¸Šè§’")
        print("   â€¢ Xè½´å‘å³ä¸ºæ­£æ–¹å‘")
        print("   â€¢ Yè½´å‘ä¸‹ä¸ºæ­£æ–¹å‘")
        print("   â€¢ æ‰€æœ‰åæ ‡å•ä½ä¸ºåƒç´ ")
        print("=" * 60)
        print(f"\nğŸ“Š æ€»è®¡æ£€æµ‹åˆ° {total_rooms} ä¸ªæˆ¿é—´")
        print("=" * 60)

    def process(self, image_path, output_path=None):
        """å®Œæ•´å¤„ç†æµç¨‹ - ä½¿ç”¨å››å±‚æ™ºèƒ½å†³ç­–æ¶æ„"""
        try:
            # è®¾ç½®è¾“å‡ºè·¯å¾„
            if output_path is None:
                output_path = Path(image_path).stem

            # 1. åŠ è½½æ¨¡å‹
            self.load_model()

            # 2. å›¾åƒé¢„å¤„ç†
            img_array, original_size, original_img = self.preprocess_image(image_path)

            # 3-6. ä½¿ç”¨å››å±‚æ™ºèƒ½å†³ç­–æ¶æ„å¤„ç†
            results = self.process_with_four_layer_architecture(
                img_array, original_img, original_size
            )

            # 7. ç”Ÿæˆç»“æœ
            standard_result_path = self.generate_results(
                results['ai_raw'],
                results['ocr_results'],
                results['fusion_result'],
                results['final_result'],
                original_img,
                original_size,
                output_path,
                results['ocr_results']
            )

            # 8. æ˜¾ç¤ºæ‘˜è¦
            self._print_summary()

            return standard_result_path

        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            raise

    def _print_summary(self):
        """æ‰“å°æ£€æµ‹æ‘˜è¦ - åŸºäºOCRéªŒè¯çš„çœŸå®æˆ¿é—´æ•°é‡"""
        # æˆ¿é—´æ ‡ç­¾åˆ°åç§°/å›¾æ ‡/é¢œè‰²çš„æ˜ å°„
        label_info = {
            7: ("å¨æˆ¿", "ğŸ³", "ç»¿è‰²"),
            2: ("å«ç”Ÿé—´", "ğŸš¿", "è“è‰²"),
            3: ("å®¢å…", "ğŸ ", "æ©™è‰²"),
            4: ("å§å®¤", "ğŸ›ï¸", "ç´«è‰²"),
            6: ("é˜³å°", "ğŸŒ", "é’è‰²"),
            8: ("ä¹¦æˆ¿", "ğŸ“š", "æ£•è‰²"),
        }

        # åŸºäºå®é™…æ£€æµ‹åˆ°çš„æˆ¿é—´åæ ‡ä¿¡æ¯ç»Ÿè®¡ï¼ˆé¿å…AIåˆ†å‰²è¯¯è¯†åˆ«ï¼‰
        if hasattr(self, 'last_room_info'):
            room_counts = {}
            for label, (name, _, _) in label_info.items():
                # ç»Ÿè®¡å®é™…éªŒè¯è¿‡çš„æˆ¿é—´æ•°é‡ï¼Œè€Œä¸æ˜¯AIåˆ†å‰²çš„è¿é€šåŸŸæ•°é‡
                room_type_map = {7: "å¨æˆ¿", 2: "å«ç”Ÿé—´", 3: "å®¢å…", 4: "å§å®¤", 6: "é˜³å°", 8: "ä¹¦æˆ¿"}
                room_type = room_type_map.get(label, "")
                if room_type and room_type in self.last_room_info:
                    # åªç»Ÿè®¡æœ‰æ•ˆæ£€æµ‹çš„æˆ¿é—´ï¼ˆåƒç´ >0çš„æˆ¿é—´ï¼‰
                    valid_rooms = [r for r in self.last_room_info[room_type] if r.get('pixels', 0) > 0]
                    room_counts[label] = len(valid_rooms)
                else:
                    room_counts[label] = 0
        else:
            # å›é€€åˆ°åŸæ¥çš„è¿é€šåŸŸç»Ÿè®¡æ–¹æ³•ï¼ˆä½†æ·»åŠ è­¦å‘Šï¼‰
            print("âš ï¸ è­¦å‘Šï¼šä½¿ç”¨AIåˆ†å‰²ç»“æœç»Ÿè®¡ï¼Œå¯èƒ½åŒ…å«è¯¯è¯†åˆ«")
            room_counts = {}
            for label, (name, _, _) in label_info.items():
                mask = self.last_enhanced == label
                pixel_count = np.count_nonzero(mask)
                if pixel_count > 0:
                    num, _ = cv2.connectedComponents(mask.astype(np.uint8))
                    count = num - 1  # å»é™¤èƒŒæ™¯
                else:
                    count = 0
                room_counts[label] = count

        total_rooms = sum(room_counts.values())
        summary_parts = [
            f"{room_counts[label]}ä¸ª{name}"
            for label, (name, _, _) in label_info.items()
        ]
        print(f"\nğŸ  æ£€æµ‹æ‘˜è¦ï¼ˆåŸºäºOCRéªŒè¯ï¼‰: {' + '.join(summary_parts)} = {total_rooms}ä¸ªæˆ¿é—´")

        # è¾“å‡ºå­˜åœ¨çš„æˆ¿é—´ç±»å‹åŠå…¶é¢œè‰²è¯´æ˜
        for label, (name, emoji, color) in label_info.items():
            if room_counts[label] > 0:
                print(f"{emoji} {name}æ£€æµ‹: {color}æ ‡è®°")
                
        # å¦‚æœå‘ç°AIåˆ†å‰²ä¸OCRéªŒè¯ç»“æœä¸ä¸€è‡´ï¼Œæä¾›é¢å¤–è¯´æ˜
        ai_room_counts = {}
        for label, (name, _, _) in label_info.items():
            mask = self.last_enhanced == label
            pixel_count = np.count_nonzero(mask)
            if pixel_count > 0:
                num, _ = cv2.connectedComponents(mask.astype(np.uint8))
                ai_count = num - 1
            else:
                ai_count = 0
            ai_room_counts[label] = ai_count
            
        # æ£€æŸ¥æ˜¯å¦æœ‰å·®å¼‚å¹¶æé†’
        for label, (name, _, _) in label_info.items():
            if ai_room_counts[label] != room_counts[label]:
                print(f"âš ï¸ æ³¨æ„ï¼š{name}çš„AIåˆ†å‰²æ£€æµ‹åˆ°{ai_room_counts[label]}ä¸ªåŒºåŸŸï¼Œä½†OCRéªŒè¯åç¡®è®¤ä¸º{room_counts[label]}ä¸ª")
                if ai_room_counts[label] > room_counts[label]:
                    print(f"   ğŸ’¡ å¯èƒ½å­˜åœ¨AIè¯¯è¯†åˆ«ï¼Œå»ºè®®æŸ¥çœ‹å›¾åƒä¸­æ˜¯å¦æœ‰{name}çš„é”™è¯¯è“è‰²æ ‡è®°")

    def __del__(self):
        """æ¸…ç†èµ„æº"""
        if hasattr(self, 'ai_engine') and hasattr(self.ai_engine, 'session') and self.ai_engine.session:
            self.ai_engine.session.close()

    @staticmethod
    def open_image_with_system_viewer(image_path):
        """ä½¿ç”¨ç³»ç»Ÿé»˜è®¤å›¾ç‰‡æŸ¥çœ‹å™¨æ‰“å¼€å›¾ç‰‡"""
        try:
            system = platform.system()
            if system == "Windows":
                os.startfile(image_path)
            elif system == "Darwin":  # macOS
                subprocess.run(["open", image_path])
            elif system == "Linux":
                subprocess.run(["xdg-open", image_path])
            else:
                print(f"âš ï¸ ä¸æ”¯æŒçš„æ“ä½œç³»ç»Ÿ: {system}ï¼Œæ— æ³•è‡ªåŠ¨æ‰“å¼€å›¾ç‰‡")
                return False
            
            print(f"ğŸ–¼ï¸ å·²ä½¿ç”¨ç³»ç»Ÿé»˜è®¤æŸ¥çœ‹å™¨æ‰“å¼€: {image_path}")
            return True
        except Exception as e:
            print(f"âŒ æ‰“å¼€å›¾ç‰‡å¤±è´¥: {e}")
            print(f"ğŸ“‚ è¯·æ‰‹åŠ¨æŸ¥çœ‹ç»“æœ: {image_path}")
            return False


def open_image_with_photos_app(image_path):
    """ä½¿ç”¨Windowsç…§ç‰‡åº”ç”¨æ‰“å¼€å›¾ç‰‡"""
    try:
        system = platform.system()
        if system == "Windows":
            # è·å–ç»å¯¹è·¯å¾„
            abs_path = os.path.abspath(image_path)
            print(f"ğŸ” å°è¯•æ‰“å¼€æ–‡ä»¶: {abs_path}")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(abs_path):
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {abs_path}")
                return False
            
            # æ–¹æ³•1: ä½¿ç”¨os.startfile (Windowsæ¨èæ–¹å¼)
            try:
                os.startfile(abs_path)
                print(f"ğŸ“¸ å·²ä½¿ç”¨ç³»ç»Ÿé»˜è®¤æŸ¥çœ‹å™¨ï¼ˆé€šå¸¸æ˜¯ç…§ç‰‡åº”ç”¨ï¼‰æ‰“å¼€: {os.path.basename(image_path)}")
                return True
            except Exception as e:
                print(f"âš ï¸ os.startfileå¤±è´¥: {e}")
                
                # æ–¹æ³•2: å°è¯•ä½¿ç”¨explorer
                try:
                    subprocess.run(["explorer", abs_path], check=True)
                    print(f"ğŸ“¸ å·²ä½¿ç”¨èµ„æºç®¡ç†å™¨æ‰“å¼€: {os.path.basename(image_path)}")
                    return True
                except subprocess.CalledProcessError:
                    print("âš ï¸ exploreræ–¹æ³•ä¹Ÿå¤±è´¥")
                    
                    # æ–¹æ³•3: å°è¯•PowerShell Invoke-Item
                    try:
                        subprocess.run([
                            "powershell.exe", 
                            "-Command", 
                            f"Invoke-Item '{abs_path}'"
                        ], check=True)
                        print(f"ï¿½ å·²ä½¿ç”¨PowerShellæ‰“å¼€: {os.path.basename(image_path)}")
                        return True
                    except subprocess.CalledProcessError as e:
                        print(f"âŒ PowerShellæ–¹æ³•ä¹Ÿå¤±è´¥: {e}")
                        return False
        else:
            print(f"âš ï¸ ç…§ç‰‡åº”ç”¨ä»…æ”¯æŒWindowsç³»ç»Ÿï¼Œå½“å‰ç³»ç»Ÿ: {system}")
            # å›é€€åˆ°ç³»ç»Ÿé»˜è®¤æŸ¥çœ‹å™¨
            return FloorplanProcessor.open_image_with_system_viewer(image_path)
    except Exception as e:
        print(f"âŒ æ‰“å¼€å›¾ç‰‡å¤±è´¥: {e}")
        print(f"ğŸ“‚ è¯·æ‰‹åŠ¨æŸ¥çœ‹ç»“æœ: {image_path}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="DeepFloorplan æˆ¿é—´æ£€æµ‹ - é‡æ„ç‰ˆæœ¬ (å¸¦åæ ‡è½´)"
    )
    parser.add_argument("image", help="è¾“å…¥å›¾åƒè·¯å¾„")
    parser.add_argument("--output", "-o", help="è¾“å‡ºæ–‡ä»¶åå‰ç¼€")
    parser.add_argument("--model", "-m", default="pretrained", help="æ¨¡å‹è·¯å¾„")
    parser.add_argument(
        "--fonts",
        help="é€—å·åˆ†éš”çš„å­—ä½“åˆ—è¡¨ï¼ŒæŒ‰ä¼˜å…ˆçº§ä½¿ç”¨",
    )

    args = parser.parse_args()

    # å­—ä½“å·²åœ¨æ¨¡å—åŠ è½½æ—¶åˆå§‹åŒ–ï¼Œè‹¥æœªæˆåŠŸæä¾›ä¸€æ¬¡è¿è¡ŒæœŸæç¤º
    if CH_FONT is None:
        print("âš ï¸ æœªæ‰¾åˆ°å¯ç”¨ä¸­æ–‡å­—ä½“ï¼Œå¯èƒ½å‡ºç° ? å·ã€‚å¯ä½¿ç”¨ --fonts æŒ‡å®šï¼Œä½†éœ€ç³»ç»Ÿå·²å®‰è£…å¯¹åº”å­—ä½“ã€‚")

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not Path(args.image).exists():
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.image}")
        sys.exit(1)

    # åˆ›å»ºå¤„ç†å™¨å¹¶æ‰§è¡Œ
    processor = FloorplanProcessor(args.model)
    standard_result_path = processor.process(args.image, args.output)

    # ç¡®å®šè¾“å‡ºæ–‡ä»¶è·¯å¾„
    output_base = args.output if args.output else Path(args.image).stem
    coordinate_result_path = f"output/{output_base}_coordinate_result.png"
    
    print("\nğŸ‰ å¤„ç†å®Œæˆï¼")
    print("ğŸ“‚ è¾“å‡ºç›®å½•: output/")
    print("ğŸ–¼ï¸ ä¸»è¦ç»“æœ:")
    print(f"   ğŸ“Š å¸¦åæ ‡è½´ç»“æœ: {coordinate_result_path}")
    print(f"   ğŸ“¸ æ ‡å‡†ç»“æœ: {standard_result_path}")
    
    # è‡ªåŠ¨æ‰“å¼€ç”Ÿæˆçš„å›¾ç‰‡
    print("\nğŸ–¼ï¸ æ­£åœ¨æ‰“å¼€ç»“æœå›¾ç‰‡...")
    
    # ä¼˜å…ˆæ‰“å¼€å¸¦åæ ‡è½´çš„ç»“æœå›¾ï¼ˆæ›´è¯¦ç»†ï¼‰
    if os.path.exists(coordinate_result_path):
        if open_image_with_photos_app(coordinate_result_path):
            print("âœ… å·²ä½¿ç”¨ç…§ç‰‡åº”ç”¨æ‰“å¼€å¸¦åæ ‡è½´çš„ç»“æœå›¾")
        else:
            print("âš ï¸ æ— æ³•è‡ªåŠ¨æ‰“å¼€å›¾ç‰‡ï¼Œè¯·æ‰‹åŠ¨æŸ¥çœ‹ç»“æœæ–‡ä»¶")
    elif os.path.exists(standard_result_path):
        if open_image_with_photos_app(standard_result_path):
            print("âœ… å·²ä½¿ç”¨ç…§ç‰‡åº”ç”¨æ‰“å¼€æ ‡å‡†ç»“æœå›¾")
        else:
            print("âš ï¸ æ— æ³•è‡ªåŠ¨æ‰“å¼€å›¾ç‰‡ï¼Œè¯·æ‰‹åŠ¨æŸ¥çœ‹ç»“æœæ–‡ä»¶")
    else:
        print("âŒ æ‰¾ä¸åˆ°ç”Ÿæˆçš„ç»“æœå›¾ç‰‡æ–‡ä»¶")


if __name__ == "__main__":
    main()
