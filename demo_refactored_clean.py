#!/usr/bin/env python3
"""
DeepFloorplan æˆ¿é—´æ£€æµ‹ - é‡æ„ç‰ˆæœ¬ (å¸¦åæ ‡è½´)
============================================

æœ¬æ–‡ä»¶æ˜¯ demo.py çš„å®Œå…¨é‡æ„ç‰ˆæœ¬ï¼Œä¸»è¦æ”¹è¿›ï¼š
1. é¢å‘å¯¹è±¡è®¾è®¡æ›¿ä»£è¿‡ç¨‹å¼ç¼–ç¨‹
2. æ¶ˆé™¤90%é‡å¤ä»£ç 
3. ç»Ÿä¸€é…ç½®ç®¡ç†
4. æ¸…æ™°çš„èŒè´£åˆ†ç¦»
5. ç°ä»£åŒ–ä»£ç é£æ ¼
6. åæ ‡è½´æ˜¾ç¤ºå’Œæˆ¿é—´åæ ‡ä¿¡æ¯

åŠŸèƒ½å®Œå…¨ç­‰åŒäºåŸç‰ˆæœ¬ï¼Œä½†ä»£ç æ›´ç®€æ´ã€ä¼˜é›…ã€æ˜“ç»´æŠ¤ã€‚
"""

import os
import sys
import subprocess
import platform
import argparse
import numpy as np
import cv2
from pathlib import Path
import json
from datetime import datetime

# é…ç½®ç¯å¢ƒ
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"
import warnings

warnings.filterwarnings("ignore")

try:
    import tensorflow.compat.v1 as tf  # type: ignore
except Exception as _tf_err:
    class _DummyTF:
        def __getattr__(self, item):
            raise ImportError(f"TensorFlow æœªå®‰è£…ï¼Œæ— æ³•è®¿é—® {item}: {_tf_err}")
    tf = _DummyTF()  # fallback
import matplotlib.pyplot as plt
import matplotlib
from matplotlib import font_manager
from matplotlib.font_manager import FontProperties
from PIL import ImageFont, ImageDraw, Image

# å¼•å…¥å››å±‚æ¶æ„ç»„ä»¶
from engines.segmentation_engine import AISegmentationEngine
from engines.ocr_engine import OCRRecognitionEngine
from engines.fusion_engine import FusionDecisionEngine
from engines.post_rules import ReasonablenessValidator

## åŸç¬¬ä¸€è‡³ä¸‰å±‚åŠç¬¬å››å±‚è§„åˆ™ç±»å·²æ‹†åˆ†åˆ° engines/ ä¸‹, æ­¤å¤„ä¸å†å®šä¹‰é‡å¤å®ç°ï¼Œä»¥ä¸‹å¼€å§‹ä¸»å¤„ç†å™¨ç±»

# ================= ä¸­æ–‡å­—ä½“é…ç½®ï¼ˆé˜²æ­¢ Matplotlib / OCR å­å›¾å‡ºç°é—®å·ï¼‰=================
# è¯´æ˜: ä¹‹å‰çš„è‡ªåŠ¨æ£€æµ‹åªåœ¨ matplotlib ç›®å½•ä¸‹æ‰¾å­—ä½“, å®é™… Windows ä¸­æ–‡å­—ä½“åœ¨ C:/Windows/Fonts ä¸‹, å¯¼è‡´æœªæ‰¾åˆ° -> é—®å·ã€‚
# ç­–ç•¥: 1) ä¼˜å…ˆç³»ç»Ÿå¸¸è§å­—ä½“ 2) å…¶æ¬¡é¡¹ç›®è‡ªå¸¦ fonts/ 3) æœ€åé€€å›é»˜è®¤å­—ä½“ (ä»å¯æ˜¾ç¤ºè‹±æ–‡, ä½†æç¤º).

def _find_chinese_font():
    candidates = [
        # Windows å¸¸è§å­—ä½“
        r"C:/Windows/Fonts/msyh.ttc",
        r"C:/Windows/Fonts/msyh.ttf",
        r"C:/Windows/Fonts/msyhl.ttc",
        r"C:/Windows/Fonts/simhei.ttf",
        r"C:/Windows/Fonts/simhei.ttc",
        r"C:/Windows/Fonts/simsun.ttc",
        r"C:/Windows/Fonts/simfang.ttf",
        r"C:/Windows/Fonts/STSONG.TTF",
        # é¡¹ç›®å†…è‡ªå¸¦ (å¯è‡ªè¡Œæ·»åŠ )
        str(Path(__file__).parent / "fonts" / "msyh.ttc"),
        str(Path(__file__).parent / "fonts" / "simhei.ttf"),
    ]
    for p in candidates:
        if os.path.exists(p):
            return p
    return None

CH_FONT_PATH = _find_chinese_font()
if CH_FONT_PATH:
    try:
        # æ˜¾å¼æ³¨å†Œå­—ä½“ï¼Œé¿å…ä»…ä½¿ç”¨ stem å¯¼è‡´æ‰¾ä¸åˆ° family åç§°
        try:
            from matplotlib import font_manager as _fm
            _fm.fontManager.addfont(CH_FONT_PATH)
        except Exception:
            pass
        CH_FONT = FontProperties(fname=CH_FONT_PATH)
        # å¸¸è§ä¸­æ–‡å­—ä½“åˆ«åï¼Œæå‡åŒ¹é…æˆåŠŸç‡
        matplotlib.rcParams['font.sans-serif'] = [
            'Microsoft YaHei', 'MS YaHei', 'å¾®è½¯é›…é»‘', 'SimHei', 'SimSun', 'Heiti SC', 'Noto Sans CJK SC'
        ]
        # è¿½åŠ å½“å‰å­—ä½“æ–‡ä»¶å¯¹åº”çš„åç§°ï¼ˆå¯èƒ½æ˜¯ msyh / simhei ç­‰ï¼‰
        stem_name = Path(CH_FONT_PATH).stem
        if stem_name not in matplotlib.rcParams['font.sans-serif']:
            matplotlib.rcParams['font.sans-serif'].append(stem_name)
        matplotlib.rcParams['axes.unicode_minus'] = False
        print(f"ğŸˆ¶ å·²åŠ è½½ä¸­æ–‡å­—ä½“: {CH_FONT_PATH}")
    except Exception as _fe:
        print(f"âš ï¸ ä¸­æ–‡å­—ä½“åŠ è½½å¤±è´¥, ä½¿ç”¨é»˜è®¤å­—ä½“: {_fe}")
        CH_FONT = FontProperties()
else:
    print("âš ï¸ æœªæ‰¾åˆ°å¯ç”¨ä¸­æ–‡å­—ä½“, å¯èƒ½å‡ºç°é—®å·ã€‚å¯å°† ms yh / simhei å­—ä½“æ”¾å…¥ fonts/ ç›®å½•ã€‚")
    CH_FONT = FontProperties()

class SizeConstraintEngine:  # å ä½é¿å…æ—§å¼•ç”¨; å®é™…é€»è¾‘å·²åœ¨ engines.post_rules ä¸­
    pass

class BuildingBoundaryDetector:  # å ä½é¿å…æ—§å¼•ç”¨; å®é™…é€»è¾‘å·²åœ¨ engines.post_rules ä¸­
    pass


class FloorplanProcessor:
    """æˆ·å‹å›¾å¤„ç†å™¨ - å››å±‚æ™ºèƒ½å†³ç­–æ¶æ„ç»Ÿä¸€ç®¡ç†å™¨"""

    def __init__(self, model_path="pretrained"):
        """åˆå§‹åŒ–å››å±‚æ¶æ„å¤„ç†å™¨"""
        if getattr(tf, "__class__", type(tf)).__name__ == "_DummyTF":
            raise ImportError("è¯·å®‰è£… TensorFlow â‰¥ 1.x")

        print("ğŸ  DeepFloorplan æˆ¿é—´æ£€æµ‹ - å››å±‚æ™ºèƒ½å†³ç­–æ¶æ„")
        print("=" * 60)

        # åˆå§‹åŒ–å››å±‚æ¶æ„ç»„ä»¶
        self.ai_engine = AISegmentationEngine(model_path)
        self.ocr_engine = OCRRecognitionEngine()
        self.fusion_engine = FusionDecisionEngine()
        self.validator = ReasonablenessValidator()

        # è¿è¡Œæ—¶ç¼“å­˜/çŠ¶æ€
        self.last_enhanced = None  # æœ€è¿‘ä¸€æ¬¡å¢å¼ºåçš„ label å›¾ (512x512)
        self._boundary_cache = {}  # {md5: å¢å¼ºåå«å¢™ä½“ç»“æœ}

    def load_model(self):
        """åŠ è½½AIåˆ†å‰²æ¨¡å‹"""
        if getattr(tf, "__class__", type(tf)).__name__ == "_DummyTF":
            raise ImportError("è¯·å®‰è£… TensorFlow â‰¥ 1.x")
        self.ai_engine.load_model()

    def preprocess_image(self, image_path):
        """å›¾åƒé¢„å¤„ç†"""
        print(f"ğŸ“¸ å¤„ç†å›¾åƒ: {image_path}")

        # è¯»å–å›¾åƒ
        img = Image.open(image_path).convert("RGB")
        original_size = img.size

        print(f"ğŸ“ åŸå§‹å›¾åƒå°ºå¯¸: {original_size[0]} x {original_size[1]} (å®½xé«˜)")

        # è°ƒæ•´åˆ°æ¨¡å‹è¾“å…¥å°ºå¯¸ (512x512)
        img_resized = img.resize((512, 512), Image.LANCZOS)
        img_array = np.array(img_resized, dtype=np.float32) / 255.0

        print(f"ğŸ”„ ç¥ç»ç½‘ç»œè¾“å…¥: 512 x 512 (å›ºå®šå°ºå¯¸)")

        return img_array, original_size, np.array(img)

    def process_with_four_layer_architecture(self, img_array, original_img, original_size):
        """ä½¿ç”¨å››å±‚æ¶æ„å¤„ç†å›¾åƒ"""
        print("\nğŸ—ï¸ å¼€å§‹å››å±‚æ™ºèƒ½å†³ç­–å¤„ç†æµç¨‹...")
        
        # ç¬¬ä¸€å±‚ï¼šAIè¯­ä¹‰åˆ†å‰²
        ai_prediction = self.ai_engine.segment_image(img_array)
        
        # ç¬¬äºŒå±‚ï¼šOCRæ–‡å­—è¯†åˆ«
        ocr_results, ocr_shape = self.ocr_engine.recognize_text(original_img)
        
        # ç¬¬ä¸‰å±‚ï¼šèåˆå†³ç­–
        fused_results = self.fusion_engine.fuse_results(ai_prediction, ocr_results, ocr_shape)
        
        # ç¬¬å››å±‚ï¼šåˆç†æ€§éªŒè¯
        validated_results = self.validator.validate_and_correct(fused_results, ocr_results, original_size)
        
        # ä¿å­˜ç»“æœç”¨äºç»Ÿè®¡
        self.last_enhanced = validated_results
        
        print("ğŸ‰ å››å±‚æ™ºèƒ½å†³ç­–å¤„ç†å®Œæˆï¼")
        return {
            'ai_raw': ai_prediction,
            'ocr_results': ocr_results, 
            'fusion_result': fused_results,
            'final_result': validated_results
        }

    # ä¿ç•™åŸæœ‰æ¥å£ä»¥ä¿æŒå…¼å®¹æ€§
    def run_inference(self, img_array):
        """è¿è¡Œç¥ç»ç½‘ç»œæ¨ç†ï¼ˆå…¼å®¹æ¥å£ï¼‰"""
        return self.ai_engine.segment_image(img_array)

    def extract_ocr_info(self, original_img):
        """æå–OCRæ–‡å­—ä¿¡æ¯ï¼ˆå…¼å®¹æ¥å£ï¼‰"""
        return self.ocr_engine.recognize_text(original_img)

    def fuse_predictions(self, prediction, room_text_items, ocr_shape):
        """èåˆé¢„æµ‹ç»“æœï¼ˆå…¼å®¹æ¥å£ï¼‰"""
        return self.fusion_engine.fuse_results(prediction, room_text_items, ocr_shape)

    def detect_rooms(self, enhanced, room_text_items, original_size):
        """æ£€æµ‹å„ç±»æˆ¿é—´ï¼ˆå…¼å®¹æ¥å£ï¼‰"""
        # ç°åœ¨è¿™ä¸ªåŠŸèƒ½å·²ç»æ•´åˆåˆ°å››å±‚æ¶æ„ä¸­
        return enhanced
        
    def _clean_misidentified_regions(self, enhanced, room_text_items, original_size):
        """æ¸…ç†AIåˆ†å‰²ä¸­çš„è¯¯è¯†åˆ«åŒºåŸŸï¼Œåªä¿ç•™OCRéªŒè¯çš„æˆ¿é—´åŒºåŸŸ"""
        print("ğŸ§¹ æ¸…ç†AIåˆ†å‰²è¯¯è¯†åˆ«åŒºåŸŸ...")
        
        # è·å–OCRéªŒè¯çš„æˆ¿é—´ä½ç½®
        ocr_rooms = {}
        for item in room_text_items:
            text = item["text"].lower().strip()
            room_type = None
            
            if any(keyword in text for keyword in ["å¨æˆ¿", "kitchen", "å¨"]):
                room_type = 7  # å¨æˆ¿
            elif any(keyword in text for keyword in ["å«ç”Ÿé—´", "bathroom", "å«", "æ´—æ‰‹é—´", "æµ´å®¤", "æ·‹æµ´é—´", "shower", "æ·‹æµ´", "ç›¥æ´—å®¤"]):
                room_type = 2  # å«ç”Ÿé—´
            elif any(keyword in text for keyword in ["å®¢å…", "living", "å…", "èµ·å±…å®¤"]):
                room_type = 3  # å®¢å…
            elif any(keyword in text for keyword in ["å§å®¤", "bedroom", "ä¸»å§", "æ¬¡å§"]):
                room_type = 4  # å§å®¤
            elif any(keyword in text for keyword in ["é˜³å°", "balcony", "é˜³å…®", "é˜³åˆ", "é˜³å›Š"]):
                room_type = 6  # é˜³å°
            elif any(keyword in text for keyword in ["ä¹¦æˆ¿", "study", "åŠå…¬å®¤", "office"]):
                room_type = 8  # ä¹¦æˆ¿
                
            if room_type:
                if room_type not in ocr_rooms:
                    ocr_rooms[room_type] = []
                
                # è½¬æ¢OCRåæ ‡åˆ°512x512åæ ‡ç³»
                x, y, w, h = item["bbox"]
                # OCRæ˜¯åœ¨2å€æ”¾å¤§å›¾åƒä¸Šï¼Œéœ€è¦è½¬æ¢åˆ°512x512
                ocr_to_512_x = 512.0 / (original_size[0] * 2)
                ocr_to_512_y = 512.0 / (original_size[1] * 2) 
                
                center_512_x = int((x + w//2) * ocr_to_512_x)
                center_512_y = int((y + h//2) * ocr_to_512_y)
                ocr_rooms[room_type].append((center_512_x, center_512_y, item["confidence"]))
        
        # å¯¹äºæ¯ä¸ªæˆ¿é—´ç±»å‹ï¼Œåªä¿ç•™OCRéªŒè¯ä½ç½®é™„è¿‘çš„åˆ†å‰²åŒºåŸŸ
        for room_label, room_positions in ocr_rooms.items():
            if room_label in [2, 7]:  # å¤„ç†å«ç”Ÿé—´å’Œå¨æˆ¿çš„è¯¯è¯†åˆ«é—®é¢˜
                room_name = "å«ç”Ÿé—´" if room_label == 2 else "å¨æˆ¿"
                print(f"ğŸ§¹ æ¸…ç†{room_name}è¯¯è¯†åˆ«åŒºåŸŸï¼Œä¿ç•™{len(room_positions)}ä¸ªOCRéªŒè¯ä½ç½®")
                
                # è·å–æ‰€æœ‰æŒ‡å®šæ ‡ç­¾çš„åƒç´ 
                mask = (enhanced == room_label).astype(np.uint8)
                
                # ä½¿ç”¨è¿é€šåŸŸåˆ†ææ‰¾åˆ°æ‰€æœ‰åŒºåŸŸ
                num_labels, labels_im, stats, centroids = cv2.connectedComponentsWithStats(mask, connectivity=4)
                
                # åˆ›å»ºæ–°çš„æ¸…ç†åçš„mask
                cleaned_mask = np.zeros_like(mask)
                
                for comp_id in range(1, num_labels):  # è·³è¿‡èƒŒæ™¯(0)
                    comp_centroid = centroids[comp_id]
                    comp_center_x, comp_center_y = int(comp_centroid[0]), int(comp_centroid[1])
                    comp_area = stats[comp_id, cv2.CC_STAT_AREA]
                    
                    # æ£€æŸ¥è¿™ä¸ªè¿é€šåŸŸæ˜¯å¦æ¥è¿‘ä»»ä½•OCRéªŒè¯çš„ä½ç½®
                    is_valid = False
                    min_distance = float('inf')
                    closest_confidence = 0
                    
                    for ocr_x, ocr_y, confidence in room_positions:
                        distance = np.sqrt((comp_center_x - ocr_x)**2 + (comp_center_y - ocr_y)**2)
                        if distance < min_distance:
                            min_distance = distance
                            closest_confidence = confidence
                    
                    # è®¾ç½®è·ç¦»é˜ˆå€¼ï¼šæ ¹æ®OCRéªŒè¯ä½ç½®æ•°é‡åŠ¨æ€è°ƒæ•´
                    if len(room_positions) > 1:
                        # å¤šä¸ªOCRä½ç½®æ—¶ï¼Œä½¿ç”¨æ›´å®½æ¾çš„é˜ˆå€¼
                        distance_threshold = 120 if room_label == 7 else 100
                    else:
                        # å•ä¸ªOCRä½ç½®æ—¶ï¼Œä½¿ç”¨æ ‡å‡†é˜ˆå€¼  
                        distance_threshold = 100 if room_label == 7 else 80
                    
                    # è®¾ç½®é¢ç§¯é˜ˆå€¼ï¼šé˜²æ­¢å·¨å¤§çš„è¯¯è¯†åˆ«åŒºåŸŸ
                    max_area_threshold = 15000 if room_label == 7 else 10000  # é€‚å½“æ”¾å®½é¢ç§¯é™åˆ¶
                    
                    # å¦‚æœè·ç¦»åœ¨åˆç†èŒƒå›´å†…ä¸”é¢ç§¯ä¸è¶…æ ‡ï¼Œè®¤ä¸ºæ˜¯æœ‰æ•ˆçš„
                    if min_distance < distance_threshold and comp_area < max_area_threshold:  
                        is_valid = True
                        print(f"   âœ… ä¿ç•™{room_name}åŒºåŸŸï¼šä¸­å¿ƒ({comp_center_x}, {comp_center_y}), è·OCR: {min_distance:.1f}åƒç´ , é¢ç§¯: {comp_area}, ç½®ä¿¡åº¦: {closest_confidence:.3f}")
                    else:
                        reasons = []
                        if min_distance >= distance_threshold:
                            reasons.append("è·ç¦»è¿‡è¿œ")
                        if comp_area >= max_area_threshold:
                            reasons.append("é¢ç§¯è¿‡å¤§")
                        print(f"   âŒ ç§»é™¤è¯¯è¯†åˆ«åŒºåŸŸï¼šä¸­å¿ƒ({comp_center_x}, {comp_center_y}), è·OCR: {min_distance:.1f}åƒç´ , é¢ç§¯: {comp_area} ({', '.join(reasons)})")
                    
                    if is_valid:
                        # ä¿ç•™è¿™ä¸ªè¿é€šåŸŸ
                        component_mask = (labels_im == comp_id)
                        cleaned_mask[component_mask] = 1
                
                # ç”¨æ¸…ç†åçš„maskæ›´æ–°enhanced
                enhanced[mask == 1] = 0  # å…ˆæ¸…é™¤æ‰€æœ‰åŸæ¥çš„æ ‡è®°
                enhanced[cleaned_mask == 1] = room_label  # ç„¶åè®¾ç½®éªŒè¯è¿‡çš„åŒºåŸŸ
                
                removed_pixels = np.sum(mask) - np.sum(cleaned_mask)
                print(f"   ğŸ“Š æ¸…ç†ç»“æœï¼šç§»é™¤äº† {removed_pixels} ä¸ªè¯¯è¯†åˆ«åƒç´ ")
        
        return enhanced

    def _apply_color_mapping(self, result_array, original_size):
        """å°†åˆ†å‰²ç»“æœåº”ç”¨é¢œè‰²æ˜ å°„"""
        # è°ƒæ•´åˆ°åŸå§‹å°ºå¯¸
        result_resized = cv2.resize(result_array, original_size, interpolation=cv2.INTER_NEAREST)

        # ä½¿ç”¨ç¼“å­˜çš„è¾¹ç•Œå¢å¼ºï¼Œé¿å…é‡å¤å¤šæ¬¡ç»†åŒ–ç ´åç»“æ„
        result_with_boundaries = self._add_boundary_detection_cached(result_resized)

        # ç”Ÿæˆå½©è‰²å›¾
        h, w = result_with_boundaries.shape
        colored_result = np.zeros((h, w, 3), dtype=np.uint8)
        # ä¸å›¾ä¾‹ç»Ÿä¸€: ä½¿ç”¨ floorplan_fuse_map_figure
        from utils.rgb_ind_convertor import floorplan_fuse_map_figure as _COLOR_MAP
        for label_value, color in _COLOR_MAP.items():
            if label_value > 10:  # å®‰å…¨è¿‡æ»¤ï¼ˆç°ç”¨åˆ°0-10ï¼‰
                continue
            mask = (result_with_boundaries == label_value)
            colored_result[mask] = color

        return colored_result

    def _visualize_ocr_results(self, original_img, room_text_items):
        """å¯è§†åŒ–OCRè¯†åˆ«ç»“æœï¼ˆæ˜¾ç¤ºä¿®æ­£åçš„æ–‡æœ¬ï¼‰"""
        ocr_img = original_img.copy()

        # å®šä¹‰æˆ¿é—´ç±»å‹é¢œè‰²
        room_colors = {
            "å¨æˆ¿": (0, 255, 0),      # ç»¿è‰²
            "å«ç”Ÿé—´": (255, 0, 0),    # è“è‰²
            "å®¢å…": (0, 165, 255),    # æ©™è‰²
            "å§å®¤": (128, 0, 128),    # ç´«è‰²
            "é˜³å°": (255, 255, 0),    # é’è‰²
            "ä¹¦æˆ¿": (165, 42, 42),    # æ£•è‰²
        }

        # OCRä¿®æ­£æ˜ å°„ - ä¿®æ­£å¸¸è§çš„OCRè¯†åˆ«é”™è¯¯
        ocr_corrections = {
            # é˜³å°ç›¸å…³ä¿®æ­£
            "é˜³å…®": "é˜³å°",
            "é˜³å°": "é˜³å°",
            "é™½å°": "é˜³å°",
            "é˜³åˆ": "é˜³å°",
            "é˜³èˆ": "é˜³å°",
            "é˜³å¤": "é˜³å°",

            # å¨æˆ¿ç›¸å…³ä¿®æ­£
            "å¨æˆ¿": "å¨æˆ¿",
            "å»šæˆ¿": "å¨æˆ¿",
            "å¨æˆ·": "å¨æˆ¿",
            "å¨åº": "å¨æˆ¿",
            "åºæˆ¿": "å¨æˆ¿",

            # å«ç”Ÿé—´ç›¸å…³ä¿®æ­£
            "å«ç”Ÿé—´": "å«ç”Ÿé—´",
            "è¡›ç”Ÿé–“": "å«ç”Ÿé—´",
            "å«ç”Ÿé—¬": "å«ç”Ÿé—´",
            "å«ç”Ÿé—¨": "å«ç”Ÿé—´",
            "æµ´å®¤": "å«ç”Ÿé—´",
            "æ´—æ‰‹é—´": "å«ç”Ÿé—´",
            "å•æ‰€": "å«ç”Ÿé—´",

            # å®¢å…ç›¸å…³ä¿®æ­£
            "å®¢å…": "å®¢å…",
            "å®¢å»³": "å®¢å…",
            "å®¢åº”": "å®¢å…",
            "å®¢å¹¿": "å®¢å…",
            "èµ·å±…å®¤": "å®¢å…",
            "ä¼šå®¢å…": "å®¢å…",

            # å§å®¤ç›¸å…³ä¿®æ­£
            "å§å®¤": "å§å®¤",
            "è‡¥å®¤": "å§å®¤",
            "å§å®": "å§å®¤",
            "å§çª’": "å§å®¤",
            "å§ç©º": "å§å®¤",
            "ç½‘æˆ¿": "å§å®¤",
            "ä¸»å§": "ä¸»å§",
            "æ¬¡å§": "æ¬¡å§",

            # ä¹¦æˆ¿ç›¸å…³ä¿®æ­£
            "ä¹¦æˆ¿": "ä¹¦æˆ¿",
            "æ›¸æˆ¿": "ä¹¦æˆ¿",
            "ä¹¦æˆ·": "ä¹¦æˆ¿",
            "ä¹¦åº": "ä¹¦æˆ¿",
            "å­¦ä¹ å®¤": "ä¹¦æˆ¿",
            "å·¥ä½œå®¤": "ä¹¦æˆ¿",

            # é¤å…ç›¸å…³ä¿®æ­£
            "é¤å…": "é¤å…",
            "é¤å»³": "é¤å…",
            "é¥­å…": "é¤å…",
            "ç”¨é¤åŒº": "é¤å…",

            # å…¥æˆ·ç›¸å…³ä¿®æ­£
            "å…¥æˆ·": "å…¥æˆ·",
            "ç„å…³": "å…¥æˆ·",
            "é—¨å…": "å…¥æˆ·",

            # èµ°å»Šç›¸å…³ä¿®æ­£
            "èµ°å»Š": "èµ°å»Š",
            "è¿‡é“": "èµ°å»Š",
            "é€šé“": "èµ°å»Š",

            # å‚¨ç‰©ç›¸å…³ä¿®æ­£
            "å‚¨ç‰©é—´": "å‚¨ç‰©é—´",
            "å‚¨è—å®¤": "å‚¨ç‰©é—´",
            "æ‚ç‰©é—´": "å‚¨ç‰©é—´",
            "è¡£å¸½é—´": "è¡£å¸½é—´",

            # æ¸…ç†å•å­—ç¬¦å™ªéŸ³ï¼ˆå¸¸è§OCRé”™è¯¯è¯†åˆ«ï¼‰
            "é—¨": "",
            "æˆ·": "",
            "å£": "",
            "äºº": "",
            "å¤§": "",
            "å°": "",
            "ä¸­": "",
            "ä¸Š": "",
            "ä¸‹": "",
            "å·¦": "",
            "å³": "",
            "ä¸€": "",
            "äºŒ": "",
            "ä¸‰": "",
            "å››": "",
            "äº”": "",
            "1": "",
            "2": "",
            "3": "",
            "4": "",
            "5": "",
            "6": "",
            "7": "",
            "8": "",
            "9": "",
            "0": "",
            "m": "",
            "M": "",
            "ã¡": "",
            "å¹³": "",
            "æ–¹": "",
            "ç±³": "",
        }

        for item in room_text_items:
            original_text = item["text"]
            bbox = item["bbox"]
            confidence = item.get("confidence", 1.0)

            # ===== åæ ‡ç¼©æ”¾ä¿®æ­£ =====
            # OCRé˜¶æ®µå›¾åƒè¢«æ”¾å¤§2å€(æˆ–å…¶ä»–æ¯”ä¾‹)ï¼Œå½“å‰bboxä»å¤„äºOCRåæ ‡ç³»ï¼Œéœ€è¦æ˜ å°„å›åŸå›¾
            ocr_w = item.get('ocr_width')
            ocr_h = item.get('ocr_height')
            if ocr_w and ocr_h:
                scale_x = ocr_w / original_img.shape[1]
                scale_y = ocr_h / original_img.shape[0]
            else:
                # å›é€€ï¼šå¦‚æœåæ ‡æ˜æ˜¾è¶…å‡ºåŸå›¾å°ºå¯¸ï¼Œå‡è®¾æ”¾å¤§2å€
                scale_x = scale_y = 2.0 if (bbox[0] > original_img.shape[1] or bbox[1] > original_img.shape[0]) else 1.0

            x, y, w, h = bbox
            if scale_x != 1.0 or scale_y != 1.0:
                x = int(x / scale_x)
                y = int(y / scale_y)
                w = max(1, int(w / scale_x))
                h = max(1, int(h / scale_y))
            # ä½¿ç”¨ç¼©æ”¾åçš„å±€éƒ¨å˜é‡ï¼Œä¸ä¿®æ”¹åŸå§‹æ•°æ®

            # 1. è·³è¿‡ç©ºæ–‡æœ¬æˆ–çº¯ç©ºç™½
            if not original_text or not original_text.strip():
                continue

            # 2. è·³è¿‡ä½ç½®ä¿¡åº¦çš„å•å­—ç¬¦ï¼ˆè¿™äº›é€šå¸¸æ˜¯å™ªéŸ³ï¼‰
            if len(original_text.strip()) == 1 and confidence < 0.8:
                continue

            # 3. è·³è¿‡çº¯æ•°å­—ã€çº¯ç¬¦å·æ–‡æœ¬
            cleaned_for_check = original_text.strip()
            if cleaned_for_check.isdigit() or not any(c.isalpha() or c in 'å¨æˆ¿å®¢å…å§å®¤å«ç”Ÿé—´é˜³å°ä¹¦é¤å‚¨è¡£ç„èµ°å»Šè¿‡é“å…¥æˆ·' for c in cleaned_for_check):
                continue

            # 4. è·³è¿‡é•¿åº¦è¿‡çŸ­ä¸”ä¸åŒ…å«æˆ¿é—´å…³é”®è¯çš„æ–‡æœ¬
            if len(cleaned_for_check) < 2 and not any(keyword in cleaned_for_check for keyword in ['å¨', 'å«', 'å®¢', 'å§', 'é˜³', 'ä¹¦', 'é¤']):
                continue

            # 5. è·³è¿‡åŒ…å«æ˜æ˜¾ä¹±ç å­—ç¬¦çš„æ–‡æœ¬
            garbage_chars = {'ï¿½', 'â–¡', 'â– ', 'â–²', 'â–¼', 'â—†', 'â—', 'â—‹', 'â€»', 'â˜…', 'â˜†'}
            if any(char in original_text for char in garbage_chars):
                continue

            # 6. åº”ç”¨OCRä¿®æ­£
            display_text = ocr_corrections.get(original_text, original_text)

            # 7. å¦‚æœä¿®æ­£åä¸ºç©ºï¼Œåˆ™è·³è¿‡
            if not display_text or not display_text.strip():
                continue

            # 8. æœ€åæ£€æŸ¥ï¼šå¦‚æœä¿®æ­£åä»ç„¶æ˜¯å•å­—ç¬¦ä¸”ç½®ä¿¡åº¦ä¸é«˜ï¼Œè·³è¿‡
            if len(display_text.strip()) == 1 and confidence < 0.9:
                continue

            # ç¡®å®šæˆ¿é—´ç±»å‹å’Œé¢œè‰²
            color = (255, 255, 255)  # é»˜è®¤ç™½è‰²
            for room_type, room_color in room_colors.items():
                if any(keyword in display_text.lower() for keyword in [room_type.lower(),
                      {"å¨æˆ¿": "kitchen", "å«ç”Ÿé—´": "bathroom", "å®¢å…": "living",
                       "å§å®¤": "bedroom", "é˜³å°": "balcony", "ä¹¦æˆ¿": "study"}.get(room_type, "")]):
                    color = room_color
                    break

            # ç»˜åˆ¶æ–‡å­—è¾¹ç•Œæ¡†
            cv2.rectangle(ocr_img, (x, y), (x + w, y + h), color, 2)

            # æ ‡ç­¾æ–‡æœ¬å¤„ç†
            if original_text != display_text and display_text:
                label = f"{display_text} (ä¿®æ­£:{original_text})"
                label_color = (255, 165, 0)
            elif display_text:
                label = f"{display_text}"
                label_color = color
            else:
                continue

            font_scale = max(0.5, min(1.0, w / 100))
            thickness = max(1, int(font_scale * 2))

            has_chinese = any('\u4e00' <= c <= '\u9fff' for c in label)
            if has_chinese and CH_FONT_PATH:
                # PIL è·¯å¾„ï¼šåªæè¾¹ + åŠé€æ˜èƒŒæ™¯ï¼ˆé¿å…çº¯ç™½å—ï¼‰
                font_size = max(12, min(32, int(w * 0.5)))
                try:
                    pil_font = ImageFont.truetype(CH_FONT_PATH, font_size)
                except Exception:
                    pil_font = ImageFont.load_default()
                # è½¬ RGBA ä»¥å®ç°åŠé€æ˜
                pil_img = Image.fromarray(ocr_img)
                if pil_img.mode != 'RGBA':
                    pil_img = pil_img.convert('RGBA')
                draw = ImageDraw.Draw(pil_img, 'RGBA')
                text_bbox = draw.textbbox((0, 0), label, font=pil_font)
                tw = text_bbox[2] - text_bbox[0]
                th = text_bbox[3] - text_bbox[1]
                place_above = y - th - 6 >= 0
                if place_above:
                    text_x = x
                    text_y = y - th - 4
                else:
                    text_x = x
                    text_y = y + 2
                bg_x1 = text_x - 3
                bg_y1 = text_y - 2
                bg_x2 = text_x + tw + 3
                bg_y2 = text_y + th + 2
                # åŠé€æ˜èƒŒæ™¯ (ç™½ 30% é€æ˜)
                draw.rectangle([bg_x1, bg_y1, bg_x2, bg_y2], fill=(255, 255, 255, 70), outline=label_color + (255,), width=1)
                draw.text((text_x, text_y), label, font=pil_font, fill=label_color + (255,))
                # å›åˆ°BGR
                ocr_img = np.array(pil_img.convert('RGB'))
            else:
                # OpenCV è·¯å¾„ï¼šç”¨ alpha æ··åˆç”ŸæˆåŠé€æ˜èƒŒæ™¯
                text_size, baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)
                tw, th = text_size
                place_above = y - th - 6 >= 0
                if place_above:
                    text_x = x
                    text_y = y - 4
                    box_y1 = y - th - 6
                    box_y2 = y - 2
                else:
                    text_x = x
                    text_y = y + th + 2
                    box_y1 = y
                    box_y2 = y + th + 8
                box_x1 = x - 2
                box_x2 = x + tw + 4
                # è¾¹ç•Œè£å‰ª
                h_img, w_img = ocr_img.shape[:2]
                box_x1_c = max(0, box_x1); box_y1_c = max(0, box_y1)
                box_x2_c = min(w_img - 1, box_x2); box_y2_c = min(h_img - 1, box_y2)
                if box_x2_c > box_x1_c and box_y2_c > box_y1_c:
                    roi = ocr_img[box_y1_c:box_y2_c, box_x1_c:box_x2_c]
                    overlay = roi.copy()
                    overlay[:] = (255, 255, 255)
                    cv2.addWeighted(overlay, 0.3, roi, 0.7, 0, roi)
                    ocr_img[box_y1_c:box_y2_c, box_x1_c:box_x2_c] = roi
                cv2.rectangle(ocr_img, (box_x1, box_y1), (box_x2, box_y2), label_color, 1)
                cv2.putText(ocr_img, label, (text_x, text_y - 6 if place_above else text_y - 4), cv2.FONT_HERSHEY_SIMPLEX,
                            font_scale, label_color, thickness, cv2.LINE_AA)

        return ocr_img

    def _add_room_annotations(self, ax, room_info):
        """åœ¨å›¾ä¸Šæ·»åŠ æˆ¿é—´æ ‡æ³¨"""
        for room_type, room_list in room_info.items():
            for i, coords in enumerate(room_list):
                if coords["pixels"] > 0:
                    center_x, center_y = coords["center"]
                    bbox = coords["bbox"]
                    raw_text = coords.get("text", "")
                    is_fallback = (raw_text == "åˆ†å‰²æ£€æµ‹") or coords.get('source') == 'segmentation_fallback'

                    # æ ‡æ³¨æˆ¿é—´ä¸­å¿ƒç‚¹
                    ax.plot(center_x, center_y, "o", markersize=10, color="white",
                           markeredgecolor="black", markeredgewidth=2)

                    # æˆ¿é—´æ ‡æ³¨
                    display_name = room_type
                    # è‹¥å­˜åœ¨åŸå§‹OCRæ–‡æœ¬ä¸”ä¸æ˜¯åˆ†å‰²å›é€€ï¼Œä¼˜å…ˆæ˜¾ç¤ºåŸæ–‡æœ¬ï¼ˆä¿ç•™ A/B/C ç­‰åç¼€ï¼‰
                    if raw_text and not is_fallback and raw_text != room_type:
                        display_name = raw_text
                    # å¤šå®ä¾‹åŠ åºå·ï¼ˆåŒæ—¶ä»ä¿ç•™å…·ä½“æ–‡æœ¬ï¼‰
                    if len(room_list) > 1 and not raw_text.startswith(display_name):
                        display_name = f"{display_name}#{i+1}"
                    label_text = f"{display_name}\n({center_x},{center_y})"

                    ax.annotate(label_text, xy=(center_x, center_y), xytext=(10, 10),
                                textcoords="offset points", fontsize=10, fontweight="bold",
                                fontproperties=CH_FONT,
                                bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8),
                                arrowprops=dict(arrowstyle="->", connectionstyle="arc3,rad=0"))

                    # ç»˜åˆ¶è¾¹ç•Œæ¡†
                    x1, y1, x2, y2 = bbox
                    rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False,
                                       edgecolor="red", linewidth=2, linestyle="--")
                    ax.add_patch(rect)

    def _add_color_legend(self, fig):
        """æ·»åŠ é¢œè‰²å›¾ä¾‹ï¼ˆä¸å®é™…ç€è‰²ä¸¥æ ¼ä¸€è‡´ï¼‰

        ä¹‹å‰ç‰ˆæœ¬å›¾ä¾‹é¢œè‰²æ˜¯æ‰‹å†™/ç¤ºæ„è‰²ï¼Œå¯¼è‡´ä¸å®é™… floorplan_fuse_map_figure ä¸­çš„é¢œè‰²ä¸ä¸€è‡´ã€‚
        è¿™é‡Œç›´æ¥è¯»å– utils.rgb_ind_convertor.floorplan_fuse_map_figureï¼Œç¡®ä¿å®Œå…¨åŒæ­¥ã€‚
        """
        from utils.rgb_ind_convertor import floorplan_fuse_map_figure as _COLOR_MAP

        # æ ‡ç­¾ -> ä¸­æ–‡åç§°æ˜ å°„ï¼ˆåªå±•ç¤ºä¸»è¦æˆ¿å‹ + å¢™ä½“/å¼€å£ï¼‰
        label_name_map = {
            7: "å¨æˆ¿",
            2: "å«ç”Ÿé—´",
            3: "å®¢å…",
            4: "å§å®¤",
            6: "é˜³å°",
            8: "ä¹¦æˆ¿",
            9: "å¼€å£",
            10: "å¢™ä½“",
        }

        legend_elements = []
        ordered_labels = [7,2,3,4,6,8,9,10]
        print("ğŸ¨ å›¾ä¾‹åŒæ­¥æ£€æŸ¥: ")
        for label_id in ordered_labels:  # å›ºå®šæ’åºï¼Œæ–¹ä¾¿é˜…è¯»
            if label_id not in _COLOR_MAP:
                continue
            name = label_name_map.get(label_id, str(label_id))
            rgb = _COLOR_MAP[label_id]
            print(f"   - {name} (label {label_id}) é¢œè‰² RGB={rgb}")
            # è½¬ 0-1 èŒƒå›´ (matplotlib éœ€è¦ RGB é¡ºåºï¼›åŸæ˜ å°„å°±æ˜¯ RGB)
            color = np.array(rgb) / 255.0
            legend_elements.append(plt.Rectangle((0, 0), 1, 1, facecolor=color, label=name))

        fig.legend(
            handles=legend_elements,
            loc='upper center',
            bbox_to_anchor=(0.5, 0.02),
            ncol=len(legend_elements),
            fontsize=12,
            prop=CH_FONT,
            frameon=True,
        )

    def generate_results(self, ai_raw_result, ocr_result, fusion_result, final_result,
                         original_img, original_size, output_path, room_text_items):
        """ç”Ÿæˆå››å®«æ ¼å¯¹æ¯”ç»“æœå›¾åƒï¼ˆä¿®æ­£ä¸­æ–‡å­—ä½“æ˜¾ç¤ºä¸º ? çš„é—®é¢˜ï¼‰ã€‚"""
        print("ğŸ¨ ç”Ÿæˆå››å®«æ ¼å¯¹æ¯”ç»“æœå›¾åƒ...")

        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 16))

        room_info = self._extract_room_coordinates(final_result, original_size, room_text_items)
        self.last_room_info = room_info

        # AI åˆ†å‰²
        ai_colored = self._apply_color_mapping(ai_raw_result, original_size)
        ax1.imshow(cv2.addWeighted(original_img, 0.5, ai_colored, 0.5, 0))
        ax1.set_title("ğŸ¤– AIè¯­ä¹‰åˆ†å‰²ç»“æœ", fontsize=14, fontweight="bold", fontproperties=CH_FONT)
        ax1.grid(True, alpha=0.3)
        ax1.set_xlabel("Xåæ ‡ (åƒç´ )", fontsize=12, fontproperties=CH_FONT)
        ax1.set_ylabel("Yåæ ‡ (åƒç´ )", fontsize=12, fontproperties=CH_FONT)

        # OCR
        ocr_colored = self._visualize_ocr_results(original_img, room_text_items)
        ax2.imshow(ocr_colored)
        ax2.set_title("ğŸ” OCRæ–‡å­—è¯†åˆ«ç»“æœ", fontsize=14, fontweight="bold", fontproperties=CH_FONT)
        ax2.grid(True, alpha=0.3)
        ax2.set_xlabel("Xåæ ‡ (åƒç´ )", fontsize=12, fontproperties=CH_FONT)
        ax2.set_ylabel("Yåæ ‡ (åƒç´ )", fontsize=12, fontproperties=CH_FONT)

        # èåˆ
        fusion_colored = self._apply_color_mapping(fusion_result, original_size)
        ax3.imshow(cv2.addWeighted(original_img, 0.5, fusion_colored, 0.5, 0))
        ax3.set_title("ğŸ”— AI+OCRèåˆç»“æœ", fontsize=14, fontweight="bold", fontproperties=CH_FONT)
        ax3.grid(True, alpha=0.3)
        ax3.set_xlabel("Xåæ ‡ (åƒç´ )", fontsize=12, fontproperties=CH_FONT)
        ax3.set_ylabel("Yåæ ‡ (åƒç´ )", fontsize=12, fontproperties=CH_FONT)

        # æœ€ç»ˆ
        final_colored = self._apply_color_mapping(final_result, original_size)
        final_overlay = cv2.addWeighted(original_img, 0.5, final_colored, 0.5, 0)

        # ===== ç«–çº¿(x=600)è°ƒè¯•è¾…åŠ© =====
        try:
            ow, oh = original_size
            probe_x = 600
            if ow > probe_x and final_result is not None:
                # final_result ä»åœ¨ 512 å°ºåº¦ (å®½=512) => æ˜ å°„åˆ—ç´¢å¼•
                fr_w = final_result.shape[1]
                mapped_col = int(round(probe_x * fr_w / float(ow)))
                col_vals = final_result[:, mapped_col]
                import numpy as _np
                uniq, cnt = _np.unique(col_vals, return_counts=True)
                dist = {int(u): int(c) for u, c in zip(uniq, cnt)}
                wall_len = dist.get(10, 0) + dist.get(9, 0)
                continuous_wall = wall_len >= (final_result.shape[0] * 0.95)
                print(f"ğŸ” [ç«–çº¿è¯Šæ–­] åŸå›¾x={probe_x} -> 512åˆ—={mapped_col}, æ ‡ç­¾åˆ†å¸ƒ={dist}, æ˜¯å¦å‡ ä¹æ•´åˆ—å¢™ä½“={continuous_wall}")
                if not continuous_wall:
                    print("âœ… åˆ¤å®š: è¯¥ç«–çº¿æ›´å¯èƒ½æ˜¯å¯è§†åŒ–ç½‘æ ¼/å åŠ ä¼ªå½±, ä¸å½±å“è¯†åˆ«é€»è¾‘")
                else:
                    print("âš ï¸ åˆ¤å®š: è¯¥åˆ—æ¥è¿‘æ•´åˆ—å¢™ä½“, å¯èƒ½æ¥æºäºå¢™ä½“ç»†åŒ–ç®—æ³•, å¯è¿›ä¸€æ­¥æ’æŸ¥ _add_boundary_detection ä¸­ endpoint è¿æ¥é€»è¾‘")
        except Exception as _e:
            print(f"âš ï¸ [ç«–çº¿è¯Šæ–­] å‘ç”Ÿå¼‚å¸¸: {_e}")
        ax4.imshow(final_overlay)
        ax4.set_title("âœ… åˆç†æ€§éªŒè¯åæœ€ç»ˆç»“æœ", fontsize=14, fontweight="bold", fontproperties=CH_FONT)
        ax4.grid(True, alpha=0.3)
        ax4.set_xlabel("Xåæ ‡ (åƒç´ )", fontsize=12, fontproperties=CH_FONT)
        ax4.set_ylabel("Yåæ ‡ (åƒç´ )", fontsize=12, fontproperties=CH_FONT)

        self._add_room_annotations(ax4, room_info)
        self._add_color_legend(fig)
        plt.tight_layout()

        os.makedirs("output", exist_ok=True)
        comparison_output = f"output/{output_path}_coordinate_result.png"
        plt.savefig(comparison_output, dpi=300, bbox_inches="tight")
        print(f"ğŸ“Š å››å®«æ ¼å¯¹æ¯”ç»“æœå·²ä¿å­˜: {comparison_output}")

        # å•ç‹¬æœ€ç»ˆç»“æœ
        plt.figure(figsize=(12, 8))
        plt.imshow(final_overlay)
        plt.title("æˆ¿é—´æ£€æµ‹æœ€ç»ˆç»“æœ", fontsize=16, fontweight="bold", fontproperties=CH_FONT)
        plt.grid(True, alpha=0.3)
        plt.xlabel("Xåæ ‡ (åƒç´ )", fontsize=12, fontproperties=CH_FONT)
        plt.ylabel("Yåæ ‡ (åƒç´ )", fontsize=12, fontproperties=CH_FONT)
        for room_type, room_list in room_info.items():
            for i, coords in enumerate(room_list):
                if coords["pixels"] <= 0:
                    continue
                center_x, center_y = coords["center"]
                x1, y1, x2, y2 = coords["bbox"]
                plt.plot(center_x, center_y, "o", markersize=10, color="white",
                         markeredgecolor="black", markeredgewidth=2)
                if len(room_list) > 1:
                    label_text = f"{room_type}{i+1}\n({center_x},{center_y})"
                else:
                    label_text = f"{room_type}\n({center_x},{center_y})"
                plt.annotate(label_text, xy=(center_x, center_y), xytext=(10, 10),
                             textcoords="offset points", fontsize=10, fontweight="bold",
                             fontproperties=CH_FONT,
                             bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8),
                             arrowprops=dict(arrowstyle="->", connectionstyle="arc3,rad=0"))
                rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False,
                                     edgecolor="red", linewidth=2, linestyle="--")
                plt.gca().add_patch(rect)
        standard_output = f"output/{output_path}_result.png"
        plt.savefig(standard_output, dpi=300, bbox_inches="tight")
        print(f"ğŸ“¸ æ ‡å‡†ç»“æœå·²ä¿å­˜: {standard_output}")
        plt.close('all')

        # ====== å¯¼å‡ºè¾¹ç•Œæ–‡ä»¶ï¼ˆå•ç‹¬ï¼‰======
        try:
            boundary_labeled = self._add_boundary_detection_cached(final_result.copy())  # åœ¨ 512x512 ç©ºé—´
            # æå–ä»…åŒ…å« 9/10 æ ‡ç­¾çš„è¾¹ç•Œæ©è†œ
            boundary_only = np.zeros_like(boundary_labeled)
            boundary_only[np.isin(boundary_labeled, [9, 10])] = boundary_labeled[np.isin(boundary_labeled, [9, 10])]

            # ç”Ÿæˆå½©è‰²è¾¹ç•Œå›¾ (ç™½åº• + å¼€å£æ´‹çº¢ + å¢™ä½“é»‘)
            boundary_color = np.full((boundary_only.shape[0], boundary_only.shape[1], 3), 255, dtype=np.uint8)
            boundary_color[boundary_only == 9] = [255, 60, 128]   # openings
            boundary_color[boundary_only == 10] = [0, 0, 0]       # walls

            # æ”¾å¤§å›åŸå§‹å°ºå¯¸
            boundary_color_resized = cv2.resize(boundary_color, original_size, interpolation=cv2.INTER_NEAREST)
            boundary_mask_binary = np.zeros((boundary_only.shape[0], boundary_only.shape[1]), dtype=np.uint8)
            boundary_mask_binary[boundary_only == 10] = 255  # å¢™ä½“
            boundary_mask_binary[boundary_only == 9] = 128   # å¼€å£
            boundary_mask_resized = cv2.resize(boundary_mask_binary, original_size, interpolation=cv2.INTER_NEAREST)

            boundary_png = f"output/{output_path}_boundary.png"
            boundary_mask_png = f"output/{output_path}_boundary_mask.png"
            cv2.imwrite(boundary_png, cv2.cvtColor(boundary_color_resized, cv2.COLOR_RGB2BGR))
            cv2.imwrite(boundary_mask_png, boundary_mask_resized)
            print(f"ğŸ§± è¾¹ç•Œå½©è‰²å›¾å·²ä¿å­˜: {boundary_png}")
            print(f"ğŸ§± è¾¹ç•Œæ©è†œå›¾å·²ä¿å­˜: {boundary_mask_png}")

            # è¿½åŠ ï¼šå¢™ä½“ + å¼€å£ çŸ¢é‡åŒ– & SVG/DXF å¯¼å‡º
            try:
                vec_data = self._vectorize_walls(boundary_mask_binary, original_size)
                svg_out = f"output/{output_path}_walls.svg"
                dxf_out = f"output/{output_path}_walls.dxf"
                self._export_walls_svg(svg_out, vec_data, original_size)
                self._export_walls_dxf(dxf_out, vec_data, original_size)
                print(f"ğŸ—ºï¸ çŸ¢é‡å¢™ä½“å¯¼å‡º: SVG {len(vec_data['walls_segments'])} æ®µ / DXF å¤šæ®µçº¿ {len(vec_data['walls_polylines'])}")
            except Exception as _ve:
                print(f"âš ï¸ çŸ¢é‡å¢™ä½“å¯¼å‡ºå¤±è´¥: {_ve}")
        except Exception as e:
            print(f"âš ï¸ è¾¹ç•Œå¯¼å‡ºå¤±è´¥: {e}")

        # ç»“æ„åŒ–JSONå¯¼å‡º
        try:
            json_path = f"output/{output_path}_result.json"
            self._export_room_json(room_info, original_size, json_path, room_text_items, image_output=standard_output)
            print(f"ğŸ§¾ ç»“æ„åŒ–æˆ¿é—´æ•°æ®å·²ä¿å­˜: {json_path}")
        except Exception as e:
            print(f"âš ï¸ JSONå¯¼å‡ºå¤±è´¥: {e}")
        return standard_output

    def _export_room_json(self, room_info, original_size, json_path, ocr_items, image_output=None):
        """å¯¼å‡ºæˆ¿é—´è¯†åˆ«ç»“æœä¸ºJSONï¼Œä¾¿äºåç»­é£æ°´/ç©ºé—´åˆ†æã€‚

        JSONç»“æ„:
        {
          "meta": { åŸå›¾å°ºå¯¸/æ—¶é—´/è¾“å‡ºå›¾åƒç­‰ },
          "rooms": [
             {
               "type": "å§å®¤",
               "index": 1,              # åŒç±»å‹åºå·ï¼ˆä»1èµ·ï¼‰
               "label_id": 4,
               "center": {"x":123, "y":245},
               "center_normalized": {"x":0.35, "y":0.62},
               "bbox": {"x1":..,"y1":..,"x2":..,"y2":..,"width":..,"height":..},
               "area_pixels": 3456,      # ç›®å‰åŸºäºbboxåƒç´ ä¼°è®¡ï¼ˆè‹¥éœ€çœŸå®maské¢ç§¯å¯åç»­æ‰©å±•ï¼‰
               "text_raw": "å§å®¤",
               "confidence": 0.91,
               "distance_to_center": 210.4,
               "direction_8": "ä¸œåŒ—"     # ä»¥å›¾åƒä¸Šæ–¹ä¸ºåŒ—ï¼Œå·¦ä¸ºè¥¿
             }, ...
          ]
        }
        """
        orig_w, orig_h = original_size
        img_cx, img_cy = orig_w / 2.0, orig_h / 2.0

        # æˆ¿é—´ä¸­æ–‡åˆ°labelæ˜ å°„ï¼ˆä¸ _extract_room_coordinates ä¸­ä¸€è‡´ï¼‰
        name_to_label = {"å¨æˆ¿":7, "å«ç”Ÿé—´":2, "å®¢å…":3, "å§å®¤":4, "é˜³å°":6, "ä¹¦æˆ¿":8}

        def direction_from_vector(dx, dy):
            # å›¾åƒåæ ‡: yå‘ä¸‹ -> åŒ—åœ¨ä¸Šæ–¹ => dy<0 ä¸ºåŒ—
            angle = (np.degrees(np.arctan2(-dy, dx)) + 360) % 360  # 0=ä¸œ, 90=åŒ—
            dirs = ["ä¸œ", "ä¸œåŒ—", "åŒ—", "è¥¿åŒ—", "è¥¿", "è¥¿å—", "å—", "ä¸œå—"]
            idx = int(((angle + 22.5) % 360) / 45)
            return dirs[idx]

        rooms_json = []
        for room_type, room_list in room_info.items():
            for idx, info in enumerate(room_list, start=1):
                if info.get('pixels', 0) <= 0:
                    continue
                cx, cy = info['center']
                x1, y1, x2, y2 = info['bbox']
                width = info.get('width', x2 - x1 + 1)
                height = info.get('height', y2 - y1 + 1)
                # ä½¿ç”¨bboxé¢ç§¯ä½œä¸ºè¿‘ä¼¼
                area_pixels = width * height
                dx = cx - img_cx
                dy = cy - img_cy
                dist = float(np.hypot(dx, dy))
                direction = direction_from_vector(dx, dy)
                rooms_json.append({
                    "type": room_type,
                    "index": idx,
                    "label_id": name_to_label.get(room_type, -1),
                    "center": {"x": int(cx), "y": int(cy)},
                    "center_normalized": {"x": round(cx / orig_w, 4), "y": round(cy / orig_h, 4)},
                    "bbox": {"x1": int(x1), "y1": int(y1), "x2": int(x2), "y2": int(y2), "width": int(width), "height": int(height)},
                    "area_pixels": int(area_pixels),
                    "text_raw": info.get('text', ''),
                    "confidence": round(float(info.get('confidence', 0.0)), 4),
                    "distance_to_center": round(dist, 2),
                    "direction_8": direction,
                })

        data = {
            "meta": {
                "timestamp": datetime.utcnow().isoformat() + 'Z',
                "image_width": orig_w,
                "image_height": orig_h,
                "rooms_detected": len(rooms_json),
                "output_image": image_output,
                "note": "æ–¹å‘åŸºäºå›¾åƒä¸ŠåŒ—ä¸‹å—å·¦è¥¿å³ä¸œçš„é»˜è®¤å‡è®¾; è‹¥å›¾çº¸æœå‘ä¸åŒéœ€è°ƒæ•´ã€‚"
            },
            "rooms": rooms_json
        }

        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    def _add_boundary_detection(self, enhanced):
        """æ”¹è¿›ç‰ˆå¢™ä½“/è¾¹ç•Œæå– (V2+ æ‰©å±•)"""
        print("ğŸ”² è¾¹ç•Œé‡æ„(V2+ æ‰©å±•: è½®å»“ç®€åŒ– + ç›´çº¿æ‹Ÿåˆ)...")
        arr = enhanced.copy()
        room_labels = {2,3,4,6,7,8}
        wall_labels = {9,10}
        original_wall_mask = np.isin(arr, list(wall_labels))

        # 1) å¹³æ»‘ & æå°ç¢ç‰‡è¿‡æ»¤ + è½®å»“ç®€åŒ–
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))
        smoothed = arr.copy()
        MIN_ROOM_COMPONENT = 25
        for lbl in room_labels:
            mask = (arr==lbl).astype(np.uint8)
            if mask.sum()==0:
                continue
            num_c, lab_c, stats_c, _ = cv2.connectedComponentsWithStats(mask, connectivity=4)
            for cid in range(1, num_c):
                if stats_c[cid, cv2.CC_STAT_AREA] < MIN_ROOM_COMPONENT:
                    mask[lab_c==cid] = 0
            closed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=1)
            opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel, iterations=1)
            try:
                contours,_ = cv2.findContours(opened, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                simp = np.zeros_like(opened)
                for cnt in contours:
                    peri = cv2.arcLength(cnt, True)
                    eps = max(1.0, 0.005*peri)
                    approx = cv2.approxPolyDP(cnt, eps, True)
                    cv2.fillPoly(simp,[approx],1)
                opened = simp
            except Exception:
                pass
            smoothed[opened==1] = lbl
        smoothed[original_wall_mask] = arr[original_wall_mask]

        # 2) æ ‡ç­¾å·®åˆ†
        padded = np.pad(smoothed,1,mode='edge')
        center = padded[1:-1,1:-1]
        up = padded[0:-2,1:-1]; down = padded[2:,1:-1]; left = padded[1:-1,0:-2]; right = padded[1:-1,2:]
        def diff_mask(neigh):
            return (center!=neigh) & (np.isin(center,list(room_labels)) | np.isin(neigh,list(room_labels)) | (center==0) | (neigh==0))
        boundary_candidates = diff_mask(up)|diff_mask(down)|diff_mask(left)|diff_mask(right)
        candidate_mask = boundary_candidates.astype(np.uint8)

        # 3) ç»†åŒ–
        def zhang_suen_thinning(bin_img):
            img = bin_img.copy().astype(np.uint8)
            changed=True
            while changed:
                changed=False
                to_remove=[]
                for y in range(1,img.shape[0]-1):
                    for x in range(1,img.shape[1]-1):
                        if img[y,x]==1:
                            P2=img[y-1,x];P3=img[y-1,x+1];P4=img[y,x+1];P5=img[y+1,x+1];P6=img[y+1,x];P7=img[y+1,x-1];P8=img[y,x-1];P9=img[y-1,x-1]
                            nbr=[P2,P3,P4,P5,P6,P7,P8,P9]; cnt=sum(nbr)
                            if 2<=cnt<=6:
                                trans=0
                                for i in range(8):
                                    if nbr[i]==0 and nbr[(i+1)%8]==1: trans+=1
                                if trans==1 and (P2*P4*P6)==0 and (P4*P6*P8)==0: to_remove.append((y,x))
                if to_remove:
                    changed=True
                    for y,x in to_remove: img[y,x]=0
                to_remove=[]
                for y in range(1,img.shape[0]-1):
                    for x in range(1,img.shape[1]-1):
                        if img[y,x]==1:
                            P2=img[y-1,x];P3=img[y-1,x+1];P4=img[y,x+1];P5=img[y+1,x+1];P6=img[y+1,x];P7=img[y+1,x-1];P8=img[y,x-1];P9=img[y-1,x-1]
                            nbr=[P2,P3,P4,P5,P6,P7,P8,P9]; cnt=sum(nbr)
                            if 2<=cnt<=6:
                                trans=0
                                for i in range(8):
                                    if nbr[i]==0 and nbr[(i+1)%8]==1: trans+=1
                                if trans==1 and (P2*P4*P8)==0 and (P2*P6*P8)==0: to_remove.append((y,x))
                if to_remove:
                    changed=True
                    for y,x in to_remove: img[y,x]=0
            return img
        skeleton = zhang_suen_thinning(candidate_mask)

        # Hough è¡¥å¼º
        try:
            ls = (candidate_mask*255).astype(np.uint8)
            lines = cv2.HoughLinesP(ls,1,np.pi/180,threshold=18,minLineLength=14,maxLineGap=4)
            if lines is not None:
                hmask = np.zeros_like(skeleton)
                for l in lines[:1500]:
                    x1,y1,x2,y2 = l[0]; cv2.line(hmask,(x1,y1),(x2,y2),1,1)
                skeleton = ((skeleton==1)|(hmask==1)).astype(np.uint8)
                print(f"   ğŸ“ Hough ç›´çº¿è¡¥å¼º: {len(lines)} æ¡")
        except Exception as _e:
            print(f"   âš ï¸ Hough è·³è¿‡: {_e}")

        # 4) å¸é™„ä¸åŠ ç²—
        ORTHO_TOL=15; allow_diagonal=True
        skel_arr=skeleton.copy(); new_skel=np.zeros_like(skel_arr)
        num_s,lab_s,stats_s,_ = cv2.connectedComponentsWithStats(skel_arr.astype(np.uint8),connectivity=8)
        for sid in range(1,num_s):
            comp=(lab_s==sid); ys,xs=np.where(comp)
            if xs.size<3: new_skel[comp]=1; continue
            xc=xs.mean(); yc=ys.mean(); xz=xs-xc; yz=ys-yc
            cov=np.cov(np.vstack((xz,yz))); eigvals,eigvecs=np.linalg.eig(cov)
            vx,vy=eigvecs[:,np.argmax(eigvals)]; angle=(np.degrees(np.arctan2(vy,vx))+180)%180
            if angle<ORTHO_TOL or angle>180-ORTHO_TOL:
                yline=int(round(yc)); new_skel[yline, xs.min():xs.max()+1]=1
            elif abs(angle-90)<ORTHO_TOL:
                xline=int(round(xc)); new_skel[ys.min():ys.max()+1, xline]=1
            else:
                if allow_diagonal: new_skel[comp]=1
                else:
                    for ux in np.unique(xs):
                        yv=ys[xs==ux]; new_skel[int(np.median(yv)), ux]=1
        skeleton=new_skel

        if np.any(skeleton):
            dil=cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))
            thick=cv2.dilate(skeleton.astype(np.uint8),dil,iterations=1)
        else:
            thick=skeleton

        def merge_small_gaps(m):
            merged=m.copy()
            # è¡Œ
            for y in range(merged.shape[0]):
                xs=np.where(merged[y]==1)[0]
                if xs.size==0: continue
                pv=xs[0]
                for x in xs[1:]:
                    gap=x-pv-1
                    if 0<gap<=2: merged[y,pv+1:x]=1
                    pv=x
            # åˆ—
            for x in range(merged.shape[1]):
                ys=np.where(merged[:,x]==1)[0]
                if ys.size==0: continue
                pv=ys[0]
                for y in ys[1:]:
                    gap=y-pv-1
                    if 0<gap<=2: merged[pv+1:y,x]=1
                    pv=y
            return merged
        thick=merge_small_gaps(thick.astype(np.uint8))

        def close_endpoints(m):
            lm=m.copy(); H,W=lm.shape; dirs=[(1,0),(-1,0),(0,1),(0,-1)]
            endpoints=[]
            for y in range(H):
                for x in range(W):
                    if lm[y,x]==1:
                        deg=0
                        for dx,dy in dirs:
                            nx,ny=x+dx,y+dy
                            if 0<=nx<W and 0<=ny<H and lm[ny,nx]==1: deg+=1
                        if deg==1: endpoints.append((x,y))
            used=set()
            for i,(x1,y1) in enumerate(endpoints):
                if i in used: continue
                best=None; bestd=1e9
                for j,(x2,y2) in enumerate(endpoints):
                    if j<=i or j in used: continue
                    dx=abs(x2-x1); dy=abs(y2-y1)
                    if max(dx,dy)<=5 and ((y1==y2) or (x1==x2) or (dx+dy)<=5):
                        d=dx+dy
                        if d<bestd: bestd=d; best=j
                if best is not None:
                    x2,y2=endpoints[best]
                    if y1==y2: lm[y1,min(x1,x2):max(x1,x2)+1]=1
                    elif x1==x2: lm[min(y1,y2):max(y1,y2)+1,x1]=1
                    else:
                        lm[y1,min(x1,x2):max(x1,x2)+1]=1
                        lm[min(y1,y2):max(y1,y2)+1,x2]=1
                    used.add(i); used.add(best)
            return lm
        thick=close_endpoints(thick)

        # 5) å¢™ä½“ç˜¦èº« + éª¨æ¶èåˆ
        wall_mask_initial=(arr==10).astype(np.uint8)
        num,labels_im,stats,_=cv2.connectedComponentsWithStats(wall_mask_initial,connectivity=4)
        large_perimeter_mask=np.zeros_like(wall_mask_initial)
        for comp in range(1,num):
            area=stats[comp,cv2.CC_STAT_AREA]
            if area>400:
                comp_mask=(labels_im==comp).astype(np.uint8)
                eroded=cv2.erode(comp_mask,kernel,iterations=1)
                perimeter=comp_mask-eroded
                large_perimeter_mask[perimeter==1]=1
            else:
                large_perimeter_mask[labels_im==comp]=1

        new_arr=arr.copy()
        new_arr[new_arr==10]=0
        new_arr[large_perimeter_mask==1]=10
        add_mask=(thick==1) & (~np.isin(new_arr,[9,10]))
        new_arr[add_mask]=10

        # 6) å™ªç‚¹æ¸…ç†
        wall_mask_final=(new_arr==10).astype(np.uint8)
        num2,labels2,stats2,_=cv2.connectedComponentsWithStats(wall_mask_final,connectivity=8)
        removed=0
        for comp in range(1,num2):
            area=stats2[comp,cv2.CC_STAT_AREA]
            if area<3:
                removed+=area
                new_arr[labels2==comp]=0
        added=int(add_mask.sum())
        # 7) ç«–ç›´æ•´åˆ—ä¼ªå¢™æŠ‘åˆ¶ (å‡ ä¹å…¨é«˜ä¸”å­¤ç«‹çš„ç»†åˆ—)
        H,W=new_arr.shape; removed_cols=0
        col_wall_ratio = []
        for cx in range(W):
            col_vals = new_arr[:,cx]
            wall_ratio = (col_vals==10).mean()
            col_wall_ratio.append(wall_ratio)
        import numpy as _np
        col_wall_ratio = _np.array(col_wall_ratio)
        # è®¡ç®—å·¦å³ç›¸é‚»å¹³å‡ï¼Œåˆ¤æ–­å­¤ç«‹
        for cx in range(W):
            wr = col_wall_ratio[cx]
            if wr>0.95:  # å‡ ä¹æ•´åˆ—å¢™
                left_wr = col_wall_ratio[cx-1] if cx-1>=0 else 1.0
                right_wr = col_wall_ratio[cx+1] if cx+1<W else 1.0
                # ä¸¤ä¾§éƒ½ä¸æ˜¯å¤§æ¯”ä¾‹å¢™ä½“ï¼Œè¯´æ˜çªå…€
                if left_wr<0.30 and right_wr<0.30:
                    new_arr[new_arr[:,cx]==10, cx]=0
                    removed_cols+=1
        if removed_cols>0:
            print(f"ğŸ› ï¸ ä¼ªç«–å¢™åˆ—æŠ‘åˆ¶: ç§»é™¤ {removed_cols} åˆ—æ¥è¿‘å…¨é«˜çš„å­¤ç«‹ç«–çº¿")
        print(f"âœ… è¾¹ç•Œé‡æ„å®Œæˆ: æ–°å¢å¢™ä½“ {added} åƒç´ , æ¸…ç†å™ªç‚¹ {removed} åƒç´ , ä¼ªåˆ—ç§»é™¤ {removed_cols} åˆ—, å¤§å—ç»„ä»¶ {num-1} -> {np.unique(labels2).size-1}")
        return new_arr

    def _add_boundary_detection_cached(self, enhanced):
        """å¸¦ç¼“å­˜åŒ…è£…ï¼Œé¿å…åŒä¸€ label å›¾å¤šæ¬¡ç»†åŒ–å¯¼è‡´ç¢è£‚"""
        try:
            import hashlib
            key = hashlib.md5(enhanced.tobytes()).hexdigest()
        except Exception:
            key = str(id(enhanced))
        if key in self._boundary_cache:
            return self._boundary_cache[key]
        result = self._add_boundary_detection(enhanced)
        self._boundary_cache[key] = result
        return result

    # ===== çŸ¢é‡åŒ–: ä»å¢™ä½“äºŒå€¼å›¾æå–çº¿æ®µå¹¶å¯¼å‡º SVG =====
    def _vectorize_walls(self, boundary_mask_binary, original_size):
        """è¿”å›å­—å…¸: {walls_segments, walls_polylines, openings_segments} (å‡å·²ç¼©æ”¾åˆ°åŸå°ºå¯¸)"""
        import numpy as np, cv2, math
        ow,oh = original_size
        wall_mask_512 = (boundary_mask_binary==255).astype(np.uint8)
        open_mask_512 = (boundary_mask_binary==128).astype(np.uint8)

        def skeletonize(mask):
            skel = mask.copy()
            def thin_once(img):
                h,w=img.shape; remove=[]
                for y in range(1,h-1):
                    for x in range(1,w-1):
                        if img[y,x]==1:
                            P2=img[y-1,x];P3=img[y-1,x+1];P4=img[y,x+1];P5=img[y+1,x+1];P6=img[y+1,x];P7=img[y+1,x-1];P8=img[y,x-1];P9=img[y-1,x-1]
                            nbr=[P2,P3,P4,P5,P6,P7,P8,P9]; cnt=sum(nbr)
                            if 2<=cnt<=6:
                                trans=0
                                for i in range(8):
                                    if nbr[i]==0 and nbr[(i+1)%8]==1: trans+=1
                                if trans==1 and (P2*P4*P6)==0 and (P4*P6*P8)==0:
                                    remove.append((y,x))
                for (y,x) in remove: img[y,x]=0
                return len(remove)>0
            it=0
            while thin_once(skel) and it<8: it+=1
            return skel

        def chains_from_skel(skel):
            h,w=skel.shape; visited=np.zeros_like(skel,bool)
            dirs=[(-1,0),(1,0),(0,-1),(0,1),(-1,-1),(-1,1),(1,-1),(1,1)]
            chains=[]
            for y in range(h):
                for x in range(w):
                    if skel[y,x]==1 and not visited[y,x]:
                        stack=[(x,y)]; visited[y,x]=True; pts=[]
                        while stack:
                            cx,cy=stack.pop(); pts.append((cx,cy))
                            for dx,dy in dirs:
                                nx,ny=cx+dx,cy+dy
                                if 0<=nx<w and 0<=ny<h and skel[ny,nx]==1 and not visited[ny,nx]:
                                    visited[ny,nx]=True; stack.append((nx,ny))
                        if len(pts)>=3: chains.append(pts)
            return chains

        def rdp(points, eps=1.8):
            if len(points)<3: return points
            x1,y1=points[0]; x2,y2=points[-1]; A=np.array([x2-x1,y2-y1]); L=np.linalg.norm(A)
            if L==0: dists=[0]*len(points)
            else:
                dists=[]
                for (x,y) in points:
                    v=np.array([x-x1,y-y1]); proj=(v@A)/L if L else 0
                    proj_pt=np.array([x1,y1]) + (proj/L)*A if L else np.array([x1,y1])
                    dists.append(np.linalg.norm(np.array([x,y])-proj_pt))
            idx=int(np.argmax(dists))
            if dists[idx]>eps:
                return rdp(points[:idx+1],eps)[:-1]+rdp(points[idx:],eps)
            return [points[0],points[-1]]

        def chains_to_segments(chains):
            segs=[]
            for c in chains:
                c_sorted=sorted(c)
                simp=rdp(c_sorted)
                for i in range(len(simp)-1):
                    x1,y1=simp[i]; x2,y2=simp[i+1]
                    if (x1,y1)!=(x2,y2): segs.append((x1,y1,x2,y2))
            return segs

        def merge_colinear(segments, ang_tol=6, dist_tol=4):
            segments=list(segments); merged=True
            def colinear(a,b):
                x1,y1,x2,y2=a; x3,y3,x4,y4=b
                v1=np.array([x2-x1,y2-y1]); v2=np.array([x4-x3,y4-y3])
                n1=np.linalg.norm(v1); n2=np.linalg.norm(v2)
                if n1==0 or n2==0: return False
                ang=math.degrees(math.acos(np.clip((v1@v2)/(n1*n2),-1,1)))
                if ang>ang_tol: return False
                for p in [(x1,y1),(x2,y2)]:
                    for q in [(x3,y3),(x4,y4)]:
                        if ( (p[0]-q[0])**2+(p[1]-q[1])**2 )**0.5 < dist_tol: return True
                return False
            while merged:
                merged=False; out=[]; used=[False]*len(segments)
                for i,a in enumerate(segments):
                    if used[i]: continue
                    ax1,ay1,ax2,ay2=a; vax=np.array([ax2-ax1, ay2-ay1])
                    for j,b in enumerate(segments):
                        if j<=i or used[j]: continue
                        if colinear(a,b):
                            bx1,by1,bx2,by2=b
                            pts=[(ax1,ay1),(ax2,ay2),(bx1,by1),(bx2,by2)]
                            if abs(vax[0])>=abs(vax[1]): pts=sorted(pts,key=lambda p:p[0])
                            else: pts=sorted(pts,key=lambda p:p[1])
                            ax1,ay1=pts[0]; ax2,ay2=pts[-1]
                            used[j]=True; merged=True
                    used[i]=True; out.append((ax1,ay1,ax2,ay2))
                segments=out
            return segments

        def angle_snap(segments, ang_set=(0,45,90,135), tol=12):
            snapped=[]
            for (x1,y1,x2,y2) in segments:
                dx=x2-x1; dy=y2-y1
                if dx==0 and dy==0: continue
                ang= (math.degrees(math.atan2(dy,dx)) + 180) % 180
                best=None; best_diff=999
                for a in ang_set:
                    diff=min(abs(ang-a), 180-abs(ang-a))
                    if diff<best_diff: best_diff=diff; best=a
                if best_diff<=tol:
                    # ä»¥ä¸­ç‚¹ & åŸé•¿åº¦é‡æ–°æ„é€ 
                    L=(dx*dx+dy*dy)**0.5
                    cx=(x1+x2)/2; cy=(y1+y2)/2
                    rad=math.radians(best)
                    hx=(L/2)*math.cos(rad); hy=(L/2)*math.sin(rad)
                    nx1=cx-hx; ny1=cy-hy; nx2=cx+hx; ny2=cy+hy
                    snapped.append((int(round(nx1)),int(round(ny1)),int(round(nx2)),int(round(ny2))))
                else:
                    snapped.append((x1,y1,x2,y2))
            return snapped

        def segments_to_polylines(segments, join_tol=4):
            # æ„é€ ç«¯ç‚¹å›¾
            pts=[]
            for (x1,y1,x2,y2) in segments: pts.extend([(x1,y1),(x2,y2)])
            # å»é‡
            uniq=[]
            for p in pts:
                if not any((abs(p[0]-q[0])<=1 and abs(p[1]-q[1])<=1) for q in uniq): uniq.append(p)
            # æ˜ å°„
            def find_idx(p):
                for i,q in enumerate(uniq):
                    if abs(p[0]-q[0])<=1 and abs(p[1]-q[1])<=1: return i
                uniq.append(p); return len(uniq)-1
            adj={i:set() for i in range(len(uniq))}
            for (x1,y1,x2,y2) in segments:
                i1=find_idx((x1,y1)); i2=find_idx((x2,y2))
                adj[i1].add(i2); adj[i2].add(i1)
            polylines=[]; visited=set()
            for start in adj:
                if start in visited: continue
                # çº¿æ€§é“¾/ç¯éå†
                stack=[start]; current=[]
                while stack:
                    v=stack.pop();
                    if v in visited: continue
                    visited.add(v); current.append(uniq[v])
                    for nb in adj[v]:
                        if nb not in visited: stack.append(nb)
                if len(current)>=2: polylines.append(sorted(current))
            return polylines

        def scale_segments(segs):
            scaled=[]
            for (x1,y1,x2,y2) in segs:
                sx1=int(round(x1/512*ow)); sy1=int(round(y1/512*oh))
                sx2=int(round(x2/512*ow)); sy2=int(round(y2/512*oh))
                if (sx1,sy1)!=(sx2,sy2): scaled.append((sx1,sy1,sx2,sy2))
            return scaled

        # ========== å¢™ä½“å¤„ç† ==========
        wall_skel = skeletonize(wall_mask_512)
        wall_chains = chains_from_skel(wall_skel)
        wall_segments = chains_to_segments(wall_chains)
        wall_segments = merge_colinear(angle_snap(wall_segments))
        wall_polylines = segments_to_polylines(wall_segments)
        wall_segments_scaled = scale_segments(wall_segments)

        # ========== å¼€å£å¤„ç†ï¼ˆç®€å•ï¼šç›´æ¥éª¨æ¶æå–ï¼‰ ==========
        open_skel = skeletonize(open_mask_512) if open_mask_512.sum()>0 else open_mask_512
        open_chains = chains_from_skel(open_skel) if open_mask_512.sum()>0 else []
        open_segments = chains_to_segments(open_chains)
        open_segments = merge_colinear(angle_snap(open_segments))
        open_segments_scaled = scale_segments(open_segments)

        return {
            'walls_segments': wall_segments_scaled,
            'walls_polylines': wall_polylines,  # æœªç¼©æ”¾ç‚¹é›†åˆ(512åæ ‡)å¯åç»­åˆ©ç”¨
            'openings_segments': open_segments_scaled
        }

    def _export_walls_svg(self, path, vec_data, original_size):
        ow,oh = original_size
        walls = vec_data['walls_segments']
        openings = vec_data['openings_segments']
        lines=[
            '<?xml version="1.0" encoding="UTF-8"?>',
            f'<svg xmlns="http://www.w3.org/2000/svg" width="{ow}" height="{oh}" viewBox="0 0 {ow} {oh}" stroke-linecap="round" stroke-linejoin="round">',
            '<g id="walls" stroke="#000" stroke-width="2" fill="none">'
        ]
        for (x1,y1,x2,y2) in walls:
            lines.append(f'<line x1="{x1}" y1="{y1}" x2="{x2}" y2="{y2}" />')
        lines.append('</g>')
        lines.append('<g id="openings" stroke="#FF3C80" stroke-width="2" fill="none">')
        for (x1,y1,x2,y2) in openings:
            lines.append(f'<line x1="{x1}" y1="{y1}" x2="{x2}" y2="{y2}" />')
        lines.append('</g></svg>')
        with open(path,'w',encoding='utf-8') as f: f.write('\n'.join(lines))

    def _export_walls_dxf(self, path, vec_data, original_size):
        ow,oh = original_size
        walls = vec_data['walls_segments']
        openings = vec_data['openings_segments']
        def dxf_header():
            return ["0","SECTION","2","HEADER","0","ENDSEC","0","SECTION","2","ENTITIES"]
        def dxf_footer():
            return ["0","ENDSEC","0","EOF"]
        lines=dxf_header()
        # å¢™ä½“ LINE
        for (x1,y1,x2,y2) in walls:
            lines += ["0","LINE","8","WALLS","10",str(x1),"20",str(y1),"11",str(x2),"21",str(y2)]
        # å¼€å£ LINE (å›¾å±‚ OPEN)
        for (x1,y1,x2,y2) in openings:
            lines += ["0","LINE","8","OPEN","10",str(x1),"20",str(y1),"11",str(x2),"21",str(y2)]
        lines += dxf_footer()
        with open(path,'w',encoding='utf-8') as f: f.write('\n'.join(lines))

    def _extract_room_coordinates(
        self, enhanced_resized, original_size, room_text_items
    ):
        """æå–å„æˆ¿é—´çš„åæ ‡ä¿¡æ¯ï¼Œä¼˜å…ˆä½¿ç”¨OCRæ–‡å­—ä½ç½®ï¼Œæ”¯æŒå¤šä¸ªåŒç±»å‹æˆ¿é—´"""
        # ===== A + C é¢„å¤„ç†: é’ˆå¯¹å¨æˆ¿çš„å°ç¢ç‰‡åˆå¹¶ (C) =====
        # åœºæ™¯: åˆ†å‰²è¾“å‡ºå¨æˆ¿ label(7) å¯èƒ½è¢«å¢™çº¿å‰²è£‚æˆå¤šä¸ªå¾ˆå°ç¢ç‰‡, å¯¼è‡´åç»­åŸºäºå•ä¸ª OCR seed çš„ BFS åªæŠ“åˆ°ä¸€å°å—ã€‚
        # ç­–ç•¥(C): è‹¥å¨æˆ¿æ€»é¢ç§¯å æ¯”å¾ˆå°(<1.2%) ä¸”è¿é€šåŸŸæ•°é‡>1, å¯¹å¨æˆ¿æ©è†œåšä¸€æ¬¡æ¸©å’Œé—­è¿ç®—+è†¨èƒ€ä»¥æ¡¥æ¥è¿‘è·ç¦»ç¢ç‰‡ã€‚
        kitchen_fragment_merged_mask = None
        try:
            mask_k = (enhanced_resized == 7).astype(np.uint8)
            total_pixels_512 = enhanced_resized.shape[0] * enhanced_resized.shape[1]
            kitchen_pixels = int(mask_k.sum())
            if kitchen_pixels > 0:
                area_ratio_k = kitchen_pixels / float(total_pixels_512)
                num_k, lab_k, stats_k, _ = cv2.connectedComponentsWithStats(mask_k, connectivity=4)
                comp_cnt = num_k - 1
                if area_ratio_k < 0.012 and comp_cnt > 1:
                    # ç»Ÿè®¡å°ç¢ç‰‡æ•°é‡
                    small_components = sum(1 for cid in range(1, num_k) if stats_k[cid, cv2.CC_STAT_AREA] < 160)
                    if small_components >= 1:
                        k_close = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
                        merged1 = cv2.morphologyEx(mask_k, cv2.MORPH_CLOSE, k_close, iterations=1)
                        merged2 = cv2.dilate(merged1, cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3)), iterations=1)
                        # ä»…åœ¨è†¨èƒ€åæ–°å¢åƒç´ ä¸è¶…è¿‡åŸå¨æˆ¿é¢ç§¯çš„ 60% æ—¶æ¥å—ï¼ˆé˜²æ­¢è¯¯åå…¶å®ƒåŒºåŸŸï¼‰
                        added = merged2.sum() - mask_k.sum()
                        if added <= kitchen_pixels * 0.6:
                            kitchen_fragment_merged_mask = merged2
                            print(f"ğŸ§© [ç¢ç‰‡åˆå¹¶C] å¨æˆ¿ç¢ç‰‡æ•°={comp_cnt} å°ç¢ç‰‡={small_components} é¢ç§¯å æ¯”={area_ratio_k:.2%} -> åº”ç”¨é—­è¿ç®—+è†¨èƒ€ åˆå¹¶å¢é‡åƒç´ ={int(added)}")
                        else:
                            print(f"ğŸ§© [ç¢ç‰‡åˆå¹¶C] æ‹’ç»åˆå¹¶: æ–°å¢åƒç´ è¿‡å¤š({int(added)} > {int(kitchen_pixels*0.6)})")
        except Exception as _frag_e:
            print(f"âš ï¸ [ç¢ç‰‡åˆå¹¶C] å¼‚å¸¸: {_frag_e}")
        room_info = {}

        # è®¡ç®—åæ ‡è½¬æ¢æ¯”ä¾‹
        original_width, original_height = original_size

        # å®šä¹‰æˆ¿é—´ç±»å‹åŠå…¶åœ¨åˆ†å‰²æ©ç ä¸­çš„æ ‡ç­¾
        room_types = ["å¨æˆ¿", "å«ç”Ÿé—´", "å®¢å…", "å§å®¤", "é˜³å°", "ä¹¦æˆ¿"]
        room_label_mapping = {
            "å¨æˆ¿": 7,
            "å«ç”Ÿé—´": 2,
            "å®¢å…": 3,
            "å§å®¤": 4,
            "é˜³å°": 6,
            "ä¹¦æˆ¿": 8,
        }

        # åˆå§‹åŒ–æ‰€æœ‰æˆ¿é—´ä¿¡æ¯ä¸ºç©ºåˆ—è¡¨ï¼Œæ”¯æŒå¤šä¸ªåŒç±»å‹æˆ¿é—´
        for room_type in room_types:
            room_info[room_type] = []

        # ä¼˜å…ˆä½¿ç”¨OCRæ–‡å­—ä½ç½®ç¡®å®šæˆ¿é—´åæ ‡
        for item in room_text_items:
            text = item["text"].lower().strip()

            # åŒ¹é…æˆ¿é—´ç±»å‹
            room_type = None
            if any(keyword in text for keyword in ["å¨æˆ¿", "kitchen", "å¨"]):
                room_type = "å¨æˆ¿"
            elif any(
                keyword in text
                for keyword in [
                    "å«ç”Ÿé—´",
                    "bathroom",
                    "å«",
                    "æ´—æ‰‹é—´",
                    "æµ´å®¤",
                    "æ·‹æµ´é—´",
                    "shower",
                    "æ·‹æµ´",
                    "ç›¥æ´—å®¤",
                ]
            ):
                room_type = "å«ç”Ÿé—´"
            elif any(keyword in text for keyword in ["å®¢å…", "living", "å…", "èµ·å±…å®¤"]):
                room_type = "å®¢å…"
            elif any(
                keyword in text for keyword in ["å§å®¤", "bedroom", "ä¸»å§", "æ¬¡å§", "å§æˆ¿", "å§ç©º", "ç½‘æˆ¿"]
            ):
                # æ‰©å±•å§å®¤åŒä¹‰è¯/è¯¯è¯†åˆ«è¯æ”¯æŒï¼ˆç½‘æˆ¿/å§ç©ºç­‰ï¼‰
                room_type = "å§å®¤"
            elif any(keyword in text for keyword in ["é˜³å°", "balcony", "é˜³å…®", "é˜³åˆ", "é˜³å›Š"]):
                room_type = "é˜³å°"
                if text in ["é˜³å…®", "é˜³åˆ", "é˜³å›Š"]:
                    print(f"ğŸ”§ [OCRä¿®æ­£] è¯¯è¯†åˆ«'{text}' -> 'é˜³å°'")
            elif any(
                keyword in text
                for keyword in ["ä¹¦æˆ¿", "study", "åŠå…¬å®¤", "office"]
            ):
                room_type = "ä¹¦æˆ¿"
                print(f"ğŸ” [OCRéªŒè¯] ç¡®è®¤ä¹¦æˆ¿: '{text}' (OCRæ”¯æŒ)")

            if room_type and room_type in room_info:
                # ä½¿ç”¨OCRæ–‡å­—çš„ bbox (å·²åœ¨ ocr_enhanced ä¸­ç¼©æ”¾å›åŸå›¾åæ ‡)
                x, y, w, h = item["bbox"]

                # è®¡ç®—æ–‡å­—ä¸­å¿ƒ (åŸå›¾åæ ‡)
                ocr_center_x = x + w // 2
                ocr_center_y = y + h // 2

                # æ—©æœŸç‰ˆæœ¬å­˜åœ¨å†æ¬¡é™¤ä»¥ scale_factor çš„é”™è¯¯ (å¯¼è‡´åæ ‡åå° 0.5x)
                # ä¿®æ­£: ç›´æ¥ä½¿ç”¨å½“å‰ä¸­å¿ƒ (å‡å®š bbox å·²æ˜¯åŸå°ºåº¦)
                orig_center_x = ocr_center_x
                orig_center_y = ocr_center_y

                # ä¿æŠ¤æ€§æ£€æµ‹: å¦‚æœ bbox æ˜æ˜¾è¶…å‡ºåŸå›¾å°ºå¯¸ (>1.2x), è¯´æ˜å¯èƒ½è¿˜æ²¡ç¼©æ”¾, å†æŒ‰ scale_factor å›è°ƒ
                scale_factor = float(item.get('scale_factor', 1.0) or 1.0)
                if scale_factor > 1.01 and (orig_center_x > original_width * 1.2 or orig_center_y > original_height * 1.2):
                    orig_center_x = int(round(orig_center_x / scale_factor))
                    orig_center_y = int(round(orig_center_y / scale_factor))
                    x = int(round(x / scale_factor))
                    y = int(round(y / scale_factor))
                    w = int(round(w / scale_factor))
                    h = int(round(h / scale_factor))
                    print(f"ğŸ”§ [åæ ‡è‡ªé€‚åº”] å‘ç°æœªç¼©æ”¾OCRæ¡†, å·²æŒ‰ scale_factor={scale_factor:.2f} å›è°ƒ -> center=({orig_center_x},{orig_center_y})")

                # ä¼˜å…ˆä½¿ç”¨åˆ†å‰²æ©ç ç¡®å®šæ•´é—´æˆ¿çš„è¾¹ç•Œ
                min_x = max_x = min_y = max_y = None
                label = room_label_mapping.get(room_type)
                if label is not None:
                    # ä½¿ç”¨ç¢ç‰‡åˆå¹¶åçš„å¨æˆ¿æ©è†œ (C)
                    if label == 7 and kitchen_fragment_merged_mask is not None:
                        mask = kitchen_fragment_merged_mask.astype(bool)
                    else:
                        mask = (enhanced_resized == label)
                    mask_h, mask_w = mask.shape
                    # å°†åŸå›¾ä¸­å¿ƒæ˜ å°„åˆ° 512 æ©è†œåæ ‡
                    mask_x = int(round(orig_center_x * mask_w / original_width))
                    mask_y = int(round(orig_center_y * mask_h / original_height))
                    seed_x, seed_y, seed_found = mask_x, mask_y, False

                    # è¾¹ç•Œä¿æŠ¤
                    if not (0 <= mask_x < mask_w and 0 <= mask_y < mask_h):
                        mask_x = min(max(mask_x, 0), mask_w - 1)
                        mask_y = min(max(mask_y, 0), mask_h - 1)
                        seed_x, seed_y = mask_x, mask_y

                    # å¦‚æœä¸­å¿ƒç‚¹ä¸æ˜¯è¯¥æ ‡ç­¾ï¼Œæ‰©å¤§æœç´¢åŠå¾„å¯»æ‰¾æœ€è¿‘çš„åŒæ ‡ç­¾åƒç´ 
                    if mask[mask_y, mask_x]:
                        seed_found = True
                    else:
                        for search_radius in (3, 6, 10):  # åˆ†é˜¶æ®µæ‰©å¤§
                            min_dist = None
                            for dy in range(-search_radius, search_radius + 1):
                                for dx in range(-search_radius, search_radius + 1):
                                    nx, ny = mask_x + dx, mask_y + dy
                                    if 0 <= nx < mask_w and 0 <= ny < mask_h and mask[ny, nx]:
                                        dist = dx * dx + dy * dy
                                        if min_dist is None or dist < min_dist:
                                            min_dist = dist
                                            seed_x, seed_y = nx, ny
                                            seed_found = True
                            if seed_found:
                                break

                    if seed_found:
                        labeled_mask = mask.astype(np.uint8)
                        num_labels, labels_img = cv2.connectedComponents(labeled_mask)
                        region_label = labels_img[seed_y, seed_x]
                        if region_label != 0:
                            full_region = (labels_img == region_label)

                            # ===== åŠå¾„é™åˆ¶æ³›æ´ªï¼Œé¿å…ä¸€ä¸ªæ ‡ç­¾åå¹¶å¤šä¸ªé€»è¾‘æˆ¿é—´ =====
                            # æ ¹æ®æˆ¿é—´ç±»å‹è®¾å®šæœ€å¤§åŠå¾„ (åŸå›¾åƒç´ ) ä¸æœ€å¤§é¢ç§¯æ¯”ä¸Šé™
                            max_radius_map = {"å¨æˆ¿": 180, "å«ç”Ÿé—´": 160, "å§å®¤": 260, "é˜³å°": 220, "ä¹¦æˆ¿": 240, "å®¢å…": 480}
                            max_area_ratio_map = {"å¨æˆ¿": 0.15, "å«ç”Ÿé—´": 0.12, "å§å®¤": 0.28, "é˜³å°": 0.20, "ä¹¦æˆ¿": 0.22, "å®¢å…": 0.38}
                            max_radius_orig = max_radius_map.get(room_type, 300)
                            max_area_ratio = max_area_ratio_map.get(room_type, 0.30)

                            # è½¬æ¢åˆ° 512 ç©ºé—´çš„æœ€å¤§åŠå¾„
                            radius_512_x = int(round(max_radius_orig * mask_w / original_width))
                            radius_512_y = int(round(max_radius_orig * mask_h / original_height))
                            radius_512 = int((radius_512_x + radius_512_y) / 2)

                            # BFS å—é™æ³›æ´ª
                            visited = np.zeros_like(full_region, dtype=np.uint8)
                            from collections import deque
                            q = deque()
                            q.append((seed_x, seed_y))
                            visited[seed_y, seed_x] = 1
                            sel_pixels = [(seed_x, seed_y)]
                            while q:
                                cx, cy = q.popleft()
                                for nx in (cx-1, cx, cx+1):
                                    for ny in (cy-1, cy, cy+1):
                                        if nx == cx and ny == cy: continue
                                        if 0 <= nx < mask_w and 0 <= ny < mask_h and not visited[ny, nx]:
                                            if full_region[ny, nx]:
                                                # åŠå¾„çº¦æŸ
                                                if abs(nx - seed_x) <= radius_512 and abs(ny - seed_y) <= radius_512:
                                                    visited[ny, nx] = 1
                                                    q.append((nx, ny))
                                                    sel_pixels.append((nx, ny))
                                            visited[ny, nx] = 1  # æ ‡è®°è®¿é—®é¿å…é‡å¤

                            sel_pixels_arr = np.array(sel_pixels)
                            x_coords = sel_pixels_arr[:,0]
                            y_coords = sel_pixels_arr[:,1]
                            min_x_512, max_x_512 = x_coords.min(), x_coords.max()
                            min_y_512, max_y_512 = y_coords.min(), y_coords.max()

                            # å¦‚æœé€‰æ‹©åŒºåŸŸé¢ç§¯æ¯”è¶…è¿‡æœ€å¤§é™åˆ¶æˆ–åŒºåŸŸå¤ªå°ä¸å®Œæ•´åŒºåŸŸé¢ç§¯å·®å¼‚å·¨å¤§ï¼Œé€€å›ä½¿ç”¨å®Œæ•´åŒºåŸŸ
                            limited_area = len(sel_pixels)
                            full_area = int(full_region.sum())
                            total_pixels = original_width * original_height
                            bbox_area_est = (max_x_512 - min_x_512 + 1) * (max_y_512 - min_y_512 + 1) * (total_pixels / (mask_w * mask_h))
                            if (bbox_area_est / total_pixels) > max_area_ratio or limited_area < min(50, full_area * 0.05):
                                # ä½¿ç”¨åŸå®Œæ•´åŒºåŸŸ
                                y_coords, x_coords = np.where(full_region)
                                min_x_512, max_x_512 = x_coords.min(), x_coords.max()
                                min_y_512, max_y_512 = y_coords.min(), y_coords.max()
                                print(f"âš ï¸ [æˆ¿é—´è£å‰ª] {room_type} å—é™æ³›æ´ªä¸ç¨³å®š(é¢ç§¯æˆ–å°ºå¯¸å¼‚å¸¸)ï¼Œå›é€€ä½¿ç”¨å®Œæ•´è¿é€šåŸŸ")
                            else:
                                print(f"âœ… [æˆ¿é—´è£å‰ª] {room_type} å—é™æ³›æ´ªé€‰å– {limited_area}/{full_area} åƒç´ , é¿å…è¿‡åº¦æ‰©å¼ ")

                            scale_x = original_width / float(mask_w)
                            scale_y = original_height / float(mask_h)
                            min_x = int(min_x_512 * scale_x)
                            max_x = int(max_x_512 * scale_x)
                            min_y = int(min_y_512 * scale_y)
                            max_y = int(max_y_512 * scale_y)

                            # è¿‡å¤§åŒºåŸŸä¿æŠ¤: è‹¥ bbox å åŸå›¾é¢ç§¯ > 40% (æ—  OCR æƒ…å†µé™¤å¤–)ï¼Œè®¤ä¸ºæ³›åŒ–è¿‡åº¦ï¼Œå°è¯•å±€éƒ¨æ”¶ç¼©
                            bbox_area = (max_x - min_x + 1) * (max_y - min_y + 1)
                            whole_area = original_width * original_height
                            if bbox_area / whole_area > 0.40 and text not in ("åˆ†å‰²æ£€æµ‹",):
                                # åœ¨ 512 ç©ºé—´æ„é€ è·ç¦»ä¸­å¿ƒç‚¹çš„å±€éƒ¨çª—å£ (é™åˆ¶ 35% åŸå§‹å®½/é«˜)
                                win_w = int(min(mask_w * 0.5, max(64, mask_w * 0.35)))
                                win_h = int(min(mask_h * 0.5, max(64, mask_h * 0.35)))
                                cx512 = int(round(orig_center_x * mask_w / original_width))
                                cy512 = int(round(orig_center_y * mask_h / original_height))
                                x1_l = max(0, cx512 - win_w // 2)
                                x2_l = min(mask_w, cx512 + win_w // 2)
                                y1_l = max(0, cy512 - win_h // 2)
                                y2_l = min(mask_h, cy512 + win_h // 2)
                                local = full_region[y1_l:y2_l, x1_l:x2_l]
                                if local.any():
                                    ly, lx = np.where(local)
                                    # æ˜ å°„å›å…¨å±€ 512
                                    min_x_512 = x1_l + lx.min(); max_x_512 = x1_l + lx.max()
                                    min_y_512 = y1_l + ly.min(); max_y_512 = y1_l + ly.max()
                                    min_x = int(min_x_512 * scale_x)
                                    max_x = int(max_x_512 * scale_x)
                                    min_y = int(min_y_512 * scale_y)
                                    max_y = int(max_y_512 * scale_y)
                                    print(f"âš ï¸ [åæ ‡è°ƒæ•´] {room_type} åŒºåŸŸè¿‡å¤§({bbox_area/whole_area:.1%}), ä½¿ç”¨å±€éƒ¨çª—å£æ”¶ç¼© bbox")
                            print(f"ğŸ§© [åæ ‡è°ƒè¯•] {room_type} OCRä¸­å¿ƒ=({orig_center_x},{orig_center_y}) ç§å­=({seed_x},{seed_y}) bbox=({min_x},{min_y},{max_x},{max_y})")

                if min_x is None:
                    # æœªæ‰¾åˆ°è¿é€šåŸŸï¼Œå›é€€åˆ°åŸºäºOCRæ–‡å­—è‡ªèº«çš„æœ€å°è¾¹ç•Œ (bbox å·²æ˜¯åŸå›¾å°ºåº¦)
                    orig_w = w
                    orig_h = h
                    # ç»™ä¸€äº›å†—ä½™é¿å…è¿‡ç´§è£å‰ª
                    half_width = max(20, int(orig_w * 0.6))
                    half_height = max(15, int(orig_h * 0.6))
                    min_x = max(0, orig_center_x - half_width)
                    max_x = min(original_width - 1, orig_center_x + half_width)
                    min_y = max(0, orig_center_y - half_height)
                    max_y = min(original_height - 1, orig_center_y + half_height)

                width = max_x - min_x + 1
                height = max_y - min_y + 1

                room_info[room_type].append({
                    'center': (orig_center_x, orig_center_y),
                    'bbox': (min_x, min_y, max_x, max_y),
                    'pixels': width * height,  # åŸºäºè¾¹ç•Œæ¡†çš„é¢ç§¯ (åç»­å¯æ›¿æ¢ä¸ºçœŸå® mask é¢ç§¯)
                    'width': width,
                    'height': height,
                    'text': text,
                    'raw_text': item.get('raw_text', item.get('text', '')),
                    'confidence': item.get('confidence', 0.0),
                    'source': 'ocr'
                })

        # ===== A: åŸºäº OCR seed çš„å¨æˆ¿åŒºåŸŸé‡å»º / æ‰©å±• =====
        try:
            if room_info.get('å¨æˆ¿'):
                orig_w, orig_h = original_size
                img_area = orig_w * orig_h
                rebuilt_any = False
                new_kitchens = []
                for k_room in room_info['å¨æˆ¿']:
                    bx1, by1, bx2, by2 = k_room['bbox']
                    bbox_area = (bx2 - bx1 + 1) * (by2 - by1 + 1)
                    area_ratio = bbox_area / img_area
                    need_rebuild = (area_ratio < 0.006) or (k_room['width'] < 55) or (k_room['height'] < 40)
                    if not need_rebuild:
                        new_kitchens.append(k_room)
                        continue
                    # è¿›å…¥é‡å»º: åœ¨ 512 ç©ºé—´æ”¶é›†é™„è¿‘ label=7 åƒç´  (ä½¿ç”¨åˆå¹¶æ©è†œè‹¥å¯ç”¨)
                    mask512 = kitchen_fragment_merged_mask if kitchen_fragment_merged_mask is not None else (enhanced_resized == 7).astype(np.uint8)
                    if mask512.sum() == 0:
                        # æ— åˆ†å‰²æ”¯æŒ -> ç›´æ¥ OCR ä¸­å¿ƒæ‰©å±•åˆ°ç›®æ ‡é¢ç§¯
                        cx, cy = k_room['center']
                        target_ratio = 0.022  # 2.2%
                        target_area = int(img_area * target_ratio)
                        side = int((target_area) ** 0.5)
                        half = side // 2
                        nx1 = max(0, cx - half)
                        nx2 = min(orig_w - 1, cx + half)
                        ny1 = max(0, cy - half)
                        ny2 = min(orig_h - 1, cy + half)
                        k_room.update({'bbox': (nx1, ny1, nx2, ny2), 'width': nx2-nx1+1, 'height': ny2-ny1+1, 'pixels': (nx2-nx1+1)*(ny2-ny1+1), 'rebuild': 'ocr_expand_no_seg'})
                        rebuilt_any = True
                        print(f"ğŸ³ [å¨æˆ¿é‡å»ºA] æ— åˆ†å‰²å¨æˆ¿: OCR æ‰©å±•ä¸º {(nx2-nx1+1)}x{(ny2-ny1+1)} é¢ç§¯æ¯”={(nx2-nx1+1)*(ny2-ny1+1)/img_area:.2%}")
                        new_kitchens.append(k_room)
                        continue
                    # æœ‰åˆ†å‰²: æ˜ å°„ OCR ä¸­å¿ƒåˆ° 512
                    cx, cy = k_room['center']
                    cx512 = int(round(cx / orig_w * mask512.shape[1]))
                    cy512 = int(round(cy / orig_h * mask512.shape[0]))
                    # å¤šçº§çª—å£æ‰©å±•æ”¶é›† label=7 åƒç´ 
                    collected = None
                    for win in (40, 60, 80, 100):
                        x1 = max(0, cx512 - win)
                        x2 = min(mask512.shape[1]-1, cx512 + win)
                        y1 = max(0, cy512 - win)
                        y2 = min(mask512.shape[0]-1, cy512 + win)
                        sub = mask512[y1:y2+1, x1:x2+1]
                        if sub.sum() == 0:
                            continue
                        collected = (x1, y1, x2, y2, sub.copy())
                        # å¦‚æœå­çª—å£å†…å¨æˆ¿åƒç´ å çª—å£ > 9% æˆ–åƒç´ æ•°é‡ > 350 å³å¯åœæ­¢æ‰©å¤§
                        if (sub.sum() / ((x2-x1+1)*(y2-y1+1))) > 0.09 or sub.sum() > 350:
                            break
                    if collected is None:
                        # é€€å› OCR æ‰©å±•
                        target_ratio = 0.022
                        target_area = int(img_area * target_ratio)
                        side = int((target_area) ** 0.5)
                        half = side // 2
                        nx1 = max(0, cx - half)
                        nx2 = min(orig_w - 1, cx + half)
                        ny1 = max(0, cy - half)
                        ny2 = min(orig_h - 1, cy + half)
                        k_room.update({'bbox': (nx1, ny1, nx2, ny2), 'width': nx2-nx1+1, 'height': ny2-ny1+1, 'pixels': (nx2-nx1+1)*(ny2-ny1+1), 'rebuild': 'ocr_expand_no_pixels'})
                        rebuilt_any = True
                        print(f"ğŸ³ [å¨æˆ¿é‡å»ºA] åˆ†å‰²çª—å£æ— åƒç´ : OCR æ‰©å±•ä¸º {(nx2-nx1+1)}x{(ny2-ny1+1)} é¢ç§¯æ¯”={(nx2-nx1+1)*(ny2-ny1+1)/img_area:.2%}")
                        new_kitchens.append(k_room)
                        continue
                    x1_512, y1_512, x2_512, y2_512, sub = collected
                    ys, xs = np.where(sub > 0)
                    if len(xs) == 0:
                        new_kitchens.append(k_room)
                        continue
                    minx = x1_512 + xs.min(); maxx = x1_512 + xs.max()
                    miny = y1_512 + ys.min(); maxy = y1_512 + ys.max()
                    # æ˜ å°„å›åŸå›¾
                    scale_x = orig_w / mask512.shape[1]; scale_y = orig_h / mask512.shape[0]
                    nx1 = int(minx * scale_x); nx2 = int(maxx * scale_x)
                    ny1 = int(miny * scale_y); ny2 = int(maxy * scale_y)
                    # è‹¥é¢ç§¯ä»è¿‡å°åˆ™å¤–æ‰©å›ºå®š margin
                    if (nx2-nx1+1)*(ny2-ny1+1) / img_area < 0.010:
                        margin = 10
                        nx1 = max(0, nx1 - margin); ny1 = max(0, ny1 - margin)
                        nx2 = min(orig_w-1, nx2 + margin); ny2 = min(orig_h-1, ny2 + margin)
                    k_room.update({'bbox': (nx1, ny1, nx2, ny2), 'width': nx2-nx1+1, 'height': ny2-ny1+1, 'pixels': (nx2-nx1+1)*(ny2-ny1+1), 'rebuild': 'seg_merge'})
                    rebuilt_any = True
                    print(f"ğŸ³ [å¨æˆ¿é‡å»ºA] é‡å»ºå¨æˆ¿ bbox=({nx1},{ny1},{nx2},{ny2}) é¢ç§¯æ¯”={(nx2-nx1+1)*(ny2-ny1+1)/img_area:.2%} åŸå æ¯”={area_ratio:.2%}")
                    new_kitchens.append(k_room)
                if rebuilt_any:
                    room_info['å¨æˆ¿'] = new_kitchens
        except Exception as _kreb_e:
            print(f"âš ï¸ [å¨æˆ¿é‡å»ºA] å¼‚å¸¸: {_kreb_e}")
        # å¯¹äºæ²¡æœ‰OCRæ£€æµ‹åˆ°çš„æˆ¿é—´ï¼Œå°è¯•ä»åˆ†å‰²ç»“æœä¸­æå–
        label_mapping = {v: k for k, v in room_label_mapping.items()}

        for label, room_type in label_mapping.items():
            if len(room_info[room_type]) == 0:  # OCRæ²¡æœ‰æ£€æµ‹åˆ°
                mask = enhanced_resized == label
                pixels = np.sum(mask)
                if pixels <= 0:
                    continue

                total_pixels = enhanced_resized.shape[0] * enhanced_resized.shape[1]
                area_ratio = pixels / total_pixels
                max_area_without_ocr = 0.05  # å…¨å±€é™å®š 5%

                # é˜³å°ç‰¹æ®Šï¼šå¿…é¡»è§¦åˆ°å›¾åƒè¾¹ç•Œ(å‡è®¾é˜³å°å¸¸è´´å¤–å¢™)ä¸”é¢ç§¯ <3% æ‰å…è®¸æ— OCRå›é€€
                if room_type == "é˜³å°":
                    # è¾¹ç•Œæ¥è§¦æ£€æµ‹
                    border_touch = False
                    ys, xs = np.where(mask)
                    if len(xs) > 0:
                        if (xs.min() == 0 or ys.min() == 0 or xs.max() == mask.shape[1]-1 or ys.max() == mask.shape[0]-1):
                            border_touch = True
                    if not border_touch:
                        print("ğŸš« [å›é€€è¿‡æ»¤] æ— OCRé˜³å°æœªè§¦åŠè¾¹ç•Œ -> ä¸¢å¼ƒ")
                        continue
                    if area_ratio > 0.03:
                        print(f"ğŸš« [å›é€€è¿‡æ»¤] æ— OCRé˜³å°é¢ç§¯è¿‡å¤§ {area_ratio:.1%} > 3.0% -> ä¸¢å¼ƒ")
                        continue

                if area_ratio > max_area_without_ocr:
                    print(f"âš ï¸ [ç¬¬3å±‚-èåˆå†³ç­–å™¨] è·³è¿‡è¿‡å¤§çš„æ— OCRæ”¯æŒ{room_type}åŒºåŸŸ: {area_ratio:.1%} > {max_area_without_ocr:.1%}")
                    continue

                # æ‰¾åˆ°æˆ¿é—´åŒºåŸŸçš„åæ ‡
                ys, xs = np.where(mask)
                min_x_512, max_x_512 = xs.min(), xs.max()
                min_y_512, max_y_512 = ys.min(), ys.max()
                center_x_512 = int(xs.mean())
                center_y_512 = int(ys.mean())

                scale_x = original_width / 512.0
                scale_y = original_height / 512.0
                center_x = int(center_x_512 * scale_x)
                center_y = int(center_y_512 * scale_y)
                min_x = int(min_x_512 * scale_x)
                max_x = int(max_x_512 * scale_x)
                min_y = int(min_y_512 * scale_y)
                max_y = int(max_y_512 * scale_y)
                width = max_x - min_x + 1
                height = max_y - min_y + 1

                room_info[room_type].append({
                    "center": (center_x, center_y),
                    "bbox": (min_x, min_y, max_x, max_y),
                    "pixels": int(pixels),
                    "width": width,
                    "height": height,
                    "text": "åˆ†å‰²æ£€æµ‹",
                    "raw_text": "",
                    "confidence": 0.35,
                    "source": "segmentation_fallback"
                })
                print(f"â„¹ï¸ [å›é€€æ·»åŠ ] {room_type} (æ— OCR) bbox=({min_x},{min_y},{max_x},{max_y}) é¢ç§¯æ¯”={area_ratio:.2%}")

        # åˆå¹¶ç›¸è¿‘çš„åŒç±»å‹æˆ¿é—´ï¼ˆå¦‚ä¸­è‹±æ–‡æ ‡è¯†çš„åŒä¸€æˆ¿é—´ï¼‰
        room_info = self._merge_nearby_rooms(room_info, original_size)
        
        # ğŸ”’ ä¸¥æ ¼è¿‡æ»¤ä¹¦æˆ¿ï¼šåªæœ‰OCRéªŒè¯çš„ä¹¦æˆ¿æ‰èƒ½ä¿ç•™
        if "ä¹¦æˆ¿" in room_info:
            ocr_verified_study_rooms = []
            for room in room_info["ä¹¦æˆ¿"]:
                # åªä¿ç•™æœ‰OCRæ–‡å­—éªŒè¯çš„ä¹¦æˆ¿ï¼ˆä¸æ˜¯"åˆ†å‰²æ£€æµ‹"ï¼‰
                if room.get("text", "") != "åˆ†å‰²æ£€æµ‹":
                    ocr_verified_study_rooms.append(room)
                    print(f"âœ… [ä¹¦æˆ¿éªŒè¯] ä¿ç•™OCRéªŒè¯çš„ä¹¦æˆ¿: '{room['text']}'")
                else:
                    print(f"ğŸš« [ä¹¦æˆ¿è¿‡æ»¤] ç§»é™¤æ— OCRæ”¯æŒçš„AIåˆ†å‰²ä¹¦æˆ¿åŒºåŸŸ")
            
            room_info["ä¹¦æˆ¿"] = ocr_verified_study_rooms
            if len(ocr_verified_study_rooms) == 0:
                print("ğŸ“‹ [ä¹¦æˆ¿è¿‡æ»¤] æ— OCRéªŒè¯çš„ä¹¦æˆ¿ï¼Œæœ€ç»ˆç»“æœä¸åŒ…å«ä¹¦æˆ¿")

        # ===== å†²çªè§£æ & è§„èŒƒåŒ– =====
        try:
            # 1) è§„èŒƒåŒ–å§å®¤è¯¯è¯†åˆ«æ ‡ç­¾: å§ç©º / ç½‘æˆ¿ / å§æˆ¿ ç»Ÿä¸€å±•ç¤ºä¸º å§å®¤
            if 'å§å®¤' in room_info:
                for b in room_info['å§å®¤']:
                    raw_txt = b.get('text','')
                    if any(tok in raw_txt for tok in ['å§ç©º','ç½‘æˆ¿','å§æˆ¿']):
                        if raw_txt != 'å§å®¤':
                            print(f"ğŸ”§ [å§å®¤è§„èŒƒåŒ–] '{raw_txt}' -> 'å§å®¤'")
                        b['text'] = 'å§å®¤'

            # 2) ç½‘æˆ¿ ä¸ å¨æˆ¿ å†²çª: è‹¥åŒä¸€ä½ç½®æ—¢å‡ºç° å¨æˆ¿ åˆå‡ºç° 'ç½‘æˆ¿'(ç–‘ä¼¼'å¨æˆ¿'è¢«è¯¯åˆ†), ä¸”é«˜åº¦é‡å , å½’å¹¶ä¸ºå¨æˆ¿
            if 'å¨æˆ¿' in room_info and 'å§å®¤' in room_info and room_info['å¨æˆ¿'] and room_info['å§å®¤']:
                def _bbox_iou(a,b):
                    ax1,ay1,ax2,ay2 = a; bx1,by1,bx2,by2 = b
                    ix1=max(ax1,bx1); iy1=max(ay1,by1); ix2=min(ax2,bx2); iy2=min(ay2,by2)
                    if ix2<ix1 or iy2<iy1: return 0.0
                    inter=(ix2-ix1+1)*(iy2-iy1+1)
                    aarea=(ax2-ax1+1)*(ay2-ay1+1); barea=(bx2-bx1+1)*(by2-by1+1)
                    return inter/float(aarea+barea-inter)
                updated_bedrooms=[]
                for b in room_info['å§å®¤']:
                    raw_txt=b.get('raw_text', b.get('text',''))
                    if 'ç½‘æˆ¿' not in raw_txt:
                        updated_bedrooms.append(b)
                        continue
                    # æ£€æŸ¥ä¸å¨æˆ¿çš„IoU
                    merged_into_k=False
                    for k in room_info['å¨æˆ¿']:
                        iou=_bbox_iou(b['bbox'], k['bbox'])
                        if iou>0.45:
                            # åˆå¹¶: æ‰©å¤§å¨æˆ¿bboxä¸ºå¹¶é›†
                            kx1,ky1,kx2,ky2=k['bbox']; bx1,by1,bx2,by2=b['bbox']
                            union_bbox=(min(kx1,bx1), min(ky1,by1), max(kx2,bx2), max(ky2,by2))
                            if union_bbox!=k['bbox']:
                                print(f"ğŸ”„ [å†²çªè§£æ] 'ç½‘æˆ¿' ä¸ 'å¨æˆ¿' IoU={iou:.2f} -> å½’å¹¶å¹¶æ›´æ–°å¨æˆ¿bbox")
                                k['bbox']=union_bbox
                                k['width']=union_bbox[2]-union_bbox[0]+1
                                k['height']=union_bbox[3]-union_bbox[1]+1
                                k['pixels']=k['width']*k['height']
                            merged_into_k=True
                            break
                    if not merged_into_k:
                        # IoUä¸è¶³, ä¿ç•™ä¸ºå§å®¤(å·²è§„èŒƒåŒ– text)
                        updated_bedrooms.append(b)
                room_info['å§å®¤']=updated_bedrooms

            # 3) å®¢å…è¶Šç•Œè£å‰ª: è‹¥å®¢å… bbox å«æœ‰å¤šä¸ªå…¶å®ƒæˆ¿é—´ä¸­å¿ƒç‚¹åˆ™è§†ä¸ºè¿‡åº¦æ‰©å¼ , è¿›è¡Œè¾¹ç•Œå›ç¼©
            if 'å®¢å…' in room_info and room_info['å®¢å…']:
                other_types=['å¨æˆ¿','å«ç”Ÿé—´','å§å®¤','ä¹¦æˆ¿','é˜³å°']
                for lr in room_info['å®¢å…']:
                    lx1,ly1,lx2,ly2=lr['bbox']
                    # æ”¶é›†è¢«åŒ…å«çš„å…¶å®ƒæˆ¿é—´ä¸­å¿ƒ
                    contained=[]
                    blockers=[]
                    for ot in other_types:
                        for rr in room_info.get(ot,[]):
                            cx,cy=rr['center']
                            if lx1<=cx<=lx2 and ly1<=cy<=ly2:
                                contained.append((ot, rr))
                                blockers.append(rr['bbox'])
                    if len(contained)>=2:
                        print(f"âš ï¸ [å®¢å…ä¿®æ­£] å®¢å…åŒ…å« {len(contained)} ä¸ªå…¶å®ƒæˆ¿é—´ä¸­å¿ƒ -> å°è¯•è£å‰ª")
                        # é€ä¸ªé˜»æŒ¡æ¡†å›ç¼©å®¢å…è¾¹ç•Œ
                        for bx1,by1,bx2,by2 in blockers:
                            # ä¼˜å…ˆæ²¿è·ç¦»è¾ƒè¿‘çš„æ–¹å‘æ”¶ç¼©
                            # å·¦ä¾§æ”¶ç¼©
                            if bx2< (lx1+lx2)//2 and bx2>lx1 and (bx2-lx1) < (lx2-bx1):
                                lx1 = min(max(lx1, bx2+3), lx2-10)
                            # å³ä¾§æ”¶ç¼©
                            if bx1> (lx1+lx2)//2 and bx1<lx2 and (lx2-bx1) < (bx2-lx1):
                                lx2 = max(min(lx2, bx1-3), lx1+10)
                            # ä¸Šä¾§æ”¶ç¼©
                            if by2< (ly1+ly2)//2 and by2>ly1 and (by2-ly1) < (ly2-by1):
                                ly1 = min(max(ly1, by2+3), ly2-10)
                            # ä¸‹ä¾§æ”¶ç¼©
                            if by1> (ly1+ly2)//2 and by1<ly2 and (ly2-by1) < (by2-ly1):
                                ly2 = max(min(ly2, by1-3), ly1+10)
                        # æ›´æ–°
                        new_bbox=(lx1,ly1,lx2,ly2)
                        if new_bbox!=lr['bbox']:
                            lr['bbox']=new_bbox
                            lr['width']=lx2-lx1+1
                            lr['height']=ly2-ly1+1
                            lr['pixels']=lr['width']*lr['height']
                            print(f"âœ… [å®¢å…ä¿®æ­£] è£å‰ªåbbox={new_bbox}")
        except Exception as _conf_e:
            print(f"âš ï¸ [å†²çª/è¶Šç•Œå¤„ç†å¼‚å¸¸] {_conf_e}")
        
        return room_info
        
    def _merge_nearby_rooms(self, room_info, original_size):
        """åˆå¹¶è·ç¦»å¾ˆè¿‘çš„åŒç±»å‹æˆ¿é—´"""
        print("ğŸ”„ æ£€æŸ¥å¹¶åˆå¹¶ç›¸è¿‘çš„åŒç±»å‹æˆ¿é—´...")
        # åŸºç¡€åˆå¹¶è·ç¦»é˜ˆå€¼ï¼ˆåƒç´ ï¼‰
        base_merge_threshold = 50
        # å§å®¤æ›´ä¸¥æ ¼ï¼Œé¿å…å°†å¤šä¸ªå§å®¤åˆå¹¶æˆä¸€ä¸ª
        bedroom_merge_threshold = 35
        # éœ€è¦åŒæ—¶æ»¡è¶³ä¸­å¿ƒè·ç¦»é˜ˆå€¼ AND è¾¹ç•Œæ¡† IoU >= 0.35 æˆ– ä¸€æ–¹ bbox å®Œå…¨åŒ…å«å¦ä¸€æ–¹
        
        merged_room_info = {}
        
        for room_type, room_list in room_info.items():
            if len(room_list) <= 1:
                # åªæœ‰0æˆ–1ä¸ªæˆ¿é—´ï¼Œæ— éœ€åˆå¹¶
                merged_room_info[room_type] = room_list
                continue
                
            # å¯¹æœ‰å¤šä¸ªæˆ¿é—´çš„ç±»å‹è¿›è¡Œåˆå¹¶æ£€æŸ¥
            merged_list = []
            processed = set()
            
            for i, room1 in enumerate(room_list):
                if i in processed:
                    continue
                    
                # å¯»æ‰¾ä¸å½“å‰æˆ¿é—´è·ç¦»å¾ˆè¿‘çš„å…¶ä»–æˆ¿é—´
                to_merge = [room1]
                processed.add(i)
                
                for j, room2 in enumerate(room_list[i+1:], i+1):
                    if j in processed:
                        continue
                        
                    # è®¡ç®—ä¸¤æˆ¿é—´ä¸­å¿ƒç‚¹è·ç¦»
                    x1, y1 = room1['center']
                    x2, y2 = room2['center']
                    distance = ((x2-x1)**2 + (y2-y1)**2)**0.5
                    
                    # è®¡ç®— bbox é‡å æƒ…å†µ
                    bx11,by11,bx12,by12 = room1['bbox']
                    bx21,by21,bx22,by22 = room2['bbox']
                    inter_x1 = max(bx11,bx21); inter_y1 = max(by11,by21)
                    inter_x2 = min(bx12,bx22); inter_y2 = min(by12,by22)
                    inter_area = 0
                    if inter_x2>=inter_x1 and inter_y2>=inter_y1:
                        inter_area = (inter_x2-inter_x1+1)*(inter_y2-inter_y1+1)
                    area1 = (bx12-bx11+1)*(by12-by11+1)
                    area2 = (bx22-bx21+1)*(by22-by21+1)
                    union_area = area1+area2-inter_area if (area1+area2-inter_area)>0 else 1
                    iou = inter_area/float(union_area)
                    contains = (inter_area==area1) or (inter_area==area2)
                    thr = bedroom_merge_threshold if room_type=="å§å®¤" else base_merge_threshold
                    if distance < thr and (iou>=0.35 or contains):
                        to_merge.append(room2); processed.add(j)
                        print(f"   ğŸ”— {room_type}åˆå¹¶ï¼š'{room1['text']}' + '{room2['text']}' è·ç¦»={distance:.1f} IoU={iou:.2f} contains={contains}")
                    else:
                        if room_type=="å§å®¤" and distance < thr:
                            print(f"   ğŸš« å§å®¤ä¿æŒåˆ†ç¦»ï¼šè·ç¦»{distance:.1f}<é˜ˆå€¼{thr}ä½† IoU={iou:.2f} ä¸”ä¸åŒ…å« -> è§†ä¸ºå¤šå§")
                
                if len(to_merge) > 1:
                    # éœ€è¦åˆå¹¶å¤šä¸ªæˆ¿é—´
                    merged_room = self._merge_room_group(to_merge)
                    merged_list.append(merged_room)
                    print(f"   âœ… {room_type}åˆå¹¶å®Œæˆï¼š{len(to_merge)}ä¸ªåŒºåŸŸ -> 1ä¸ªåŒºåŸŸ")
                else:
                    # å•ä¸ªæˆ¿é—´ï¼Œç›´æ¥æ·»åŠ 
                    merged_list.append(room1)
            
            merged_room_info[room_type] = merged_list
            
            # è¾“å‡ºåˆå¹¶ç»“æœ
            if len(room_list) != len(merged_list):
                print(f"   ğŸ“Š {room_type}ï¼š{len(room_list)}ä¸ª -> {len(merged_list)}ä¸ª")
        
        return merged_room_info
    
    def _merge_room_group(self, room_group):
        """å°†å¤šä¸ªæˆ¿é—´åˆå¹¶ä¸ºä¸€ä¸ª"""
        # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„æˆ¿é—´ä½œä¸ºåŸºå‡†
        best_room = max(room_group, key=lambda r: r['confidence'])
        
        # è®¡ç®—åˆå¹¶åçš„ä¸­å¿ƒç‚¹ï¼ˆåŠ æƒå¹³å‡ï¼Œç½®ä¿¡åº¦ä½œä¸ºæƒé‡ï¼‰
        total_weight = sum(r['confidence'] for r in room_group)
        if total_weight > 0:
            weighted_x = sum(r['center'][0] * r['confidence'] for r in room_group) / total_weight
            weighted_y = sum(r['center'][1] * r['confidence'] for r in room_group) / total_weight
            merged_center = (int(weighted_x), int(weighted_y))
        else:
            # å¦‚æœæƒé‡ä¸º0ï¼Œä½¿ç”¨ç®€å•å¹³å‡
            avg_x = sum(r['center'][0] for r in room_group) / len(room_group)
            avg_y = sum(r['center'][1] for r in room_group) / len(room_group)
            merged_center = (int(avg_x), int(avg_y))
        
        # è®¡ç®—åˆå¹¶åçš„è¾¹ç•Œæ¡†ï¼ˆåŒ…å«æ‰€æœ‰æˆ¿é—´çš„è¾¹ç•Œï¼‰
        all_bbox = [r['bbox'] for r in room_group]
        min_x = min(bbox[0] for bbox in all_bbox)
        min_y = min(bbox[1] for bbox in all_bbox)
        max_x = max(bbox[2] for bbox in all_bbox)
        max_y = max(bbox[3] for bbox in all_bbox)
        
        merged_width = max_x - min_x + 1
        merged_height = max_y - min_y + 1
        
        # åˆå¹¶æ–‡æœ¬æè¿°
        texts = [r['text'] for r in room_group]
        merged_text = ' + '.join(texts)
        
        # ä½¿ç”¨æœ€é«˜ç½®ä¿¡åº¦
        max_confidence = max(r['confidence'] for r in room_group)
        
        return {
            'center': merged_center,
            'bbox': (min_x, min_y, max_x, max_y),
            'pixels': merged_width * merged_height,
            'width': merged_width,
            'height': merged_height,
            'text': merged_text,
            'confidence': max_confidence,
        }

        return room_info

    def _print_room_coordinates(self, room_info, original_size):
        """æ‰“å°æˆ¿é—´åæ ‡è¯¦ç»†ä¿¡æ¯ï¼Œæ”¯æŒå¤šä¸ªåŒç±»å‹æˆ¿é—´"""
        print("\n" + "=" * 60)
        print("ğŸ“ æˆ¿é—´åæ ‡è¯¦ç»†ä¿¡æ¯")
        print("=" * 60)
        print(f"ğŸ“ å›¾åƒå°ºå¯¸: {original_size[0]} x {original_size[1]} (å®½ x é«˜)")
        print("-" * 60)

        total_rooms = 0
        for room_type, room_list in room_info.items():
            if len(room_list) > 0:
                for i, info in enumerate(room_list):
                    if info["pixels"] > 0:
                        center_x, center_y = info["center"]
                        min_x, min_y, max_x, max_y = info["bbox"]

                        # å¦‚æœæœ‰å¤šä¸ªåŒç±»å‹æˆ¿é—´ï¼Œæ˜¾ç¤ºç¼–å·
                        if len(room_list) > 1:
                            display_name = f"{room_type}{i+1}"
                        else:
                            display_name = room_type

                        print(f"ğŸ  {display_name}:")
                        print(f"   ğŸ“ ä¸­å¿ƒåæ ‡: ({center_x}, {center_y})")
                        print(
                            f"   ğŸ“ è¾¹ç•Œæ¡†: å·¦ä¸Š({min_x}, {min_y}) -> å³ä¸‹({max_x}, {max_y})"
                        )
                        print(f"   ğŸ“ å°ºå¯¸: {info['width']} x {info['height']} åƒç´ ")
                        print(f"   ğŸ“Š é¢ç§¯: {info['pixels']} åƒç´ ")
                        print(
                            f"   ğŸ“„ è¯†åˆ«æ–‡æœ¬: '{info['text']}' (ç½®ä¿¡åº¦: {info['confidence']:.3f})"
                        )
                        print(f"   ğŸ”— åæ ‡èŒƒå›´: X[{min_x}-{max_x}], Y[{min_y}-{max_y}]")
                        print("-" * 60)
                        total_rooms += 1

            # å¦‚æœè¯¥ç±»å‹æˆ¿é—´æœªæ£€æµ‹åˆ°
            if len(room_list) == 0:
                print(f"âŒ {room_type}: æœªæ£€æµ‹åˆ°")
                print("-" * 60)

        print("ğŸ’¡ åæ ‡ç³»è¯´æ˜:")
        print("   â€¢ åŸç‚¹(0,0)åœ¨å›¾åƒå·¦ä¸Šè§’")
        print("   â€¢ Xè½´å‘å³ä¸ºæ­£æ–¹å‘")
        print("   â€¢ Yè½´å‘ä¸‹ä¸ºæ­£æ–¹å‘")
        print("   â€¢ æ‰€æœ‰åæ ‡å•ä½ä¸ºåƒç´ ")
        print("=" * 60)
        print(f"\nğŸ“Š æ€»è®¡æ£€æµ‹åˆ° {total_rooms} ä¸ªæˆ¿é—´")
        print("=" * 60)

    def process(self, image_path, output_path=None):
        """å®Œæ•´å¤„ç†æµç¨‹ - ä½¿ç”¨å››å±‚æ™ºèƒ½å†³ç­–æ¶æ„"""
        try:
            # è®¾ç½®è¾“å‡ºè·¯å¾„
            if output_path is None:
                output_path = Path(image_path).stem

            # 1. åŠ è½½æ¨¡å‹
            self.load_model()

            # 2. å›¾åƒé¢„å¤„ç†
            img_array, original_size, original_img = self.preprocess_image(image_path)

            # 3-6. ä½¿ç”¨å››å±‚æ™ºèƒ½å†³ç­–æ¶æ„å¤„ç†
            results = self.process_with_four_layer_architecture(
                img_array, original_img, original_size
            )

            # 7. ç”Ÿæˆç»“æœ
            standard_result_path = self.generate_results(
                results['ai_raw'],
                results['ocr_results'],
                results['fusion_result'],
                results['final_result'],
                original_img,
                original_size,
                output_path,
                results['ocr_results']
            )

            # 8. æ˜¾ç¤ºæ‘˜è¦
            self._print_summary()

            return standard_result_path

        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            raise

    def _print_summary(self):
        """æ‰“å°æ£€æµ‹æ‘˜è¦ - åŸºäºOCRéªŒè¯çš„çœŸå®æˆ¿é—´æ•°é‡"""
        # æˆ¿é—´æ ‡ç­¾åˆ°åç§°/å›¾æ ‡/é¢œè‰²çš„æ˜ å°„
        label_info = {
            7: ("å¨æˆ¿", "ğŸ³", "ç»¿è‰²"),
            2: ("å«ç”Ÿé—´", "ğŸš¿", "è“è‰²"),
            3: ("å®¢å…", "ğŸ ", "æ©™è‰²"),
            4: ("å§å®¤", "ğŸ›ï¸", "ç´«è‰²"),
            6: ("é˜³å°", "ğŸŒ", "é’è‰²"),
            8: ("ä¹¦æˆ¿", "ğŸ“š", "æ£•è‰²"),
        }

        # åŸºäºå®é™…æ£€æµ‹åˆ°çš„æˆ¿é—´åæ ‡ä¿¡æ¯ç»Ÿè®¡ï¼ˆé¿å…AIåˆ†å‰²è¯¯è¯†åˆ«ï¼‰
        if hasattr(self, 'last_room_info'):
            room_counts = {}
            for label, (name, _, _) in label_info.items():
                # ç»Ÿè®¡å®é™…éªŒè¯è¿‡çš„æˆ¿é—´æ•°é‡ï¼Œè€Œä¸æ˜¯AIåˆ†å‰²çš„è¿é€šåŸŸæ•°é‡
                room_type_map = {7: "å¨æˆ¿", 2: "å«ç”Ÿé—´", 3: "å®¢å…", 4: "å§å®¤", 6: "é˜³å°", 8: "ä¹¦æˆ¿"}
                room_type = room_type_map.get(label, "")
                if room_type and room_type in self.last_room_info:
                    # åªç»Ÿè®¡æœ‰æ•ˆæ£€æµ‹çš„æˆ¿é—´ï¼ˆåƒç´ >0çš„æˆ¿é—´ï¼‰
                    valid_rooms = [r for r in self.last_room_info[room_type] if r.get('pixels', 0) > 0]
                    room_counts[label] = len(valid_rooms)
                else:
                    room_counts[label] = 0
        else:
            # å›é€€åˆ°åŸæ¥çš„è¿é€šåŸŸç»Ÿè®¡æ–¹æ³•ï¼ˆä½†æ·»åŠ è­¦å‘Šï¼‰
            print("âš ï¸ è­¦å‘Šï¼šä½¿ç”¨AIåˆ†å‰²ç»“æœç»Ÿè®¡ï¼Œå¯èƒ½åŒ…å«è¯¯è¯†åˆ«")
            room_counts = {}
            for label, (name, _, _) in label_info.items():
                mask = self.last_enhanced == label
                pixel_count = np.count_nonzero(mask)
                if pixel_count > 0:
                    num, _ = cv2.connectedComponents(mask.astype(np.uint8))
                    count = num - 1  # å»é™¤èƒŒæ™¯
                else:
                    count = 0
                room_counts[label] = count

        total_rooms = sum(room_counts.values())
        summary_parts = [
            f"{room_counts[label]}ä¸ª{name}"
            for label, (name, _, _) in label_info.items()
        ]
        print(f"\nğŸ  æ£€æµ‹æ‘˜è¦ï¼ˆåŸºäºOCRéªŒè¯ï¼‰: {' + '.join(summary_parts)} = {total_rooms}ä¸ªæˆ¿é—´")

        # è¾“å‡ºå­˜åœ¨çš„æˆ¿é—´ç±»å‹åŠå…¶é¢œè‰²è¯´æ˜
        for label, (name, emoji, color) in label_info.items():
            if room_counts[label] > 0:
                print(f"{emoji} {name}æ£€æµ‹: {color}æ ‡è®°")
                
        # å¦‚æœå‘ç°AIåˆ†å‰²ä¸OCRéªŒè¯ç»“æœä¸ä¸€è‡´ï¼Œæä¾›é¢å¤–è¯´æ˜
        ai_room_counts = {}
        for label, (name, _, _) in label_info.items():
            mask = self.last_enhanced == label
            pixel_count = np.count_nonzero(mask)
            if pixel_count > 0:
                num, _ = cv2.connectedComponents(mask.astype(np.uint8))
                ai_count = num - 1
            else:
                ai_count = 0
            ai_room_counts[label] = ai_count
            
        # æ£€æŸ¥æ˜¯å¦æœ‰å·®å¼‚å¹¶æé†’
        for label, (name, _, _) in label_info.items():
            if ai_room_counts[label] != room_counts[label]:
                print(f"âš ï¸ æ³¨æ„ï¼š{name}çš„AIåˆ†å‰²æ£€æµ‹åˆ°{ai_room_counts[label]}ä¸ªåŒºåŸŸï¼Œä½†OCRéªŒè¯åç¡®è®¤ä¸º{room_counts[label]}ä¸ª")
                if ai_room_counts[label] > room_counts[label]:
                    print(f"   ğŸ’¡ å¯èƒ½å­˜åœ¨AIè¯¯è¯†åˆ«ï¼Œå»ºè®®æŸ¥çœ‹å›¾åƒä¸­æ˜¯å¦æœ‰{name}çš„é”™è¯¯è“è‰²æ ‡è®°")

    def __del__(self):
        """æ¸…ç†èµ„æº"""
        if hasattr(self, 'ai_engine') and hasattr(self.ai_engine, 'session') and self.ai_engine.session:
            self.ai_engine.session.close()

    @staticmethod
    def open_image_with_system_viewer(image_path):
        """ä½¿ç”¨ç³»ç»Ÿé»˜è®¤å›¾ç‰‡æŸ¥çœ‹å™¨æ‰“å¼€å›¾ç‰‡"""
        try:
            system = platform.system()
            if system == "Windows":
                os.startfile(image_path)
            elif system == "Darwin":  # macOS
                subprocess.run(["open", image_path])
            elif system == "Linux":
                subprocess.run(["xdg-open", image_path])
            else:
                print(f"âš ï¸ ä¸æ”¯æŒçš„æ“ä½œç³»ç»Ÿ: {system}ï¼Œæ— æ³•è‡ªåŠ¨æ‰“å¼€å›¾ç‰‡")
                return False
            
            print(f"ğŸ–¼ï¸ å·²ä½¿ç”¨ç³»ç»Ÿé»˜è®¤æŸ¥çœ‹å™¨æ‰“å¼€: {image_path}")
            return True
        except Exception as e:
            print(f"âŒ æ‰“å¼€å›¾ç‰‡å¤±è´¥: {e}")
            print(f"ğŸ“‚ è¯·æ‰‹åŠ¨æŸ¥çœ‹ç»“æœ: {image_path}")
            return False


def open_image_with_photos_app(image_path):
    """ä½¿ç”¨Windowsç…§ç‰‡åº”ç”¨æ‰“å¼€å›¾ç‰‡"""
    try:
        system = platform.system()
        if system == "Windows":
            # è·å–ç»å¯¹è·¯å¾„
            abs_path = os.path.abspath(image_path)
            print(f"ğŸ” å°è¯•æ‰“å¼€æ–‡ä»¶: {abs_path}")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(abs_path):
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {abs_path}")
                return False
            
            # æ–¹æ³•1: ä½¿ç”¨os.startfile (Windowsæ¨èæ–¹å¼)
            try:
                os.startfile(abs_path)
                print(f"ğŸ“¸ å·²ä½¿ç”¨ç³»ç»Ÿé»˜è®¤æŸ¥çœ‹å™¨ï¼ˆé€šå¸¸æ˜¯ç…§ç‰‡åº”ç”¨ï¼‰æ‰“å¼€: {os.path.basename(image_path)}")
                return True
            except Exception as e:
                print(f"âš ï¸ os.startfileå¤±è´¥: {e}")
                
                # æ–¹æ³•2: å°è¯•ä½¿ç”¨explorer
                try:
                    subprocess.run(["explorer", abs_path], check=True)
                    print(f"ğŸ“¸ å·²ä½¿ç”¨èµ„æºç®¡ç†å™¨æ‰“å¼€: {os.path.basename(image_path)}")
                    return True
                except subprocess.CalledProcessError:
                    print("âš ï¸ exploreræ–¹æ³•ä¹Ÿå¤±è´¥")
                    
                    # æ–¹æ³•3: å°è¯•PowerShell Invoke-Item
                    try:
                        subprocess.run([
                            "powershell.exe", 
                            "-Command", 
                            f"Invoke-Item '{abs_path}'"
                        ], check=True)
                        print(f"ï¿½ å·²ä½¿ç”¨PowerShellæ‰“å¼€: {os.path.basename(image_path)}")
                        return True
                    except subprocess.CalledProcessError as e:
                        print(f"âŒ PowerShellæ–¹æ³•ä¹Ÿå¤±è´¥: {e}")
                        return False
        else:
            print(f"âš ï¸ ç…§ç‰‡åº”ç”¨ä»…æ”¯æŒWindowsç³»ç»Ÿï¼Œå½“å‰ç³»ç»Ÿ: {system}")
            # å›é€€åˆ°ç³»ç»Ÿé»˜è®¤æŸ¥çœ‹å™¨
            return FloorplanProcessor.open_image_with_system_viewer(image_path)
    except Exception as e:
        print(f"âŒ æ‰“å¼€å›¾ç‰‡å¤±è´¥: {e}")
        print(f"ğŸ“‚ è¯·æ‰‹åŠ¨æŸ¥çœ‹ç»“æœ: {image_path}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="DeepFloorplan æˆ¿é—´æ£€æµ‹ - é‡æ„ç‰ˆæœ¬ (å¸¦åæ ‡è½´)"
    )
    parser.add_argument("image", help="è¾“å…¥å›¾åƒè·¯å¾„")
    parser.add_argument("--output", "-o", help="è¾“å‡ºæ–‡ä»¶åå‰ç¼€")
    parser.add_argument("--model", "-m", default="pretrained", help="æ¨¡å‹è·¯å¾„")
    parser.add_argument(
        "--fonts",
        help="é€—å·åˆ†éš”çš„å­—ä½“åˆ—è¡¨ï¼ŒæŒ‰ä¼˜å…ˆçº§ä½¿ç”¨",
    )

    args = parser.parse_args()

    # å­—ä½“å·²åœ¨æ¨¡å—åŠ è½½æ—¶åˆå§‹åŒ–ï¼Œè‹¥æœªæˆåŠŸæä¾›ä¸€æ¬¡è¿è¡ŒæœŸæç¤º
    if CH_FONT is None:
        print("âš ï¸ æœªæ‰¾åˆ°å¯ç”¨ä¸­æ–‡å­—ä½“ï¼Œå¯èƒ½å‡ºç° ? å·ã€‚å¯ä½¿ç”¨ --fonts æŒ‡å®šï¼Œä½†éœ€ç³»ç»Ÿå·²å®‰è£…å¯¹åº”å­—ä½“ã€‚")

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not Path(args.image).exists():
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.image}")
        sys.exit(1)

    # åˆ›å»ºå¤„ç†å™¨å¹¶æ‰§è¡Œ
    processor = FloorplanProcessor(args.model)
    standard_result_path = processor.process(args.image, args.output)

    # ç¡®å®šè¾“å‡ºæ–‡ä»¶è·¯å¾„
    output_base = args.output if args.output else Path(args.image).stem
    coordinate_result_path = f"output/{output_base}_coordinate_result.png"
    
    print("\nğŸ‰ å¤„ç†å®Œæˆï¼")
    print("ğŸ“‚ è¾“å‡ºç›®å½•: output/")
    print("ğŸ–¼ï¸ ä¸»è¦ç»“æœ:")
    print(f"   ğŸ“Š å¸¦åæ ‡è½´ç»“æœ: {coordinate_result_path}")
    print(f"   ğŸ“¸ æ ‡å‡†ç»“æœ: {standard_result_path}")
    
    # è‡ªåŠ¨æ‰“å¼€ç”Ÿæˆçš„å›¾ç‰‡
    print("\nğŸ–¼ï¸ æ­£åœ¨æ‰“å¼€ç»“æœå›¾ç‰‡...")
    
    # ä¼˜å…ˆæ‰“å¼€å¸¦åæ ‡è½´çš„ç»“æœå›¾ï¼ˆæ›´è¯¦ç»†ï¼‰
    if os.path.exists(coordinate_result_path):
        if open_image_with_photos_app(coordinate_result_path):
            print("âœ… å·²ä½¿ç”¨ç…§ç‰‡åº”ç”¨æ‰“å¼€å¸¦åæ ‡è½´çš„ç»“æœå›¾")
        else:
            print("âš ï¸ æ— æ³•è‡ªåŠ¨æ‰“å¼€å›¾ç‰‡ï¼Œè¯·æ‰‹åŠ¨æŸ¥çœ‹ç»“æœæ–‡ä»¶")
    elif os.path.exists(standard_result_path):
        if open_image_with_photos_app(standard_result_path):
            print("âœ… å·²ä½¿ç”¨ç…§ç‰‡åº”ç”¨æ‰“å¼€æ ‡å‡†ç»“æœå›¾")
        else:
            print("âš ï¸ æ— æ³•è‡ªåŠ¨æ‰“å¼€å›¾ç‰‡ï¼Œè¯·æ‰‹åŠ¨æŸ¥çœ‹ç»“æœæ–‡ä»¶")
    else:
        print("âŒ æ‰¾ä¸åˆ°ç”Ÿæˆçš„ç»“æœå›¾ç‰‡æ–‡ä»¶")


if __name__ == "__main__":
    main()
