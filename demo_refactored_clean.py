#!/usr/bin/env python3
"""
DeepFloorplan æˆ¿é—´æ£€æµ‹ - é‡æ„ç‰ˆæœ¬ (å¸¦åæ ‡è½´)
============================================

æœ¬æ–‡ä»¶æ˜¯ demo.py çš„å®Œå…¨é‡æ„ç‰ˆæœ¬ï¼Œä¸»è¦æ”¹è¿›ï¼š
1. é¢å‘å¯¹è±¡è®¾è®¡æ›¿ä»£è¿‡ç¨‹å¼ç¼–ç¨‹
2. æ¶ˆé™¤90%é‡å¤ä»£ç 
3. ç»Ÿä¸€é…ç½®ç®¡ç†
4. æ¸…æ™°çš„èŒè´£åˆ†ç¦»
5. ç°ä»£åŒ–ä»£ç é£æ ¼
6. åæ ‡è½´æ˜¾ç¤ºå’Œæˆ¿é—´åæ ‡ä¿¡æ¯

åŠŸèƒ½å®Œå…¨ç­‰åŒäºåŸç‰ˆæœ¬ï¼Œä½†ä»£ç æ›´ç®€æ´ã€ä¼˜é›…ã€æ˜“ç»´æŠ¤ã€‚
"""

import os
import sys
import argparse
import numpy as np
from pathlib import Path

# é…ç½®ç¯å¢ƒ
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
import warnings
warnings.filterwarnings('ignore')

import tensorflow.compat.v1 as tf
import matplotlib.pyplot as plt
import matplotlib
import cv2
from PIL import Image

# é…ç½®ä¸­æ–‡å­—ä½“
matplotlib.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False
tf.disable_v2_behavior()
tf.logging.set_verbosity(tf.logging.ERROR)

# å¯¼å…¥åŸæœ‰å·¥å…·æ¨¡å—
from utils.ocr_enhanced import extract_room_text, fuse_ocr_and_segmentation
from utils.rgb_ind_convertor import floorplan_fuse_map_figure
from room_detection_manager import RefactoredRoomDetectionManager


class FloorplanProcessor:
    """æˆ·å‹å›¾å¤„ç†å™¨ - ç»Ÿä¸€ç®¡ç†æ•´ä¸ªå¤„ç†æµç¨‹"""
    
    def __init__(self, model_path="pretrained"):
        """åˆå§‹åŒ–å¤„ç†å™¨"""
        self.model_path = model_path
        self.session = None
        self.inputs = None
        self.room_type_logit = None
        self.room_boundary_logit = None
        self.room_manager = RefactoredRoomDetectionManager()
        self.last_enhanced = None  # ç”¨äºæ‘˜è¦ç»Ÿè®¡
        
        print("ğŸ  DeepFloorplan æˆ¿é—´æ£€æµ‹ - é‡æ„ç‰ˆæœ¬ (å¸¦åæ ‡è½´)")
        print("="*60)
        
    def load_model(self):
        """åŠ è½½ç¥ç»ç½‘ç»œæ¨¡å‹"""
        print("ğŸ”§ åŠ è½½DeepFloorplanæ¨¡å‹...")
        config = tf.ConfigProto()
        config.gpu_options.allow_growth = True
        config.allow_soft_placement = True
        
        self.session = tf.Session(config=config)
        
        # åŠ è½½æ¨¡å‹
        saver = tf.train.import_meta_graph(f"{self.model_path}/pretrained_r3d.meta")
        saver.restore(self.session, f"{self.model_path}/pretrained_r3d")
        
        # è·å–è¾“å…¥è¾“å‡ºèŠ‚ç‚¹
        graph = tf.get_default_graph()
        self.inputs = graph.get_tensor_by_name("inputs:0")
        self.room_type_logit = graph.get_tensor_by_name("Cast:0")
        self.room_boundary_logit = graph.get_tensor_by_name("Cast_1:0")
        
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
        
    def preprocess_image(self, image_path):
        """å›¾åƒé¢„å¤„ç†"""
        print(f"ğŸ“¸ å¤„ç†å›¾åƒ: {image_path}")
        
        # è¯»å–å›¾åƒ
        img = Image.open(image_path).convert('RGB')
        original_size = img.size
        
        print(f"ğŸ“ åŸå§‹å›¾åƒå°ºå¯¸: {original_size[0]} x {original_size[1]} (å®½xé«˜)")
        
        # è°ƒæ•´åˆ°æ¨¡å‹è¾“å…¥å°ºå¯¸ (512x512)
        img_resized = img.resize((512, 512), Image.LANCZOS)
        img_array = np.array(img_resized) / 255.0
        
        print(f"ğŸ”„ ç¥ç»ç½‘ç»œè¾“å…¥: 512 x 512 (å›ºå®šå°ºå¯¸)")
        
        return img_array, original_size, np.array(img)
        
    def run_inference(self, img_array):
        """è¿è¡Œç¥ç»ç½‘ç»œæ¨ç†"""
        print("ğŸ¤– è¿è¡Œç¥ç»ç½‘ç»œæ¨ç†...")
        
        # æ‰©å±•ç»´åº¦ä»¥é€‚åº”æ‰¹å¤„ç†
        input_batch = np.expand_dims(img_array, axis=0)
        
        # è¿è¡Œæ¨ç†
        room_type_logit, room_boundary_logit = self.session.run(
            [self.room_type_logit, self.room_boundary_logit], 
            feed_dict={self.inputs: input_batch}
        )
        
        # åˆå¹¶æˆ¿é—´ç±»å‹å’Œè¾¹ç•Œé¢„æµ‹
        logits = np.concatenate([room_type_logit, room_boundary_logit], axis=-1)
        
        # è·å–åˆ†å‰²ç»“æœ
        prediction = np.squeeze(np.argmax(logits, axis=-1))
        
        print("âœ… ç¥ç»ç½‘ç»œæ¨ç†å®Œæˆ")
        return prediction
        
    def extract_ocr_info(self, original_img):
        """æå–OCRæ–‡å­—ä¿¡æ¯"""
        print("ğŸ” æå–OCRæ–‡å­—ä¿¡æ¯...")
        
        # OCRå¤„ç†ï¼ˆæ”¾å¤§2å€æé«˜è¯†åˆ«ç‡ï¼‰
        ocr_img = cv2.resize(original_img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
        print(f"ğŸ” OCRå¤„ç†å›¾åƒ: {ocr_img.shape[1]} x {ocr_img.shape[0]} (æ”¾å¤§2å€)")
        
        # æå–æˆ¿é—´æ–‡å­—
        room_text_items = extract_room_text(ocr_img)
        
        print(f"ğŸ“Š PaddleOCRæ£€æµ‹åˆ° {len(room_text_items)} ä¸ªæ–‡å­—åŒºåŸŸ")
        
        return room_text_items, ocr_img.shape
        
    def fuse_predictions(self, prediction, room_text_items, ocr_shape):
        """èåˆç¥ç»ç½‘ç»œé¢„æµ‹å’ŒOCRç»“æœ"""
        print("ğŸ”— èåˆç¥ç»ç½‘ç»œé¢„æµ‹å’ŒOCRç»“æœ...")
        
        # è®¡ç®—åæ ‡è½¬æ¢æ¯”ä¾‹
        ocr_to_512_x = 512.0 / ocr_shape[1]  
        ocr_to_512_y = 512.0 / ocr_shape[0]
        
        print(f"   ğŸ”„ OCRåæ ‡è½¬æ¢åˆ°512x512:")
        print(f"      OCRå›¾åƒ({ocr_shape[1]}x{ocr_shape[0]}) -> 512x512")
        print(f"      è½¬æ¢æ¯”ä¾‹: X={ocr_to_512_x:.3f}, Y={ocr_to_512_y:.3f}")
        
        # è½¬æ¢OCRåæ ‡åˆ°512x512åæ ‡ç³»
        converted_items = []
        for item in room_text_items:
            # å¤åˆ¶itemå¹¶è½¬æ¢åæ ‡
            converted_item = item.copy()
            x, y, w, h = item['bbox']
            
            # è½¬æ¢åˆ°512x512åæ ‡ç³»
            new_x = int(x * ocr_to_512_x)
            new_y = int(y * ocr_to_512_y)
            new_w = int(w * ocr_to_512_x)
            new_h = int(h * ocr_to_512_y)
            
            # ç¡®ä¿åæ ‡åœ¨512x512èŒƒå›´å†…
            new_x = max(0, min(new_x, 511))
            new_y = max(0, min(new_y, 511))
            new_w = max(1, min(new_w, 512 - new_x))
            new_h = max(1, min(new_h, 512 - new_y))
            
            converted_item['bbox'] = [new_x, new_y, new_w, new_h]
            converted_items.append(converted_item)
        
        # èåˆOCRæ ‡ç­¾åˆ°åˆ†å‰²ç»“æœ
        enhanced = fuse_ocr_and_segmentation(prediction.copy(), converted_items)
        
        return enhanced
        
    def detect_rooms(self, enhanced, room_text_items, original_size):
        """æ£€æµ‹å„ç±»æˆ¿é—´"""
        print("ğŸ  å¼€å§‹æˆ¿é—´æ£€æµ‹...")
        
        # ä½¿ç”¨é‡æ„ç®¡ç†å™¨çš„ç»Ÿä¸€æ¥å£
        enhanced = self.room_manager.detect_all_rooms(enhanced, room_text_items)
        
        return enhanced
        
    def generate_results(self, enhanced, original_img, original_size, output_path):
        """ç”Ÿæˆæœ€ç»ˆç»“æœï¼ŒåŒ…å«åæ ‡è½´å’Œæˆ¿é—´åæ ‡ä¿¡æ¯"""
        print("ğŸ¨ ç”Ÿæˆç»“æœå›¾åƒ...")
        
        # è°ƒæ•´å›åŸå§‹å°ºå¯¸
        enhanced_resized = cv2.resize(
            enhanced, original_size, interpolation=cv2.INTER_NEAREST
        )
        
        # ç”Ÿæˆå½©è‰²åˆ†å‰²å›¾ - ä½¿ç”¨é¢œè‰²æ˜ å°„å­—å…¸
        h, w = enhanced_resized.shape
        colored_result = np.zeros((h, w, 3), dtype=np.uint8)
        
        # åº”ç”¨é¢œè‰²æ˜ å°„
        for label_value, color in floorplan_fuse_map_figure.items():
            mask = (enhanced_resized == label_value)
            colored_result[mask] = color
        
        # å åŠ åˆ°åŸå›¾
        alpha = 0.5
        final_result = cv2.addWeighted(original_img, 1-alpha, colored_result, alpha, 0)
        
        # ä½¿ç”¨matplotlibåˆ›å»ºå¸¦åæ ‡è½´çš„å›¾åƒ
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))
        
        # å·¦å›¾ï¼šåŸå›¾ + åˆ†å‰²ç»“æœ
        ax1.imshow(final_result)
        ax1.set_title('æˆ¿é—´æ£€æµ‹ç»“æœ', fontsize=14, fontweight='bold')
        ax1.grid(True, alpha=0.3)
        ax1.set_xlabel('Xåæ ‡ (åƒç´ )', fontsize=12)
        ax1.set_ylabel('Yåæ ‡ (åƒç´ )', fontsize=12)
        
        # æ·»åŠ æˆ¿é—´æ ‡æ³¨å’Œåæ ‡
        room_info = self._extract_room_coordinates(enhanced_resized, original_size, self.last_room_text_items)
        for room_type, room_list in room_info.items():
            for i, coords in enumerate(room_list):
                if coords['pixels'] > 0:  # åªæ˜¾ç¤ºæœ‰æ•ˆæ£€æµ‹çš„æˆ¿é—´
                    center_x, center_y = coords['center']
                    bbox = coords['bbox']
                    
                    # åœ¨å›¾ä¸Šæ ‡æ³¨æˆ¿é—´ä¸­å¿ƒç‚¹
                    ax1.plot(center_x, center_y, 'o', markersize=10, 
                            color='white', markeredgecolor='black', markeredgewidth=2)
                    
                    # æˆ¿é—´æ ‡æ³¨ï¼ˆå¦‚æœæœ‰å¤šä¸ªåŒç±»å‹æˆ¿é—´ï¼ŒåŠ ä¸Šç¼–å·ï¼‰
                    if len(room_list) > 1:
                        label_text = f'{room_type}{i+1}\n({center_x},{center_y})'
                    else:
                        label_text = f'{room_type}\n({center_x},{center_y})'
                        
                    ax1.annotate(label_text, 
                               xy=(center_x, center_y), 
                               xytext=(10, 10), textcoords='offset points',
                               fontsize=10, fontweight='bold',
                               bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8),
                               arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))
                    
                    # ç»˜åˆ¶è¾¹ç•Œæ¡†
                    x1, y1, x2, y2 = bbox
                    rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, 
                                       fill=False, edgecolor='red', linewidth=2, linestyle='--')
                    ax1.add_patch(rect)
        
        # å³å›¾ï¼šçº¯åˆ†å‰²ç»“æœ
        ax2.imshow(colored_result)
        ax2.set_title('åˆ†å‰²æ ‡ç­¾å›¾', fontsize=14, fontweight='bold')
        ax2.grid(True, alpha=0.3)
        ax2.set_xlabel('Xåæ ‡ (åƒç´ )', fontsize=12)
        ax2.set_ylabel('Yåæ ‡ (åƒç´ )', fontsize=12)
        
        # æ·»åŠ å›¾ä¾‹
        legend_elements = []
        room_colors = {
            7: ('å¨æˆ¿', 'green'),
            2: ('å«ç”Ÿé—´', 'blue'),
            3: ('å®¢å…', 'orange'),
            4: ('å§å®¤', 'purple'),
            6: ('é˜³å°', 'cyan'),
            8: ('ä¹¦æˆ¿', 'brown'),
            9: ('å¢™ä½“', 'gray'),
            10: ('å¢™ä½“', 'gray')
        }
        
        for label, (name, color) in room_colors.items():
            if np.any(enhanced_resized == label):
                legend_elements.append(plt.Line2D([0], [0], marker='s', color='w', 
                                                markerfacecolor=color, markersize=10, label=f'{name} (æ ‡ç­¾{label})'))
        
        ax2.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(1.3, 1))
        
        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()
        
        # ä¿å­˜ç»“æœ
        output_dir = Path("output")
        output_dir.mkdir(exist_ok=True)
        
        base_name = Path(output_path).stem
        
        # ä¿å­˜å¸¦åæ ‡è½´çš„å›¾åƒ
        coordinate_result_path = output_dir / f"{base_name}_coordinate_result.png"
        plt.savefig(coordinate_result_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š å¸¦åæ ‡è½´ç»“æœå·²ä¿å­˜: {coordinate_result_path}")
        
        # ä¿å­˜åŸå§‹ç»“æœï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
        result_path = output_dir / f"{base_name}_result.png"
        cv2.imwrite(str(result_path), cv2.cvtColor(final_result, cv2.COLOR_RGB2BGR))
        print(f"ğŸ“¸ æ ‡å‡†ç»“æœå·²ä¿å­˜: {result_path}")
        
        # è¾“å‡ºæˆ¿é—´åæ ‡ä¿¡æ¯
        self._print_room_coordinates(room_info, original_size)
        
        plt.close()
        
        return final_result
    
    def _extract_room_coordinates(self, enhanced_resized, original_size, room_text_items):
        """æå–å„æˆ¿é—´çš„åæ ‡ä¿¡æ¯ï¼Œä¼˜å…ˆä½¿ç”¨OCRæ–‡å­—ä½ç½®ï¼Œæ”¯æŒå¤šä¸ªåŒç±»å‹æˆ¿é—´"""
        room_info = {}
        
        # è®¡ç®—åæ ‡è½¬æ¢æ¯”ä¾‹
        original_width, original_height = original_size
        
        # å®šä¹‰æˆ¿é—´ç±»å‹
        room_types = ['å¨æˆ¿', 'å«ç”Ÿé—´', 'å®¢å…', 'å§å®¤', 'é˜³å°', 'ä¹¦æˆ¿']
        
        # åˆå§‹åŒ–æ‰€æœ‰æˆ¿é—´ä¿¡æ¯ä¸ºç©ºåˆ—è¡¨ï¼Œæ”¯æŒå¤šä¸ªåŒç±»å‹æˆ¿é—´
        for room_type in room_types:
            room_info[room_type] = []
        
        # ä¼˜å…ˆä½¿ç”¨OCRæ–‡å­—ä½ç½®ç¡®å®šæˆ¿é—´åæ ‡
        for item in room_text_items:
            text = item['text'].lower().strip()
            
            # åŒ¹é…æˆ¿é—´ç±»å‹
            room_type = None
            if any(keyword in text for keyword in ['å¨æˆ¿', 'kitchen', 'å¨']):
                room_type = 'å¨æˆ¿'
            elif any(keyword in text for keyword in ['å«ç”Ÿé—´', 'bathroom', 'å«', 'æ´—æ‰‹é—´', 'æµ´å®¤', 'æ·‹æµ´é—´', 'shower', 'æ·‹æµ´', 'ç›¥æ´—å®¤']):
                room_type = 'å«ç”Ÿé—´'  
            elif any(keyword in text for keyword in ['å®¢å…', 'living', 'å…', 'èµ·å±…å®¤']):
                room_type = 'å®¢å…'
            elif any(keyword in text for keyword in ['å§å®¤', 'bedroom', 'ä¸»å§', 'æ¬¡å§']):
                room_type = 'å§å®¤'
            elif any(keyword in text for keyword in ['é˜³å°', 'balcony']):
                room_type = 'é˜³å°'
            elif any(keyword in text for keyword in ['ä¹¦æˆ¿', 'study', 'ä¹¦', 'åŠå…¬å®¤', 'office']):
                room_type = 'ä¹¦æˆ¿'
            
            if room_type and room_type in room_info:
                # ä½¿ç”¨OCRæ–‡å­—çš„ä¸­å¿ƒä½ç½®
                x, y, w, h = item['bbox']
                
                # è®¡ç®—OCRæ–‡å­—ä¸­å¿ƒï¼ˆåœ¨OCRå¤„ç†çš„å›¾åƒåæ ‡ç³»ä¸­ï¼‰
                ocr_center_x = x + w // 2
                ocr_center_y = y + h // 2
                
                # OCRå›¾åƒæ˜¯æ”¾å¤§2å€çš„ï¼Œéœ€è¦å…ˆè½¬æ¢åˆ°åŸå§‹å›¾åƒåæ ‡
                orig_center_x = int(ocr_center_x / 2)
                orig_center_y = int(ocr_center_y / 2)
                
                # è®¡ç®—è¾¹ç•Œæ¡†ï¼ˆåŸºäºæ–‡å­—ä½ç½®ä¼°ç®—æˆ¿é—´åŒºåŸŸï¼‰
                text_width = max(50, w // 2)  # æœ€å°50åƒç´ å®½åº¦
                text_height = max(30, h // 2)  # æœ€å°30åƒç´ é«˜åº¦
                
                min_x = max(0, orig_center_x - text_width)
                max_x = min(original_width - 1, orig_center_x + text_width)
                min_y = max(0, orig_center_y - text_height)
                max_y = min(original_height - 1, orig_center_y + text_height)
                
                room_info[room_type].append({
                    'center': (orig_center_x, orig_center_y),
                    'bbox': (min_x, min_y, max_x, max_y),
                    'pixels': text_width * text_height * 2,  # ä¼°ç®—é¢ç§¯
                    'width': max_x - min_x + 1,
                    'height': max_y - min_y + 1,
                    'text': text,
                    'confidence': item.get('confidence', 0.0)
                })
        
        # å¯¹äºæ²¡æœ‰OCRæ£€æµ‹åˆ°çš„æˆ¿é—´ï¼Œå°è¯•ä»åˆ†å‰²ç»“æœä¸­æå–
        label_mapping = {7: 'å¨æˆ¿', 2: 'å«ç”Ÿé—´', 3: 'å®¢å…', 4: 'å§å®¤', 6: 'é˜³å°', 8: 'ä¹¦æˆ¿'}
        
        for label, room_type in label_mapping.items():
            if len(room_info[room_type]) == 0:  # OCRæ²¡æœ‰æ£€æµ‹åˆ°
                mask = (enhanced_resized == label)
                pixels = np.sum(mask)
                
                if pixels > 0:
                    # æ‰¾åˆ°æˆ¿é—´åŒºåŸŸçš„åæ ‡
                    coords = np.where(mask)
                    y_coords, x_coords = coords
                    
                    # è®¡ç®—è¾¹ç•Œæ¡†
                    min_x_512, max_x_512 = np.min(x_coords), np.max(x_coords)
                    min_y_512, max_y_512 = np.min(y_coords), np.max(y_coords)
                    
                    # è®¡ç®—ä¸­å¿ƒç‚¹
                    center_x_512 = int(np.mean(x_coords))
                    center_y_512 = int(np.mean(y_coords))
                    
                    # è½¬æ¢åˆ°åŸå§‹å›¾åƒå°ºå¯¸
                    scale_x = original_width / 512.0
                    scale_y = original_height / 512.0
                    
                    center_x = int(center_x_512 * scale_x)
                    center_y = int(center_y_512 * scale_y)
                    min_x = int(min_x_512 * scale_x)
                    max_x = int(max_x_512 * scale_x)
                    min_y = int(min_y_512 * scale_y)
                    max_y = int(max_y_512 * scale_y)
                    
                    room_info[room_type].append({
                        'center': (center_x, center_y),
                        'bbox': (min_x, min_y, max_x, max_y),
                        'pixels': pixels,
                        'width': max_x - min_x + 1,
                        'height': max_y - min_y + 1,
                        'text': 'åˆ†å‰²æ£€æµ‹',
                        'confidence': 0.5
                    })
        
        return room_info
    
    def _print_room_coordinates(self, room_info, original_size):
        """æ‰“å°æˆ¿é—´åæ ‡è¯¦ç»†ä¿¡æ¯ï¼Œæ”¯æŒå¤šä¸ªåŒç±»å‹æˆ¿é—´"""
        print("\n" + "="*60)
        print("ğŸ“ æˆ¿é—´åæ ‡è¯¦ç»†ä¿¡æ¯")
        print("="*60)
        print(f"ğŸ“ å›¾åƒå°ºå¯¸: {original_size[0]} x {original_size[1]} (å®½ x é«˜)")
        print("-"*60)
        
        total_rooms = 0
        for room_type, room_list in room_info.items():
            if len(room_list) > 0:
                for i, info in enumerate(room_list):
                    if info['pixels'] > 0:
                        center_x, center_y = info['center']
                        min_x, min_y, max_x, max_y = info['bbox']
                        
                        # å¦‚æœæœ‰å¤šä¸ªåŒç±»å‹æˆ¿é—´ï¼Œæ˜¾ç¤ºç¼–å·
                        if len(room_list) > 1:
                            display_name = f"{room_type}{i+1}"
                        else:
                            display_name = room_type
                            
                        print(f"ğŸ  {display_name}:")
                        print(f"   ğŸ“ ä¸­å¿ƒåæ ‡: ({center_x}, {center_y})")
                        print(f"   ğŸ“ è¾¹ç•Œæ¡†: å·¦ä¸Š({min_x}, {min_y}) -> å³ä¸‹({max_x}, {max_y})")
                        print(f"   ğŸ“ å°ºå¯¸: {info['width']} x {info['height']} åƒç´ ")
                        print(f"   ğŸ“Š é¢ç§¯: {info['pixels']} åƒç´ ")
                        print(f"   ğŸ“„ è¯†åˆ«æ–‡æœ¬: '{info['text']}' (ç½®ä¿¡åº¦: {info['confidence']:.3f})")
                        print(f"   ğŸ”— åæ ‡èŒƒå›´: X[{min_x}-{max_x}], Y[{min_y}-{max_y}]")
                        print("-"*60)
                        total_rooms += 1
            
            # å¦‚æœè¯¥ç±»å‹æˆ¿é—´æœªæ£€æµ‹åˆ°
            if len(room_list) == 0:
                print(f"âŒ {room_type}: æœªæ£€æµ‹åˆ°")
                print("-"*60)
        
        print("ğŸ’¡ åæ ‡ç³»è¯´æ˜:")
        print("   â€¢ åŸç‚¹(0,0)åœ¨å›¾åƒå·¦ä¸Šè§’")
        print("   â€¢ Xè½´å‘å³ä¸ºæ­£æ–¹å‘") 
        print("   â€¢ Yè½´å‘ä¸‹ä¸ºæ­£æ–¹å‘")
        print("   â€¢ æ‰€æœ‰åæ ‡å•ä½ä¸ºåƒç´ ")
        print("="*60)
        print(f"\nğŸ“Š æ€»è®¡æ£€æµ‹åˆ° {total_rooms} ä¸ªæˆ¿é—´")
        print("="*60)
        
    def process(self, image_path, output_path=None):
        """å®Œæ•´å¤„ç†æµç¨‹"""
        try:
            # è®¾ç½®è¾“å‡ºè·¯å¾„
            if output_path is None:
                output_path = Path(image_path).stem
                
            # 1. åŠ è½½æ¨¡å‹
            if self.session is None:
                self.load_model()
                
            # 2. å›¾åƒé¢„å¤„ç†
            img_array, original_size, original_img = self.preprocess_image(image_path)
            
            # 3. ç¥ç»ç½‘ç»œæ¨ç†
            prediction = self.run_inference(img_array)
            
            # 4. OCRæ–‡å­—æå–
            room_text_items, ocr_shape = self.extract_ocr_info(original_img)
            
            # ä¿å­˜room_text_itemsç”¨äºåæ ‡æå–
            self.last_room_text_items = room_text_items
            
            # 5. èåˆé¢„æµ‹ç»“æœ
            enhanced = self.fuse_predictions(prediction, room_text_items, ocr_shape)
            
            # 6. æˆ¿é—´æ£€æµ‹
            enhanced = self.detect_rooms(enhanced, room_text_items, original_size)
            
            # 7. ç”Ÿæˆç»“æœ
            result = self.generate_results(enhanced, original_img, original_size, output_path)
            
            # 8. ä¿å­˜ç»“æœç”¨äºæ‘˜è¦ç»Ÿè®¡
            self.last_enhanced = enhanced
            
            # 9. æ˜¾ç¤ºæ‘˜è¦
            self._print_summary()
            
            return result
            
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            raise
            
    def _print_summary(self):
        """æ‰“å°æ£€æµ‹æ‘˜è¦"""
        # ç»Ÿè®¡æ£€æµ‹åˆ°çš„æˆ¿é—´æ•°é‡
        kitchen_count = 1 if np.any(self.last_enhanced == 7) else 0
        bathroom_count = 1 if np.any(self.last_enhanced == 2) else 0  
        living_count = 1 if np.any(self.last_enhanced == 3) else 0
        
        total_rooms = kitchen_count + bathroom_count + living_count
        
        print(f"\nğŸ  æ£€æµ‹æ‘˜è¦: {kitchen_count}ä¸ªå¨æˆ¿ + "
              f"{bathroom_count}ä¸ªå«ç”Ÿé—´ + "
              f"{living_count}ä¸ªå®¢å… = {total_rooms}ä¸ªæˆ¿é—´")
        
        if kitchen_count > 0:
            print("ğŸ³ å¨æˆ¿æ£€æµ‹: ç»¿è‰²æ ‡è®°")
        if bathroom_count > 0:
            print("ğŸš¿ å«ç”Ÿé—´æ£€æµ‹: è“è‰²æ ‡è®°")
        if living_count > 0:
            print("ğŸ  å®¢å…æ£€æµ‹: æ©™è‰²æ ‡è®°")
            
    def __del__(self):
        """æ¸…ç†èµ„æº"""
        if self.session:
            self.session.close()


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='DeepFloorplan æˆ¿é—´æ£€æµ‹ - é‡æ„ç‰ˆæœ¬ (å¸¦åæ ‡è½´)')
    parser.add_argument('image', help='è¾“å…¥å›¾åƒè·¯å¾„')
    parser.add_argument('--output', '-o', help='è¾“å‡ºæ–‡ä»¶åå‰ç¼€')
    parser.add_argument('--model', '-m', default='pretrained', help='æ¨¡å‹è·¯å¾„')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not Path(args.image).exists():
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.image}")
        sys.exit(1)
        
    # åˆ›å»ºå¤„ç†å™¨å¹¶æ‰§è¡Œ
    processor = FloorplanProcessor(args.model)
    result = processor.process(args.image, args.output)
    
    print("âœ… å¤„ç†å®Œæˆ!")


if __name__ == "__main__":
    main()
