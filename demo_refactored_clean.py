#!/usr/bin/env python3
"""
DeepFloorplan æˆ¿é—´æ£€æµ‹ - é‡æ„ç‰ˆæœ¬ (å¸¦åæ ‡è½´)
============================================

æœ¬æ–‡ä»¶æ˜¯ demo.py çš„å®Œå…¨é‡æ„ç‰ˆæœ¬ï¼Œä¸»è¦æ”¹è¿›ï¼š
1. é¢å‘å¯¹è±¡è®¾è®¡æ›¿ä»£è¿‡ç¨‹å¼ç¼–ç¨‹
2. æ¶ˆé™¤90%é‡å¤ä»£ç 
3. ç»Ÿä¸€é…ç½®ç®¡ç†
4. æ¸…æ™°çš„èŒè´£åˆ†ç¦»
5. ç°ä»£åŒ–ä»£ç é£æ ¼
6. åæ ‡è½´æ˜¾ç¤ºå’Œæˆ¿é—´åæ ‡ä¿¡æ¯

åŠŸèƒ½å®Œå…¨ç­‰åŒäºåŸç‰ˆæœ¬ï¼Œä½†ä»£ç æ›´ç®€æ´ã€ä¼˜é›…ã€æ˜“ç»´æŠ¤ã€‚
"""

import os
import sys
import subprocess
import platform
import argparse
import numpy as np
from pathlib import Path

# é…ç½®ç¯å¢ƒ
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"
import warnings

warnings.filterwarnings("ignore")

import tensorflow.compat.v1 as tf
import matplotlib.pyplot as plt
import matplotlib
import cv2
from PIL import Image

# é…ç½®ä¸­æ–‡å­—ä½“
matplotlib.rcParams["font.sans-serif"] = ["Microsoft YaHei", "SimHei", "DejaVu Sans"]
matplotlib.rcParams["axes.unicode_minus"] = False
tf.disable_v2_behavior()
tf.logging.set_verbosity(tf.logging.ERROR)

# å¯¼å…¥åŸæœ‰å·¥å…·æ¨¡å—
from utils.ocr_enhanced import extract_room_text, fuse_ocr_and_segmentation, text_to_label
from utils.rgb_ind_convertor import floorplan_fuse_map_figure
from room_detection_manager import RefactoredRoomDetectionManager


# ============================================================
# å››å±‚æ™ºèƒ½å†³ç­–æ¶æ„
# ============================================================

class AISegmentationEngine:
    """ç¬¬ä¸€å±‚ï¼šAIè¯­ä¹‰åˆ†å‰²å™¨"""
    
    def __init__(self, model_path="pretrained"):
        self.model_path = model_path
        self.session = None
        self.inputs = None
        self.room_type_logit = None
        self.room_boundary_logit = None
    
    def load_model(self):
        """åŠ è½½ç¥ç»ç½‘ç»œæ¨¡å‹"""
        print("ğŸ”§ [ç¬¬1å±‚-AIåˆ†å‰²å™¨] åŠ è½½DeepFloorplanæ¨¡å‹...")
        config = tf.ConfigProto()
        config.gpu_options.allow_growth = True
        config.allow_soft_placement = True

        self.session = tf.Session(config=config)
        saver = tf.train.import_meta_graph(f"{self.model_path}/pretrained_r3d.meta")
        saver.restore(self.session, f"{self.model_path}/pretrained_r3d")

        graph = tf.get_default_graph()
        self.inputs = graph.get_tensor_by_name("inputs:0")
        self.room_type_logit = graph.get_tensor_by_name("Cast:0")
        self.room_boundary_logit = graph.get_tensor_by_name("Cast_1:0")
        print("âœ… [ç¬¬1å±‚-AIåˆ†å‰²å™¨] æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def segment_image(self, img_array):
        """æ‰§è¡Œè¯­ä¹‰åˆ†å‰²"""
        print("ğŸ¤– [ç¬¬1å±‚-AIåˆ†å‰²å™¨] è¿è¡Œç¥ç»ç½‘ç»œæ¨ç†...")
        input_batch = np.expand_dims(img_array, axis=0)
        
        room_type_logit, room_boundary_logit = self.session.run(
            [self.room_type_logit, self.room_boundary_logit],
            feed_dict={self.inputs: input_batch},
        )
        
        logits = np.concatenate([room_type_logit, room_boundary_logit], axis=-1)
        prediction = np.squeeze(np.argmax(logits, axis=-1))
        print("âœ… [ç¬¬1å±‚-AIåˆ†å‰²å™¨] ç¥ç»ç½‘ç»œæ¨ç†å®Œæˆ")
        return prediction


class OCRRecognitionEngine:
    """ç¬¬äºŒå±‚ï¼šOCRæ–‡å­—è¯†åˆ«å™¨"""
    
    def __init__(self):
        pass
    
    def recognize_text(self, original_img):
        """è¯†åˆ«å›¾åƒä¸­çš„æ–‡å­—"""
        print("ğŸ” [ç¬¬2å±‚-OCRè¯†åˆ«å™¨] æå–OCRæ–‡å­—ä¿¡æ¯...")
        
        # OCRå¤„ç†ï¼ˆæ”¾å¤§2å€æé«˜è¯†åˆ«ç‡ï¼‰
        ocr_img = cv2.resize(original_img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
        print(f"ğŸ” [ç¬¬2å±‚-OCRè¯†åˆ«å™¨] å¤„ç†å›¾åƒ: {ocr_img.shape[1]} x {ocr_img.shape[0]} (æ”¾å¤§2å€)")
        
        room_text_items = extract_room_text(ocr_img)
        print(f"ğŸ“Š [ç¬¬2å±‚-OCRè¯†åˆ«å™¨] æ£€æµ‹åˆ° {len(room_text_items)} ä¸ªæ–‡å­—åŒºåŸŸ")
        
        return room_text_items, ocr_img.shape


class FusionDecisionEngine:
    """ç¬¬ä¸‰å±‚ï¼šèåˆå†³ç­–å™¨"""
    
    def __init__(self):
        self.room_manager = RefactoredRoomDetectionManager()
    
    def fuse_results(self, ai_prediction, ocr_results, ocr_shape):
        """æ™ºèƒ½èåˆAIåˆ†å‰²å’ŒOCRè¯†åˆ«ç»“æœ"""
        print("ğŸ”— [ç¬¬3å±‚-èåˆå†³ç­–å™¨] èåˆAIå’ŒOCRç»“æœ...")
        
        # åæ ‡è½¬æ¢
        ocr_to_512_x = 512.0 / ocr_shape[1]
        ocr_to_512_y = 512.0 / ocr_shape[0]
        print(f"   ğŸ”„ [ç¬¬3å±‚-èåˆå†³ç­–å™¨] OCRåæ ‡è½¬æ¢åˆ°512x512:")
        print(f"      OCRå›¾åƒ({ocr_shape[1]}x{ocr_shape[0]}) -> 512x512")
        print(f"      è½¬æ¢æ¯”ä¾‹: X={ocr_to_512_x:.3f}, Y={ocr_to_512_y:.3f}")
        
        # ä¿å­˜åŸå§‹OCRç»“æœï¼ˆç”¨äºåç»­æ¸…ç†ç®—æ³•ï¼‰
        original_ocr_results = [item.copy() for item in ocr_results]
        
        # åœ¨OCRç»“æœä¸­æ·»åŠ å°ºå¯¸ä¿¡æ¯ï¼Œä¾›åç»­ä½¿ç”¨
        for item in ocr_results:
            item['ocr_width'] = ocr_shape[1]
            item['ocr_height'] = ocr_shape[0]
        
        # è½¬æ¢OCRåæ ‡åˆ°512x512åæ ‡ç³»ï¼ˆç”¨äºç¥ç»ç½‘ç»œèåˆï¼‰
        converted_items = self._convert_ocr_coordinates(ocr_results, ocr_to_512_x, ocr_to_512_y)

        # æ‹†åˆ†å¨æˆ¿OCRï¼Œç”¨äºå¼€æ”¾å¼å¨æˆ¿ä¼°ç®—
        processed_items = []
        open_kitchens = []
        for item in converted_items:
            label = text_to_label(item['text'])
            if label == 7:
                x, y, w, h = item['bbox']
                cx, cy = x + w // 2, y + h // 2
                if ai_prediction[cy, cx] == 3:
                    open_kitchens.append(item)
                    print(f"   ğŸ³ è¯†åˆ«åˆ°å¼€æ”¾å¼å¨æˆ¿å€™é€‰: {item['text']}")
                else:
                    processed_items.append(item)
            else:
                processed_items.append(item)

        # èåˆOCRæ ‡ç­¾åˆ°åˆ†å‰²ç»“æœï¼ˆä¸å«å¼€æ”¾å¼å¨æˆ¿ï¼‰
        enhanced = fuse_ocr_and_segmentation(ai_prediction.copy(), processed_items)

        # å¼€æ”¾å¼å¨æˆ¿åŒºåŸŸä¼°ç®—
        enhanced = self._estimate_open_kitchen(enhanced, open_kitchens)
        
        # æˆ¿é—´æ£€æµ‹å’Œç”Ÿæˆï¼ˆä½¿ç”¨åŸå§‹OCRç»“æœï¼‰
        enhanced = self.room_manager.detect_all_rooms(enhanced, original_ocr_results)
        
        # æ·»åŠ OCRæ£€æµ‹åˆ°çš„é˜³å°åŒºåŸŸæ ‡æ³¨
        enhanced = self._add_balcony_regions(enhanced, original_ocr_results, ocr_to_512_x, ocr_to_512_y)
        
        # åŸºç¡€æ¸…ç†ï¼ˆä½¿ç”¨åŸå§‹OCRç»“æœè¿›è¡Œè·ç¦»è®¡ç®—ï¼‰
        enhanced = self._basic_cleanup(enhanced, original_ocr_results, ocr_to_512_x, ocr_to_512_y)
        
        print("âœ… [ç¬¬3å±‚-èåˆå†³ç­–å™¨] èåˆå®Œæˆ")
        return enhanced
    
    def _convert_ocr_coordinates(self, room_text_items, scale_x, scale_y):
        """è½¬æ¢OCRåæ ‡åˆ°512x512åæ ‡ç³»"""
        converted_items = []
        for item in room_text_items:
            converted_item = item.copy()
            x, y, w, h = item["bbox"]
            
            new_x = max(0, min(int(x * scale_x), 511))
            new_y = max(0, min(int(y * scale_y), 511))
            new_w = max(1, min(int(w * scale_x), 512 - new_x))
            new_h = max(1, min(int(h * scale_y), 512 - new_y))
            
            converted_item["bbox"] = [new_x, new_y, new_w, new_h]
            converted_items.append(converted_item)
        
        return converted_items

    def _estimate_open_kitchen(self, enhanced, kitchen_items, size=60):
        """Estimate open kitchen areas when no wall is detected."""
        if not kitchen_items:
            return enhanced

        print("ğŸ³ [ç¬¬3å±‚-èåˆå†³ç­–å™¨] ä¼°ç®—å¼€æ”¾å¼å¨æˆ¿åŒºåŸŸ...")
        for item in kitchen_items:
            x, y, w, h = item['bbox']
            cx, cy = x + w // 2, y + h // 2
            half = size // 2
            x1 = max(0, cx - half)
            y1 = max(0, cy - half)
            x2 = min(enhanced.shape[1] - 1, cx + half)
            y2 = min(enhanced.shape[0] - 1, cy + half)
            print(f"   â• å¼€æ”¾å¼å¨æˆ¿åŒºåŸŸ: ({x1}, {y1}) -> ({x2}, {y2})")
            patch = enhanced[y1:y2, x1:x2]
            mask = ~np.isin(patch, [9, 10])
            patch[mask] = 7
            enhanced[y1:y2, x1:x2] = patch

        return enhanced
    
    def _add_balcony_regions(self, enhanced, original_ocr_results, scale_x, scale_y):
        """ä¸ºOCRæ£€æµ‹åˆ°çš„é˜³å°æ·»åŠ åˆ†å‰²æ ‡æ³¨"""
        print("ğŸŒ [ç¬¬3å±‚-èåˆå†³ç­–å™¨] æ·»åŠ é˜³å°åŒºåŸŸæ ‡æ³¨...")
        
        balcony_items = []
        for item in original_ocr_results:
            text = item["text"].lower().strip()
            if any(keyword in text for keyword in ["é˜³å°", "balcony", "é˜³å…®", "é˜³åˆ", "é˜³å›Š"]):
                balcony_items.append(item)
                print(f"   ğŸ¯ å‘ç°é˜³å°OCR: '{item['text']}' (ç½®ä¿¡åº¦: {item['confidence']:.3f})")
        
        # ä¸ºæ¯ä¸ªæ£€æµ‹åˆ°çš„é˜³å°åˆ›å»ºåŒºåŸŸæ ‡æ³¨
        for item in balcony_items:
            x, y, w, h = item["bbox"]
            # è½¬æ¢åˆ°512x512åæ ‡ç³»
            center_x_512 = int((x + w//2) * scale_x)
            center_y_512 = int((y + h//2) * scale_y)
            
            # ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
            center_x_512 = max(0, min(center_x_512, 511))
            center_y_512 = max(0, min(center_y_512, 511))
            
            # åˆ›å»ºé˜³å°åŒºåŸŸï¼ˆä½¿ç”¨é€‚ä¸­çš„å°ºå¯¸ï¼‰
            balcony_size = 30  # é˜³å°é€šå¸¸æ¯”è¾ƒå°
            x1 = max(0, center_x_512 - balcony_size // 2)
            y1 = max(0, center_y_512 - balcony_size // 2)
            x2 = min(511, center_x_512 + balcony_size // 2)
            y2 = min(511, center_y_512 + balcony_size // 2)
            
            # åœ¨è¯¥åŒºåŸŸè®¾ç½®é˜³å°æ ‡ç­¾ï¼ˆ6ï¼‰
            enhanced[y1:y2, x1:x2] = 6
            print(f"   âœ… é˜³å°åŒºåŸŸæ ‡æ³¨: ä¸­å¿ƒ({center_x_512}, {center_y_512}), åŒºåŸŸ({x1}, {y1}) -> ({x2}, {y2})")
        
        return enhanced
    
    def _basic_cleanup(self, enhanced, original_ocr_results, scale_x, scale_y):
        """åŸºç¡€æ¸…ç†ï¼šè·ç¦»é˜ˆå€¼æ¸…ç†"""
        print("ğŸ§¹ [ç¬¬3å±‚-èåˆå†³ç­–å™¨] åŸºç¡€æ¸…ç†...")
        
        # è·å–OCRéªŒè¯çš„æˆ¿é—´ä½ç½®ï¼ˆä½¿ç”¨åŸå§‹åæ ‡è½¬æ¢åˆ°512x512ï¼‰
        ocr_rooms = self._extract_ocr_rooms_for_cleanup(original_ocr_results, scale_x, scale_y)
        
        # æ¸…ç†è¯¯è¯†åˆ«åŒºåŸŸ
        for room_label, room_positions in ocr_rooms.items():
            if room_label in [2, 3, 4, 7]:  # å¤„ç†å«ç”Ÿé—´ã€å®¢å…ã€å§å®¤å’Œå¨æˆ¿
                enhanced = self._clean_room_type(enhanced, room_label, room_positions)
        
        return enhanced
    
    def _extract_ocr_rooms_for_cleanup(self, room_text_items, scale_x, scale_y):
        """ä¸ºæ¸…ç†ç®—æ³•æå–OCRéªŒè¯çš„æˆ¿é—´ä½ç½®ï¼ˆä½¿ç”¨åŸå§‹åæ ‡è½¬æ¢åˆ°512x512ï¼‰"""
        ocr_rooms = {}
        for item in room_text_items:
            text = item["text"].lower().strip()
            room_type = None
            
            if any(keyword in text for keyword in ["å¨æˆ¿", "kitchen", "å¨"]):
                room_type = 7
            elif any(keyword in text for keyword in ["å«ç”Ÿé—´", "bathroom", "å«", "æ´—æ‰‹é—´", "æµ´å®¤"]):
                room_type = 2
            elif any(keyword in text for keyword in ["å§å®¤", "bedroom", "ä¸»å§", "æ¬¡å§"]):
                room_type = 4
            elif any(keyword in text for keyword in ["å®¢å…", "living", "å®¢", "å¤§å…"]):
                room_type = 3
            
            if room_type:
                if room_type not in ocr_rooms:
                    ocr_rooms[room_type] = []
                
                # ä½¿ç”¨OCRçš„åŸå§‹åæ ‡å¹¶è½¬æ¢åˆ°512x512
                x, y, w, h = item["bbox"]  # è¿™æ˜¯åŸå§‹OCRåæ ‡ï¼ˆ2å€æ”¾å¤§å›¾åƒä¸Šçš„ï¼‰
                
                center_512_x = int((x + w//2) * scale_x)
                center_512_y = int((y + h//2) * scale_y)
                
                # ç¡®ä¿åæ ‡åœ¨512x512èŒƒå›´å†…
                center_512_x = max(0, min(center_512_x, 511))
                center_512_y = max(0, min(center_512_y, 511))
                
                ocr_rooms[room_type].append((center_512_x, center_512_y, item["confidence"]))
                print(f"   ğŸ¯ [ç¬¬3å±‚-èåˆå†³ç­–å™¨] {text}({room_type}) OCRä½ç½®è½¬æ¢: åŸå§‹({x+w//2}, {y+h//2}) -> 512x512({center_512_x}, {center_512_y})")
        
        return ocr_rooms
    
    def _extract_ocr_rooms(self, room_text_items):
        """æå–OCRéªŒè¯çš„æˆ¿é—´ä½ç½®"""
        ocr_rooms = {}
        for item in room_text_items:
            text = item["text"].lower().strip()
            room_type = None
            
            if any(keyword in text for keyword in ["å¨æˆ¿", "kitchen", "å¨"]):
                room_type = 7
            elif any(keyword in text for keyword in ["å«ç”Ÿé—´", "bathroom", "å«", "æ´—æ‰‹é—´", "æµ´å®¤"]):
                room_type = 2
            # å¯ä»¥ç»§ç»­æ·»åŠ å…¶ä»–æˆ¿é—´ç±»å‹...
            
            if room_type:
                if room_type not in ocr_rooms:
                    ocr_rooms[room_type] = []
                
                # æ³¨æ„ï¼šè¿™é‡Œçš„item["bbox"]å·²ç»æ˜¯è½¬æ¢åçš„512x512åæ ‡ç³»çš„åæ ‡
                x, y, w, h = item["bbox"]
                center_x = int(x + w//2)
                center_y = int(y + h//2)
                ocr_rooms[room_type].append((center_x, center_y, item["confidence"]))
        
        return ocr_rooms
    
    def _clean_room_type(self, enhanced, room_label, room_positions):
        """æ¸…ç†ç‰¹å®šæˆ¿é—´ç±»å‹çš„è¯¯è¯†åˆ«"""
        room_names = {2: "å«ç”Ÿé—´", 3: "å®¢å…", 4: "å§å®¤", 7: "å¨æˆ¿"}
        room_name = room_names.get(room_label, "æˆ¿é—´")
        print(f"ğŸ§¹ [ç¬¬3å±‚-èåˆå†³ç­–å™¨] æ¸…ç†{room_name}è¯¯è¯†åˆ«ï¼Œä¿ç•™{len(room_positions)}ä¸ªOCRéªŒè¯ä½ç½®")
        
        mask = (enhanced == room_label).astype(np.uint8)
        num_labels, labels_im, stats, centroids = cv2.connectedComponentsWithStats(mask, connectivity=4)
        cleaned_mask = np.zeros_like(mask)
        
        for comp_id in range(1, num_labels):
            comp_centroid = centroids[comp_id]
            comp_center_x, comp_center_y = int(comp_centroid[0]), int(comp_centroid[1])
            comp_area = stats[comp_id, cv2.CC_STAT_AREA]
            
            # è®¡ç®—åˆ°æœ€è¿‘OCRä½ç½®çš„è·ç¦»
            min_distance = float('inf')
            closest_confidence = 0
            for ocr_x, ocr_y, confidence in room_positions:
                distance = np.sqrt((comp_center_x - ocr_x)**2 + (comp_center_y - ocr_y)**2)
                if distance < min_distance:
                    min_distance = distance
                    closest_confidence = confidence
            
            # æ ¹æ®æˆ¿é—´ç±»å‹è®¾ç½®åŠ¨æ€é˜ˆå€¼
            if room_label == 3:  # å®¢å…
                distance_threshold = 150  # å®¢å…å…è®¸æ›´å¤§çš„è·ç¦»å®¹é”™
                max_area_threshold = 25000  # å®¢å…é¢ç§¯ä¸Šé™æ›´é«˜
            elif room_label == 7:  # å¨æˆ¿
                distance_threshold = 120 if len(room_positions) > 1 else 100
                max_area_threshold = 15000
            else:  # å«ç”Ÿé—´ã€å§å®¤ç­‰
                distance_threshold = 100 if len(room_positions) > 1 else 80
                max_area_threshold = 10000
            
            if min_distance < distance_threshold and comp_area < max_area_threshold:
                cleaned_mask[labels_im == comp_id] = 1
                print(f"   âœ… [ç¬¬3å±‚-èåˆå†³ç­–å™¨] ä¿ç•™{room_name}åŒºåŸŸï¼šè·OCR:{min_distance:.1f}px, é¢ç§¯:{comp_area}")
            else:
                print(f"   âŒ [ç¬¬3å±‚-èåˆå†³ç­–å™¨] ç§»é™¤{room_name}åŒºåŸŸï¼šè·OCR:{min_distance:.1f}px, é¢ç§¯:{comp_area}")
        
        enhanced[mask == 1] = 0
        enhanced[cleaned_mask == 1] = room_label
        
        return enhanced


class ReasonablenessValidator:
    """ç¬¬å››å±‚ï¼šåˆç†æ€§éªŒè¯å™¨"""
    
    def __init__(self):
        self.spatial_rules = SpatialRuleEngine()
        self.size_constraints = SizeConstraintEngine()
        self.boundary_detector = BuildingBoundaryDetector()
    
    def validate_and_correct(self, fused_results, ocr_results, original_size):
        """éªŒè¯å¹¶ä¿®æ­£ä¸åˆç†çš„è¯†åˆ«ç»“æœ"""
        print("ğŸ” [ç¬¬4å±‚-åˆç†æ€§éªŒè¯å™¨] å¼€å§‹åˆç†æ€§éªŒè¯...")
        
        # 1. ç©ºé—´åˆç†æ€§æ£€æŸ¥
        validated_results = self.spatial_rules.validate_spatial_logic(fused_results, ocr_results)
        
        # 2. å°ºå¯¸çº¦æŸéªŒè¯
        validated_results = self.size_constraints.validate_size_constraints(validated_results, original_size)
        
        # 3. è¾¹ç•ŒèŒƒå›´æ£€æŸ¥
        validated_results = self.boundary_detector.validate_building_boundary(validated_results, original_size)
        
        print("âœ… [ç¬¬4å±‚-åˆç†æ€§éªŒè¯å™¨] åˆç†æ€§éªŒè¯å®Œæˆ")
        return validated_results


class SpatialRuleEngine:
    """ç©ºé—´é€»è¾‘è§„åˆ™å¼•æ“"""
    
    def validate_spatial_logic(self, results, ocr_results):
        """éªŒè¯ç©ºé—´é€»è¾‘åˆç†æ€§"""
        print("ğŸ§  [ç©ºé—´è§„åˆ™å¼•æ“] éªŒè¯ç©ºé—´é€»è¾‘...")
        
        # è§„åˆ™1: æ£€æŸ¥å§å®¤å†…çš„é‡å¤æˆ¿é—´æ ‡è®°
        results = self._check_nested_rooms(results, ocr_results)
        
        # è§„åˆ™2: æ£€æŸ¥å¨æˆ¿ä½ç½®åˆç†æ€§ï¼ˆä¸åº”åœ¨å®¢å…ä¸­å¤®ï¼‰
        results = self._check_kitchen_position(results, ocr_results)
        
        return results
    
    def _check_nested_rooms(self, results, ocr_results):
        """æ£€æŸ¥å¹¶æ¸…ç†åµŒå¥—æˆ¿é—´ï¼ˆå¦‚å§å®¤å†…çš„é¢å¤–å§å®¤ï¼‰"""
        print("   ğŸ  [ç©ºé—´è§„åˆ™å¼•æ“] æ£€æŸ¥åµŒå¥—æˆ¿é—´...")
        
        # è·å–OCRæ ‡æ³¨çš„æˆ¿é—´åŒºåŸŸ
        ocr_room_regions = {}
        for item in ocr_results:
            text = item["text"].lower().strip()
            if any(keyword in text for keyword in ["å§å®¤", "bedroom"]):
                x, y, w, h = item["bbox"]
                
                # OCR bboxæ˜¯åœ¨2å€æ”¾å¤§å›¾åƒä¸Šçš„ï¼Œéœ€è¦è½¬æ¢åˆ°512x512åæ ‡ç³»
                # OCRå›¾åƒå°ºå¯¸å¯ä»¥ä»itemä¸­è·å–ï¼Œæˆ–è€…é€šè¿‡åŸå§‹å›¾åƒå°ºå¯¸è®¡ç®—
                ocr_to_512_scale_x = 512.0 / (item.get('ocr_width', 1158))  # é»˜è®¤å€¼åŸºäºdemo1.jpg
                ocr_to_512_scale_y = 512.0 / (item.get('ocr_height', 866))
                
                # è½¬æ¢åæ ‡åˆ°512x512
                x_512 = int(x * ocr_to_512_scale_x)
                y_512 = int(y * ocr_to_512_scale_y)
                w_512 = int(w * ocr_to_512_scale_x)
                h_512 = int(h * ocr_to_512_scale_y)
                
                # æ‰©å¤§OCRåŒºåŸŸèŒƒå›´ç”¨äºæ£€æµ‹ï¼ˆæ‰©å¤§åˆ°2å€ï¼‰
                expanded_region = {
                    'x1': max(0, x_512 - w_512),
                    'y1': max(0, y_512 - h_512), 
                    'x2': min(512, x_512 + w_512 + w_512),
                    'y2': min(512, y_512 + h_512 + h_512),
                    'text': text,
                    'center_x': x_512 + w_512//2,
                    'center_y': y_512 + h_512//2
                }
                ocr_room_regions[text] = expanded_region
                print(f"   ğŸ“ [ç©ºé—´è§„åˆ™å¼•æ“] OCRæˆ¿é—´ '{text}': ä¸­å¿ƒ({expanded_region['center_x']}, {expanded_region['center_y']}), åŒºåŸŸ({expanded_region['x1']}, {expanded_region['y1']}) -> ({expanded_region['x2']}, {expanded_region['y2']})")
        
        # æ£€æŸ¥æ¯ä¸ªOCRå§å®¤åŒºåŸŸå†…æ˜¯å¦æœ‰AIåˆ†å‰²çš„å…¶ä»–å§å®¤
        bedroom_mask = (results == 4).astype(np.uint8)
        num_labels, labels_im, stats, centroids = cv2.connectedComponentsWithStats(bedroom_mask, connectivity=4)
        
        print(f"   ğŸ” [ç©ºé—´è§„åˆ™å¼•æ“] å‘ç° {num_labels-1} ä¸ªAIåˆ†å‰²çš„å§å®¤è¿é€šåŸŸ")
        
        for room_name, region in ocr_room_regions.items():
            print(f"   ğŸ“ [ç©ºé—´è§„åˆ™å¼•æ“] æ£€æŸ¥ '{room_name}' åŒºåŸŸå†…çš„åµŒå¥—æˆ¿é—´...")
            
            # åœ¨OCRåŒºåŸŸå†…æŸ¥æ‰¾AIåˆ†å‰²çš„å§å®¤å—
            nested_components = []
            for comp_id in range(1, num_labels):
                centroid_x, centroid_y = centroids[comp_id]
                area = stats[comp_id, cv2.CC_STAT_AREA]
                
                print(f"   ğŸ” [ç©ºé—´è§„åˆ™å¼•æ“] AIå§å®¤ç»„ä»¶{comp_id}: ä¸­å¿ƒ({centroid_x:.1f}, {centroid_y:.1f}), é¢ç§¯:{area}")
                
                # æ£€æŸ¥è´¨å¿ƒæ˜¯å¦åœ¨OCRåŒºåŸŸå†…
                if (region['x1'] <= centroid_x <= region['x2'] and 
                    region['y1'] <= centroid_y <= region['y2']):
                    nested_components.append(comp_id)
                    print(f"   âœ… [ç©ºé—´è§„åˆ™å¼•æ“] ç»„ä»¶{comp_id}åœ¨ '{room_name}' åŒºåŸŸå†…")
                else:
                    print(f"   âŒ [ç©ºé—´è§„åˆ™å¼•æ“] ç»„ä»¶{comp_id}åœ¨ '{room_name}' åŒºåŸŸå¤–")
            
            # å¦‚æœæ‰¾åˆ°å¤šä¸ªç»„ä»¶ï¼Œä¿ç•™æœ€å¤§çš„ï¼Œç§»é™¤è¾ƒå°çš„
            if len(nested_components) > 1:
                print(f"   âš ï¸ [ç©ºé—´è§„åˆ™å¼•æ“] å‘ç° '{room_name}' å†…æœ‰ {len(nested_components)} ä¸ªå§å®¤ç»„ä»¶ï¼Œéœ€è¦æ¸…ç†åµŒå¥—")
                
                # æ‰¾åˆ°æœ€å¤§çš„ç»„ä»¶
                largest_comp = max(nested_components, key=lambda comp_id: stats[comp_id, cv2.CC_STAT_AREA])
                largest_area = stats[largest_comp, cv2.CC_STAT_AREA]
                
                print(f"   ğŸ“ [ç©ºé—´è§„åˆ™å¼•æ“] ä¿ç•™æœ€å¤§ç»„ä»¶{largest_comp} (é¢ç§¯:{largest_area})")
                
                # ç§»é™¤å…¶ä»–è¾ƒå°çš„ç»„ä»¶
                for comp_id in nested_components:
                    if comp_id != largest_comp:
                        area = stats[comp_id, cv2.CC_STAT_AREA]
                        results[labels_im == comp_id] = 0  # æ¸…é™¤è¯¥ç»„ä»¶
                        print(f"   ğŸ—‘ï¸ [ç©ºé—´è§„åˆ™å¼•æ“] ç§»é™¤ '{room_name}' å†…åµŒå¥—å§å®¤ç»„ä»¶{comp_id} (é¢ç§¯:{area})")
            elif len(nested_components) == 1:
                print(f"   âœ… [ç©ºé—´è§„åˆ™å¼•æ“] '{room_name}' å†…åªæœ‰1ä¸ªå§å®¤ç»„ä»¶ï¼Œæ— éœ€æ¸…ç†")
            else:
                print(f"   âš ï¸ [ç©ºé—´è§„åˆ™å¼•æ“] '{room_name}' å†…æ²¡æœ‰AIåˆ†å‰²çš„å§å®¤ç»„ä»¶")
        
        return results
    
    def _check_kitchen_position(self, results, ocr_results):
        """æ£€æŸ¥å¨æˆ¿ä½ç½®åˆç†æ€§"""
        print("   ğŸ³ [ç©ºé—´è§„åˆ™å¼•æ“] æ£€æŸ¥å¨æˆ¿ä½ç½®åˆç†æ€§...")
        
        # è·å–å®¢å…å’Œå¨æˆ¿çš„OCRä½ç½®
        living_room_centers = []
        kitchen_centers = []
        
        for item in ocr_results:
            text = item["text"].lower().strip()
            x, y, w, h = item["bbox"]
            center_x, center_y = x + w//2, y + h//2
            
            if any(keyword in text for keyword in ["å®¢å…", "living"]):
                living_room_centers.append((center_x, center_y))
            elif any(keyword in text for keyword in ["å¨æˆ¿", "kitchen"]):
                kitchen_centers.append((center_x, center_y))
        
        # å¦‚æœæœ‰å®¢å…ï¼Œæ£€æŸ¥å¨æˆ¿æ˜¯å¦åœ¨å®¢å…ä¸­å¤®
        if living_room_centers and kitchen_centers:
            for lr_x, lr_y in living_room_centers:
                for kit_x, kit_y in kitchen_centers:
                    distance = np.sqrt((lr_x - kit_x)**2 + (lr_y - kit_y)**2)
                    if distance < 50:  # è·ç¦»å¤ªè¿‘ï¼Œå¯èƒ½æ˜¯é”™è¯¯è¯†åˆ«
                        print(f"   âš ï¸ [ç©ºé—´è§„åˆ™å¼•æ“] å¨æˆ¿è·å®¢å…è¿‡è¿‘ (è·ç¦»:{distance:.1f}px)ï¼Œéœ€è¦éªŒè¯")
        
        return results


class SizeConstraintEngine:
    """å°ºå¯¸çº¦æŸå¼•æ“"""
    
    def validate_size_constraints(self, results, original_size):
        """éªŒè¯å°ºå¯¸çº¦æŸ"""
        print("ğŸ“ [å°ºå¯¸çº¦æŸå¼•æ“] éªŒè¯æˆ¿é—´å°ºå¯¸...")
        
        # è®¡ç®—åƒç´ åˆ°å®é™…å°ºå¯¸çš„è½¬æ¢æ¯”ä¾‹ï¼ˆåŸºäºå¸¸è§æˆ·å‹å›¾ï¼‰
        # å‡è®¾å›¾åƒå®½åº¦å¯¹åº”å®é™…10-15ç±³
        pixel_to_meter = 12.0 / original_size[0]  # ç²—ç•¥ä¼°ç®—
        
        # æ£€æŸ¥å„æˆ¿é—´ç±»å‹çš„å°ºå¯¸åˆç†æ€§
        room_names = {2: "å«ç”Ÿé—´", 3: "å®¢å…", 4: "å§å®¤", 6: "é˜³å°", 7: "å¨æˆ¿", 8: "ä¹¦æˆ¿"}
        
        for room_label, room_name in room_names.items():
            if room_label in [2, 7]:  # é‡ç‚¹æ£€æŸ¥å«ç”Ÿé—´å’Œå¨æˆ¿
                results = self._check_room_size(results, room_label, room_name, pixel_to_meter)
        
        return results
    
    def _check_room_size(self, results, room_label, room_name, pixel_to_meter):
        """æ£€æŸ¥ç‰¹å®šæˆ¿é—´ç±»å‹çš„å°ºå¯¸"""
        print(f"   ğŸ“ [å°ºå¯¸çº¦æŸå¼•æ“] æ£€æŸ¥{room_name}å°ºå¯¸...")
        
        mask = (results == room_label).astype(np.uint8)
        num_labels, labels_im, stats, centroids = cv2.connectedComponentsWithStats(mask, connectivity=4)
        
        # è®¾å®šåˆç†çš„é¢ç§¯èŒƒå›´ï¼ˆå¹³æ–¹ç±³ï¼‰
        if room_label == 2:  # å«ç”Ÿé—´
            min_area_m2, max_area_m2 = 2, 15  # 2-15å¹³æ–¹ç±³
        elif room_label == 7:  # å¨æˆ¿
            min_area_m2, max_area_m2 = 3, 20  # 3-20å¹³æ–¹ç±³
        else:
            return results
        
        for comp_id in range(1, num_labels):
            area_pixels = stats[comp_id, cv2.CC_STAT_AREA]
            area_m2 = area_pixels * (pixel_to_meter ** 2)
            
            if area_m2 > max_area_m2:
                print(f"   âš ï¸ [å°ºå¯¸çº¦æŸå¼•æ“] {room_name}è¿‡å¤§: {area_m2:.1f}mÂ² (>{max_area_m2}mÂ²), éœ€è¦ä¿®æ­£")
                # ç§»é™¤è¿‡å¤§çš„åŒºåŸŸ
                results[labels_im == comp_id] = 0
                print(f"   ğŸ—‘ï¸ [å°ºå¯¸çº¦æŸå¼•æ“] ç§»é™¤è¿‡å¤§{room_name}åŒºåŸŸ")
            elif area_m2 < min_area_m2:
                print(f"   âš ï¸ [å°ºå¯¸çº¦æŸå¼•æ“] {room_name}è¿‡å°: {area_m2:.1f}mÂ² (<{min_area_m2}mÂ²), å¯èƒ½æ˜¯è¯¯è¯†åˆ«")
        
        return results


class BuildingBoundaryDetector:
    """å»ºç­‘è¾¹ç•Œæ£€æµ‹å™¨"""
    
    def validate_building_boundary(self, results, original_size):
        """éªŒè¯å»ºç­‘è¾¹ç•Œ"""
        print("ğŸ—ï¸ [è¾¹ç•Œæ£€æµ‹å™¨] éªŒè¯å»ºç­‘è¾¹ç•Œ...")
        
        # æ£€æµ‹å›¾åƒè¾¹ç¼˜çš„æˆ¿é—´æ ‡è®°ï¼ˆå¯èƒ½æ˜¯å¤–éƒ¨æ ‡å°ºè¯¯è¯†åˆ«ï¼‰
        results = self._remove_edge_misidentifications(results)
        
        return results
    
    def _remove_edge_misidentifications(self, results):
        """ç§»é™¤è¾¹ç¼˜ä½ç½®çš„è¯¯è¯†åˆ«"""
        print("   ğŸš« [è¾¹ç•Œæ£€æµ‹å™¨] æ£€æŸ¥è¾¹ç¼˜è¯¯è¯†åˆ«...")
        
        h, w = results.shape
        edge_threshold = 20  # è¾¹ç¼˜é˜ˆå€¼åƒç´ 
        
        # æ£€æŸ¥å››ä¸ªè¾¹ç¼˜åŒºåŸŸ
        edges = [
            (0, edge_threshold, 0, w),  # ä¸Šè¾¹ç¼˜
            (h-edge_threshold, h, 0, w),  # ä¸‹è¾¹ç¼˜  
            (0, h, 0, edge_threshold),  # å·¦è¾¹ç¼˜
            (0, h, w-edge_threshold, w)  # å³è¾¹ç¼˜
        ]
        
        for y1, y2, x1, x2 in edges:
            edge_region = results[y1:y2, x1:x2]
            unique_labels = np.unique(edge_region)
            
            # ç§»é™¤è¾¹ç¼˜åŒºåŸŸçš„æˆ¿é—´æ ‡è®°ï¼ˆé™¤äº†èƒŒæ™¯0å’Œå¢™ä½“1ï¼‰
            for label in unique_labels:
                if label > 1:  # æˆ¿é—´æ ‡ç­¾
                    room_pixels = np.sum(edge_region == label)
                    if room_pixels > 50:  # å¦‚æœè¾¹ç¼˜åŒºåŸŸæœ‰è¾ƒå¤šè¯¥æˆ¿é—´åƒç´ 
                        print(f"   ğŸ—‘ï¸ [è¾¹ç•Œæ£€æµ‹å™¨] ç§»é™¤è¾¹ç¼˜åŒºåŸŸæˆ¿é—´æ ‡è®° (æ ‡ç­¾:{label}, åƒç´ :{room_pixels})")
                        results[results == label] = 0
        
        return results


class FloorplanProcessor:
    """æˆ·å‹å›¾å¤„ç†å™¨ - å››å±‚æ™ºèƒ½å†³ç­–æ¶æ„ç»Ÿä¸€ç®¡ç†å™¨"""

    def __init__(self, model_path="pretrained"):
        """åˆå§‹åŒ–å››å±‚æ¶æ„å¤„ç†å™¨"""
        print("ğŸ  DeepFloorplan æˆ¿é—´æ£€æµ‹ - å››å±‚æ™ºèƒ½å†³ç­–æ¶æ„")
        print("=" * 60)
        
        # åˆå§‹åŒ–å››å±‚æ¶æ„ç»„ä»¶
        self.ai_engine = AISegmentationEngine(model_path)
        self.ocr_engine = OCRRecognitionEngine()
        self.fusion_engine = FusionDecisionEngine()
        self.validator = ReasonablenessValidator()
        
        # ç”¨äºç»Ÿè®¡çš„å˜é‡
        self.last_enhanced = None

    def load_model(self):
        """åŠ è½½AIåˆ†å‰²æ¨¡å‹"""
        self.ai_engine.load_model()

    def preprocess_image(self, image_path):
        """å›¾åƒé¢„å¤„ç†"""
        print(f"ğŸ“¸ å¤„ç†å›¾åƒ: {image_path}")

        # è¯»å–å›¾åƒ
        img = Image.open(image_path).convert("RGB")
        original_size = img.size

        print(f"ğŸ“ åŸå§‹å›¾åƒå°ºå¯¸: {original_size[0]} x {original_size[1]} (å®½xé«˜)")

        # è°ƒæ•´åˆ°æ¨¡å‹è¾“å…¥å°ºå¯¸ (512x512)
        img_resized = img.resize((512, 512), Image.LANCZOS)
        img_array = np.array(img_resized) / 255.0

        print(f"ğŸ”„ ç¥ç»ç½‘ç»œè¾“å…¥: 512 x 512 (å›ºå®šå°ºå¯¸)")

        return img_array, original_size, np.array(img)

    def process_with_four_layer_architecture(self, img_array, original_img, original_size):
        """ä½¿ç”¨å››å±‚æ¶æ„å¤„ç†å›¾åƒ"""
        print("\nğŸ—ï¸ å¼€å§‹å››å±‚æ™ºèƒ½å†³ç­–å¤„ç†æµç¨‹...")
        
        # ç¬¬ä¸€å±‚ï¼šAIè¯­ä¹‰åˆ†å‰²
        ai_prediction = self.ai_engine.segment_image(img_array)
        
        # ç¬¬äºŒå±‚ï¼šOCRæ–‡å­—è¯†åˆ«
        ocr_results, ocr_shape = self.ocr_engine.recognize_text(original_img)
        
        # ç¬¬ä¸‰å±‚ï¼šèåˆå†³ç­–
        fused_results = self.fusion_engine.fuse_results(ai_prediction, ocr_results, ocr_shape)
        
        # ç¬¬å››å±‚ï¼šåˆç†æ€§éªŒè¯
        validated_results = self.validator.validate_and_correct(fused_results, ocr_results, original_size)
        
        # ä¿å­˜ç»“æœç”¨äºç»Ÿè®¡
        self.last_enhanced = validated_results
        
        print("ğŸ‰ å››å±‚æ™ºèƒ½å†³ç­–å¤„ç†å®Œæˆï¼")
        return validated_results, ocr_results

    # ä¿ç•™åŸæœ‰æ¥å£ä»¥ä¿æŒå…¼å®¹æ€§
    def run_inference(self, img_array):
        """è¿è¡Œç¥ç»ç½‘ç»œæ¨ç†ï¼ˆå…¼å®¹æ¥å£ï¼‰"""
        return self.ai_engine.segment_image(img_array)

    def extract_ocr_info(self, original_img):
        """æå–OCRæ–‡å­—ä¿¡æ¯ï¼ˆå…¼å®¹æ¥å£ï¼‰"""
        return self.ocr_engine.recognize_text(original_img)

    def fuse_predictions(self, prediction, room_text_items, ocr_shape):
        """èåˆé¢„æµ‹ç»“æœï¼ˆå…¼å®¹æ¥å£ï¼‰"""
        return self.fusion_engine.fuse_results(prediction, room_text_items, ocr_shape)

    def detect_rooms(self, enhanced, room_text_items, original_size):
        """æ£€æµ‹å„ç±»æˆ¿é—´ï¼ˆå…¼å®¹æ¥å£ï¼‰"""
        # ç°åœ¨è¿™ä¸ªåŠŸèƒ½å·²ç»æ•´åˆåˆ°å››å±‚æ¶æ„ä¸­
        return enhanced
        
    def _clean_misidentified_regions(self, enhanced, room_text_items, original_size):
        """æ¸…ç†AIåˆ†å‰²ä¸­çš„è¯¯è¯†åˆ«åŒºåŸŸï¼Œåªä¿ç•™OCRéªŒè¯çš„æˆ¿é—´åŒºåŸŸ"""
        print("ğŸ§¹ æ¸…ç†AIåˆ†å‰²è¯¯è¯†åˆ«åŒºåŸŸ...")
        
        # è·å–OCRéªŒè¯çš„æˆ¿é—´ä½ç½®
        ocr_rooms = {}
        for item in room_text_items:
            text = item["text"].lower().strip()
            room_type = None
            
            if any(keyword in text for keyword in ["å¨æˆ¿", "kitchen", "å¨"]):
                room_type = 7  # å¨æˆ¿
            elif any(keyword in text for keyword in ["å«ç”Ÿé—´", "bathroom", "å«", "æ´—æ‰‹é—´", "æµ´å®¤", "æ·‹æµ´é—´", "shower", "æ·‹æµ´", "ç›¥æ´—å®¤"]):
                room_type = 2  # å«ç”Ÿé—´
            elif any(keyword in text for keyword in ["å®¢å…", "living", "å…", "èµ·å±…å®¤"]):
                room_type = 3  # å®¢å…
            elif any(keyword in text for keyword in ["å§å®¤", "bedroom", "ä¸»å§", "æ¬¡å§"]):
                room_type = 4  # å§å®¤
            elif any(keyword in text for keyword in ["é˜³å°", "balcony", "é˜³å…®", "é˜³åˆ", "é˜³å›Š"]):
                room_type = 6  # é˜³å°
            elif any(keyword in text for keyword in ["ä¹¦æˆ¿", "study", "ä¹¦", "åŠå…¬å®¤", "office"]):
                room_type = 8  # ä¹¦æˆ¿
                
            if room_type:
                if room_type not in ocr_rooms:
                    ocr_rooms[room_type] = []
                
                # è½¬æ¢OCRåæ ‡åˆ°512x512åæ ‡ç³»
                x, y, w, h = item["bbox"]
                # OCRæ˜¯åœ¨2å€æ”¾å¤§å›¾åƒä¸Šï¼Œéœ€è¦è½¬æ¢åˆ°512x512
                ocr_to_512_x = 512.0 / (original_size[0] * 2)
                ocr_to_512_y = 512.0 / (original_size[1] * 2) 
                
                center_512_x = int((x + w//2) * ocr_to_512_x)
                center_512_y = int((y + h//2) * ocr_to_512_y)
                ocr_rooms[room_type].append((center_512_x, center_512_y, item["confidence"]))
        
        # å¯¹äºæ¯ä¸ªæˆ¿é—´ç±»å‹ï¼Œåªä¿ç•™OCRéªŒè¯ä½ç½®é™„è¿‘çš„åˆ†å‰²åŒºåŸŸ
        for room_label, room_positions in ocr_rooms.items():
            if room_label in [2, 7]:  # å¤„ç†å«ç”Ÿé—´å’Œå¨æˆ¿çš„è¯¯è¯†åˆ«é—®é¢˜
                room_name = "å«ç”Ÿé—´" if room_label == 2 else "å¨æˆ¿"
                print(f"ğŸ§¹ æ¸…ç†{room_name}è¯¯è¯†åˆ«åŒºåŸŸï¼Œä¿ç•™{len(room_positions)}ä¸ªOCRéªŒè¯ä½ç½®")
                
                # è·å–æ‰€æœ‰æŒ‡å®šæ ‡ç­¾çš„åƒç´ 
                mask = (enhanced == room_label).astype(np.uint8)
                
                # ä½¿ç”¨è¿é€šåŸŸåˆ†ææ‰¾åˆ°æ‰€æœ‰åŒºåŸŸ
                num_labels, labels_im, stats, centroids = cv2.connectedComponentsWithStats(mask, connectivity=4)
                
                # åˆ›å»ºæ–°çš„æ¸…ç†åçš„mask
                cleaned_mask = np.zeros_like(mask)
                
                for comp_id in range(1, num_labels):  # è·³è¿‡èƒŒæ™¯(0)
                    comp_centroid = centroids[comp_id]
                    comp_center_x, comp_center_y = int(comp_centroid[0]), int(comp_centroid[1])
                    comp_area = stats[comp_id, cv2.CC_STAT_AREA]
                    
                    # æ£€æŸ¥è¿™ä¸ªè¿é€šåŸŸæ˜¯å¦æ¥è¿‘ä»»ä½•OCRéªŒè¯çš„ä½ç½®
                    is_valid = False
                    min_distance = float('inf')
                    closest_confidence = 0
                    
                    for ocr_x, ocr_y, confidence in room_positions:
                        distance = np.sqrt((comp_center_x - ocr_x)**2 + (comp_center_y - ocr_y)**2)
                        if distance < min_distance:
                            min_distance = distance
                            closest_confidence = confidence
                    
                    # è®¾ç½®è·ç¦»é˜ˆå€¼ï¼šæ ¹æ®OCRéªŒè¯ä½ç½®æ•°é‡åŠ¨æ€è°ƒæ•´
                    if len(room_positions) > 1:
                        # å¤šä¸ªOCRä½ç½®æ—¶ï¼Œä½¿ç”¨æ›´å®½æ¾çš„é˜ˆå€¼
                        distance_threshold = 120 if room_label == 7 else 100
                    else:
                        # å•ä¸ªOCRä½ç½®æ—¶ï¼Œä½¿ç”¨æ ‡å‡†é˜ˆå€¼  
                        distance_threshold = 100 if room_label == 7 else 80
                    
                    # è®¾ç½®é¢ç§¯é˜ˆå€¼ï¼šé˜²æ­¢å·¨å¤§çš„è¯¯è¯†åˆ«åŒºåŸŸ
                    max_area_threshold = 15000 if room_label == 7 else 10000  # é€‚å½“æ”¾å®½é¢ç§¯é™åˆ¶
                    
                    # å¦‚æœè·ç¦»åœ¨åˆç†èŒƒå›´å†…ä¸”é¢ç§¯ä¸è¶…æ ‡ï¼Œè®¤ä¸ºæ˜¯æœ‰æ•ˆçš„
                    if min_distance < distance_threshold and comp_area < max_area_threshold:  
                        is_valid = True
                        print(f"   âœ… ä¿ç•™{room_name}åŒºåŸŸï¼šä¸­å¿ƒ({comp_center_x}, {comp_center_y}), è·OCR: {min_distance:.1f}åƒç´ , é¢ç§¯: {comp_area}, ç½®ä¿¡åº¦: {closest_confidence:.3f}")
                    else:
                        reasons = []
                        if min_distance >= distance_threshold:
                            reasons.append("è·ç¦»è¿‡è¿œ")
                        if comp_area >= max_area_threshold:
                            reasons.append("é¢ç§¯è¿‡å¤§")
                        print(f"   âŒ ç§»é™¤è¯¯è¯†åˆ«åŒºåŸŸï¼šä¸­å¿ƒ({comp_center_x}, {comp_center_y}), è·OCR: {min_distance:.1f}åƒç´ , é¢ç§¯: {comp_area} ({', '.join(reasons)})")
                    
                    if is_valid:
                        # ä¿ç•™è¿™ä¸ªè¿é€šåŸŸ
                        component_mask = (labels_im == comp_id)
                        cleaned_mask[component_mask] = 1
                
                # ç”¨æ¸…ç†åçš„maskæ›´æ–°enhanced
                enhanced[mask == 1] = 0  # å…ˆæ¸…é™¤æ‰€æœ‰åŸæ¥çš„æ ‡è®°
                enhanced[cleaned_mask == 1] = room_label  # ç„¶åè®¾ç½®éªŒè¯è¿‡çš„åŒºåŸŸ
                
                removed_pixels = np.sum(mask) - np.sum(cleaned_mask)
                print(f"   ğŸ“Š æ¸…ç†ç»“æœï¼šç§»é™¤äº† {removed_pixels} ä¸ªè¯¯è¯†åˆ«åƒç´ ")
        
        return enhanced

    def generate_results(
        self, enhanced, original_img, original_size, output_path, room_text_items
    ):
        """ç”Ÿæˆæœ€ç»ˆç»“æœï¼ŒåŒ…å«åæ ‡è½´å’Œæˆ¿é—´åæ ‡ä¿¡æ¯"""
        print("ğŸ¨ ç”Ÿæˆç»“æœå›¾åƒ...")

        # è°ƒæ•´å›åŸå§‹å°ºå¯¸
        enhanced_resized = cv2.resize(
            enhanced, original_size, interpolation=cv2.INTER_NEAREST
        )

        # ç”Ÿæˆå½©è‰²åˆ†å‰²å›¾ - ä½¿ç”¨é¢œè‰²æ˜ å°„å­—å…¸
        h, w = enhanced_resized.shape
        colored_result = np.zeros((h, w, 3), dtype=np.uint8)

        # åº”ç”¨é¢œè‰²æ˜ å°„
        for label_value, color in floorplan_fuse_map_figure.items():
            mask = enhanced_resized == label_value
            colored_result[mask] = color

        # å åŠ åˆ°åŸå›¾
        alpha = 0.5
        final_result = cv2.addWeighted(
            original_img, 1 - alpha, colored_result, alpha, 0
        )

        # ä½¿ç”¨matplotlibåˆ›å»ºå¸¦åæ ‡è½´çš„å›¾åƒ
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))

        # å·¦å›¾ï¼šåŸå›¾ + åˆ†å‰²ç»“æœ
        ax1.imshow(final_result)
        ax1.set_title("æˆ¿é—´æ£€æµ‹ç»“æœ", fontsize=14, fontweight="bold")
        ax1.grid(True, alpha=0.3)
        ax1.set_xlabel("Xåæ ‡ (åƒç´ )", fontsize=12)
        ax1.set_ylabel("Yåæ ‡ (åƒç´ )", fontsize=12)

        # æ·»åŠ æˆ¿é—´æ ‡æ³¨å’Œåæ ‡
        room_info = self._extract_room_coordinates(
            enhanced_resized, original_size, room_text_items
        )
        
        # ä¿å­˜æˆ¿é—´ä¿¡æ¯ä¾›æ‘˜è¦ä½¿ç”¨
        self.last_room_info = room_info
        
        for room_type, room_list in room_info.items():
            for i, coords in enumerate(room_list):
                if coords["pixels"] > 0:  # åªæ˜¾ç¤ºæœ‰æ•ˆæ£€æµ‹çš„æˆ¿é—´
                    center_x, center_y = coords["center"]
                    bbox = coords["bbox"]

                    # åœ¨å›¾ä¸Šæ ‡æ³¨æˆ¿é—´ä¸­å¿ƒç‚¹
                    ax1.plot(
                        center_x,
                        center_y,
                        "o",
                        markersize=10,
                        color="white",
                        markeredgecolor="black",
                        markeredgewidth=2,
                    )

                    # æˆ¿é—´æ ‡æ³¨ï¼ˆå¦‚æœæœ‰å¤šä¸ªåŒç±»å‹æˆ¿é—´ï¼ŒåŠ ä¸Šç¼–å·ï¼‰
                    if len(room_list) > 1:
                        label_text = f"{room_type}{i+1}\n({center_x},{center_y})"
                    else:
                        label_text = f"{room_type}\n({center_x},{center_y})"

                    ax1.annotate(
                        label_text,
                        xy=(center_x, center_y),
                        xytext=(10, 10),
                        textcoords="offset points",
                        fontsize=10,
                        fontweight="bold",
                        bbox=dict(
                            boxstyle="round,pad=0.3", facecolor="white", alpha=0.8
                        ),
                        arrowprops=dict(arrowstyle="->", connectionstyle="arc3,rad=0"),
                    )

                    # ç»˜åˆ¶è¾¹ç•Œæ¡†
                    x1, y1, x2, y2 = bbox
                    rect = plt.Rectangle(
                        (x1, y1),
                        x2 - x1,
                        y2 - y1,
                        fill=False,
                        edgecolor="red",
                        linewidth=2,
                        linestyle="--",
                    )
                    ax1.add_patch(rect)

        # å³å›¾ï¼šçº¯åˆ†å‰²ç»“æœ
        ax2.imshow(colored_result)
        ax2.set_title("åˆ†å‰²æ ‡ç­¾å›¾", fontsize=14, fontweight="bold")
        ax2.grid(True, alpha=0.3)
        ax2.set_xlabel("Xåæ ‡ (åƒç´ )", fontsize=12)
        ax2.set_ylabel("Yåæ ‡ (åƒç´ )", fontsize=12)

        for room_type, room_list in room_info.items():
            for i, coords in enumerate(room_list):
                if coords["pixels"] > 0:
                    center_x, center_y = coords["center"]
                    bbox = coords["bbox"]

                    ax2.plot(
                        center_x,
                        center_y,
                        "o",
                        markersize=10,
                        color="white",
                        markeredgecolor="black",
                        markeredgewidth=2,
                    )

                    if len(room_list) > 1:
                        label_text = f"{room_type}{i+1}\n({center_x},{center_y})"
                    else:
                        label_text = f"{room_type}\n({center_x},{center_y})"

                    ax2.annotate(
                        label_text,
                        xy=(center_x, center_y),
                        xytext=(10, 10),
                        textcoords="offset points",
                        fontsize=10,
                        fontweight="bold",
                        bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8),
                        arrowprops=dict(arrowstyle="->", connectionstyle="arc3,rad=0"),
                    )

                    x1, y1, x2, y2 = bbox
                    rect = plt.Rectangle(
                        (x1, y1),
                        x2 - x1,
                        y2 - y1,
                        fill=False,
                        edgecolor="red",
                        linewidth=2,
                        linestyle="--",
                    )
                    ax2.add_patch(rect)

        # æ·»åŠ å›¾ä¾‹ - é¢œè‰²ä¸å®é™…æ¸²æŸ“ä¸€è‡´
        legend_elements = []
        # ä½¿ç”¨ä¸floorplan_fuse_map_figureå®Œå…¨ä¸€è‡´çš„é¢œè‰²å®šä¹‰
        room_colors = {
            7: ("å¨æˆ¿", np.array([0, 255, 0]) / 255.0),      # çº¯ç»¿è‰² [0,255,0]
            2: ("å«ç”Ÿé—´", np.array([192, 255, 255]) / 255.0),  # æµ…é’è‰² [192,255,255]
            3: ("å®¢å…", np.array([224, 255, 192]) / 255.0),   # æµ…ç»¿è‰² [224,255,192]
            4: ("å§å®¤", np.array([255, 224, 128]) / 255.0),   # æµ…é»„è‰² [255,224,128]
            6: ("é˜³å°", np.array([255, 224, 224]) / 255.0),   # æµ…ç²‰è‰² [255,224,224]
            8: ("ä¹¦æˆ¿", np.array([224, 224, 128]) / 255.0),   # æµ…é»„ç»¿ [224,224,128]
            9: ("é—¨çª—", np.array([255, 60, 128]) / 255.0),    # ç²‰çº¢è‰² [255,60,128]
            10: ("å¢™ä½“", np.array([0, 0, 0]) / 255.0),        # é»‘è‰² [0,0,0]
        }

        for label, (name, color) in room_colors.items():
            # æ£€æŸ¥è¯¥æˆ¿é—´ç±»å‹æ˜¯å¦åœ¨åˆ†å‰²å›¾ä¸­å­˜åœ¨ï¼Œæˆ–è€…åœ¨room_infoä¸­æœ‰æ£€æµ‹è®°å½•
            room_detected_in_image = np.any(enhanced_resized == label)
            room_detected_by_ocr = False
            
            # æ£€æŸ¥room_infoä¸­æ˜¯å¦æœ‰å¯¹åº”æˆ¿é—´ç±»å‹çš„æ£€æµ‹è®°å½•
            room_name_map = {7: "å¨æˆ¿", 2: "å«ç”Ÿé—´", 3: "å®¢å…", 4: "å§å®¤", 6: "é˜³å°", 8: "ä¹¦æˆ¿"}
            if label in room_name_map and room_name_map[label] in room_info:
                room_detected_by_ocr = len(room_info[room_name_map[label]]) > 0
            
            if room_detected_in_image or room_detected_by_ocr:
                legend_elements.append(
                    plt.Line2D(
                        [0],
                        [0],
                        marker="s",
                        color="w",
                        markerfacecolor=color,
                        markersize=10,
                        label=f"{name} (æ ‡ç­¾{label})",
                    )
                )

        ax2.legend(handles=legend_elements, loc="upper right", bbox_to_anchor=(1.3, 1))

        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()

        # ä¿å­˜ç»“æœ
        output_dir = Path("output")
        output_dir.mkdir(exist_ok=True)

        base_name = Path(output_path).stem

        # ä¿å­˜å¸¦åæ ‡è½´çš„å›¾åƒ
        coordinate_result_path = output_dir / f"{base_name}_coordinate_result.png"
        plt.savefig(coordinate_result_path, dpi=300, bbox_inches="tight")
        print(f"ğŸ“Š å¸¦åæ ‡è½´ç»“æœå·²ä¿å­˜: {coordinate_result_path}")

        # ä¿å­˜åŸå§‹ç»“æœï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
        result_path = output_dir / f"{base_name}_result.png"
        cv2.imwrite(str(result_path), cv2.cvtColor(final_result, cv2.COLOR_RGB2BGR))
        print(f"ğŸ“¸ æ ‡å‡†ç»“æœå·²ä¿å­˜: {result_path}")

        # è¾“å‡ºæˆ¿é—´åæ ‡ä¿¡æ¯
        self._print_room_coordinates(room_info, original_size)

        plt.close()

        return final_result

    def _extract_room_coordinates(
        self, enhanced_resized, original_size, room_text_items
    ):
        """æå–å„æˆ¿é—´çš„åæ ‡ä¿¡æ¯ï¼Œä¼˜å…ˆä½¿ç”¨OCRæ–‡å­—ä½ç½®ï¼Œæ”¯æŒå¤šä¸ªåŒç±»å‹æˆ¿é—´"""
        room_info = {}

        # è®¡ç®—åæ ‡è½¬æ¢æ¯”ä¾‹
        original_width, original_height = original_size

        # å®šä¹‰æˆ¿é—´ç±»å‹åŠå…¶åœ¨åˆ†å‰²æ©ç ä¸­çš„æ ‡ç­¾
        room_types = ["å¨æˆ¿", "å«ç”Ÿé—´", "å®¢å…", "å§å®¤", "é˜³å°", "ä¹¦æˆ¿"]
        room_label_mapping = {
            "å¨æˆ¿": 7,
            "å«ç”Ÿé—´": 2,
            "å®¢å…": 3,
            "å§å®¤": 4,
            "é˜³å°": 6,
            "ä¹¦æˆ¿": 8,
        }

        # åˆå§‹åŒ–æ‰€æœ‰æˆ¿é—´ä¿¡æ¯ä¸ºç©ºåˆ—è¡¨ï¼Œæ”¯æŒå¤šä¸ªåŒç±»å‹æˆ¿é—´
        for room_type in room_types:
            room_info[room_type] = []

        # ä¼˜å…ˆä½¿ç”¨OCRæ–‡å­—ä½ç½®ç¡®å®šæˆ¿é—´åæ ‡
        for item in room_text_items:
            text = item["text"].lower().strip()

            # åŒ¹é…æˆ¿é—´ç±»å‹
            room_type = None
            if any(keyword in text for keyword in ["å¨æˆ¿", "kitchen", "å¨"]):
                room_type = "å¨æˆ¿"
            elif any(
                keyword in text
                for keyword in [
                    "å«ç”Ÿé—´",
                    "bathroom",
                    "å«",
                    "æ´—æ‰‹é—´",
                    "æµ´å®¤",
                    "æ·‹æµ´é—´",
                    "shower",
                    "æ·‹æµ´",
                    "ç›¥æ´—å®¤",
                ]
            ):
                room_type = "å«ç”Ÿé—´"
            elif any(keyword in text for keyword in ["å®¢å…", "living", "å…", "èµ·å±…å®¤"]):
                room_type = "å®¢å…"
            elif any(
                keyword in text for keyword in ["å§å®¤", "bedroom", "ä¸»å§", "æ¬¡å§"]
            ):
                room_type = "å§å®¤"
            elif any(keyword in text for keyword in ["é˜³å°", "balcony", "é˜³å…®", "é˜³åˆ", "é˜³å›Š"]):
                room_type = "é˜³å°"
            elif any(
                keyword in text
                for keyword in ["ä¹¦æˆ¿", "study", "ä¹¦", "åŠå…¬å®¤", "office"]
            ):
                room_type = "ä¹¦æˆ¿"

            if room_type and room_type in room_info:
                # ä½¿ç”¨OCRæ–‡å­—çš„ä¸­å¿ƒä½ç½®
                x, y, w, h = item["bbox"]

                # è®¡ç®—OCRæ–‡å­—ä¸­å¿ƒï¼ˆåœ¨OCRå¤„ç†çš„å›¾åƒåæ ‡ç³»ä¸­ï¼‰
                ocr_center_x = x + w // 2
                ocr_center_y = y + h // 2

                # OCRå›¾åƒæ˜¯æ”¾å¤§2å€çš„ï¼Œéœ€è¦å…ˆè½¬æ¢åˆ°åŸå§‹å›¾åƒåæ ‡
                orig_center_x = int(ocr_center_x / 2)
                orig_center_y = int(ocr_center_y / 2)

                # ä¼˜å…ˆä½¿ç”¨åˆ†å‰²æ©ç ç¡®å®šæ•´é—´æˆ¿çš„è¾¹ç•Œ
                min_x = max_x = min_y = max_y = None
                label = room_label_mapping.get(room_type)
                if label is not None:
                    mask = enhanced_resized == label
                    mask_h, mask_w = mask.shape
                    mask_x = int(orig_center_x * mask_w / original_width)
                    mask_y = int(orig_center_y * mask_h / original_height)
                    seed_x, seed_y, seed_found = mask_x, mask_y, False

                    if 0 <= mask_x < mask_w and 0 <= mask_y < mask_h:
                        if mask[mask_y, mask_x]:
                            seed_found = True
                        else:
                            # åœ¨é™„è¿‘å¯»æ‰¾æœ€è¿‘çš„åŒæ ‡ç­¾åƒç´ ï¼ˆ7x7é‚»åŸŸï¼‰
                            search_radius = 3
                            min_dist = None
                            for dy in range(-search_radius, search_radius + 1):
                                for dx in range(-search_radius, search_radius + 1):
                                    nx, ny = mask_x + dx, mask_y + dy
                                    if 0 <= nx < mask_w and 0 <= ny < mask_h and mask[ny, nx]:
                                        dist = dx * dx + dy * dy
                                        if min_dist is None or dist < min_dist:
                                            min_dist = dist
                                            seed_x, seed_y = nx, ny
                                            seed_found = True

                    if seed_found:
                        labeled_mask = mask.astype(np.uint8)
                        num_labels, labels_img = cv2.connectedComponents(labeled_mask)
                        region_label = labels_img[seed_y, seed_x]
                        if region_label != 0:
                            region = labels_img == region_label
                            y_coords, x_coords = np.where(region)
                            min_x_512, max_x_512 = x_coords.min(), x_coords.max()
                            min_y_512, max_y_512 = y_coords.min(), y_coords.max()
                            scale_x = original_width / float(mask_w)
                            scale_y = original_height / float(mask_h)
                            min_x = int(min_x_512 * scale_x)
                            max_x = int(max_x_512 * scale_x)
                            min_y = int(min_y_512 * scale_y)
                            max_y = int(max_y_512 * scale_y)

                if min_x is None:
                    # æœªæ‰¾åˆ°è¿é€šåŸŸï¼Œå›é€€åˆ°åŸºäºOCRæ–‡å­—çš„æœ€å°è¾¹ç•Œ
                    orig_w = int(w / 2)  # OCRå®½åº¦è½¬æ¢åˆ°åŸå§‹å›¾åƒ
                    orig_h = int(h / 2)  # OCRé«˜åº¦è½¬æ¢åˆ°åŸå§‹å›¾åƒ
                    half_width = max(20, orig_w // 2)
                    half_height = max(15, orig_h // 2)
                    min_x = max(0, orig_center_x - half_width)
                    max_x = min(original_width - 1, orig_center_x + half_width)
                    min_y = max(0, orig_center_y - half_height)
                    max_y = min(original_height - 1, orig_center_y + half_height)

                width = max_x - min_x + 1
                height = max_y - min_y + 1

                room_info[room_type].append({
                    'center': (orig_center_x, orig_center_y),
                    'bbox': (min_x, min_y, max_x, max_y),
                    'pixels': width * height,  # åŸºäºè¾¹ç•Œæ¡†çš„é¢ç§¯
                    'width': width,
                    'height': height,
                    'text': text,
                    'confidence': item.get('confidence', 0.0),
                })
        # å¯¹äºæ²¡æœ‰OCRæ£€æµ‹åˆ°çš„æˆ¿é—´ï¼Œå°è¯•ä»åˆ†å‰²ç»“æœä¸­æå–
        label_mapping = {v: k for k, v in room_label_mapping.items()}

        for label, room_type in label_mapping.items():
            if len(room_info[room_type]) == 0:  # OCRæ²¡æœ‰æ£€æµ‹åˆ°
                mask = enhanced_resized == label
                pixels = np.sum(mask)

                if pixels > 0:
                    # æ‰¾åˆ°æˆ¿é—´åŒºåŸŸçš„åæ ‡
                    coords = np.where(mask)
                    y_coords, x_coords = coords

                    # è®¡ç®—è¾¹ç•Œæ¡†
                    min_x_512, max_x_512 = np.min(x_coords), np.max(x_coords)
                    min_y_512, max_y_512 = np.min(y_coords), np.max(y_coords)

                    # è®¡ç®—ä¸­å¿ƒç‚¹
                    center_x_512 = int(np.mean(x_coords))
                    center_y_512 = int(np.mean(y_coords))

                    # è½¬æ¢åˆ°åŸå§‹å›¾åƒå°ºå¯¸
                    scale_x = original_width / 512.0
                    scale_y = original_height / 512.0

                    center_x = int(center_x_512 * scale_x)
                    center_y = int(center_y_512 * scale_y)
                    min_x = int(min_x_512 * scale_x)
                    max_x = int(max_x_512 * scale_x)
                    min_y = int(min_y_512 * scale_y)
                    max_y = int(max_y_512 * scale_y)

                    width = max_x - min_x + 1
                    height = max_y - min_y + 1

                    room_info[room_type].append(
                        {
                            "center": (center_x, center_y),
                            "bbox": (min_x, min_y, max_x, max_y),
                            "pixels": pixels,
                            "width": width,
                            "height": height,
                            "text": "åˆ†å‰²æ£€æµ‹",
                            "confidence": 0.5,
                        }
                    )

        # åˆå¹¶ç›¸è¿‘çš„åŒç±»å‹æˆ¿é—´ï¼ˆå¦‚ä¸­è‹±æ–‡æ ‡è¯†çš„åŒä¸€æˆ¿é—´ï¼‰
        room_info = self._merge_nearby_rooms(room_info, original_size)
        
        return room_info
        
    def _merge_nearby_rooms(self, room_info, original_size):
        """åˆå¹¶è·ç¦»å¾ˆè¿‘çš„åŒç±»å‹æˆ¿é—´"""
        print("ğŸ”„ æ£€æŸ¥å¹¶åˆå¹¶ç›¸è¿‘çš„åŒç±»å‹æˆ¿é—´...")
        
        # å®šä¹‰åˆå¹¶è·ç¦»é˜ˆå€¼ï¼ˆåƒç´ ï¼‰
        merge_threshold = 50  # ä¸­å¿ƒç‚¹è·ç¦»å°äº50åƒç´ çš„è®¤ä¸ºæ˜¯åŒä¸€æˆ¿é—´
        
        merged_room_info = {}
        
        for room_type, room_list in room_info.items():
            if len(room_list) <= 1:
                # åªæœ‰0æˆ–1ä¸ªæˆ¿é—´ï¼Œæ— éœ€åˆå¹¶
                merged_room_info[room_type] = room_list
                continue
                
            # å¯¹æœ‰å¤šä¸ªæˆ¿é—´çš„ç±»å‹è¿›è¡Œåˆå¹¶æ£€æŸ¥
            merged_list = []
            processed = set()
            
            for i, room1 in enumerate(room_list):
                if i in processed:
                    continue
                    
                # å¯»æ‰¾ä¸å½“å‰æˆ¿é—´è·ç¦»å¾ˆè¿‘çš„å…¶ä»–æˆ¿é—´
                to_merge = [room1]
                processed.add(i)
                
                for j, room2 in enumerate(room_list[i+1:], i+1):
                    if j in processed:
                        continue
                        
                    # è®¡ç®—ä¸¤æˆ¿é—´ä¸­å¿ƒç‚¹è·ç¦»
                    x1, y1 = room1['center']
                    x2, y2 = room2['center']
                    distance = ((x2-x1)**2 + (y2-y1)**2)**0.5
                    
                    if distance < merge_threshold:
                        to_merge.append(room2)
                        processed.add(j)
                        print(f"   ğŸ”— {room_type}åˆå¹¶ï¼š'{room1['text']}'({x1},{y1}) + '{room2['text']}'({x2},{y2}) è·ç¦»{distance:.1f}åƒç´ ")
                
                if len(to_merge) > 1:
                    # éœ€è¦åˆå¹¶å¤šä¸ªæˆ¿é—´
                    merged_room = self._merge_room_group(to_merge)
                    merged_list.append(merged_room)
                    print(f"   âœ… {room_type}åˆå¹¶å®Œæˆï¼š{len(to_merge)}ä¸ªåŒºåŸŸ -> 1ä¸ªåŒºåŸŸ")
                else:
                    # å•ä¸ªæˆ¿é—´ï¼Œç›´æ¥æ·»åŠ 
                    merged_list.append(room1)
            
            merged_room_info[room_type] = merged_list
            
            # è¾“å‡ºåˆå¹¶ç»“æœ
            if len(room_list) != len(merged_list):
                print(f"   ğŸ“Š {room_type}ï¼š{len(room_list)}ä¸ª -> {len(merged_list)}ä¸ª")
        
        return merged_room_info
    
    def _merge_room_group(self, room_group):
        """å°†å¤šä¸ªæˆ¿é—´åˆå¹¶ä¸ºä¸€ä¸ª"""
        # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„æˆ¿é—´ä½œä¸ºåŸºå‡†
        best_room = max(room_group, key=lambda r: r['confidence'])
        
        # è®¡ç®—åˆå¹¶åçš„ä¸­å¿ƒç‚¹ï¼ˆåŠ æƒå¹³å‡ï¼Œç½®ä¿¡åº¦ä½œä¸ºæƒé‡ï¼‰
        total_weight = sum(r['confidence'] for r in room_group)
        if total_weight > 0:
            weighted_x = sum(r['center'][0] * r['confidence'] for r in room_group) / total_weight
            weighted_y = sum(r['center'][1] * r['confidence'] for r in room_group) / total_weight
            merged_center = (int(weighted_x), int(weighted_y))
        else:
            # å¦‚æœæƒé‡ä¸º0ï¼Œä½¿ç”¨ç®€å•å¹³å‡
            avg_x = sum(r['center'][0] for r in room_group) / len(room_group)
            avg_y = sum(r['center'][1] for r in room_group) / len(room_group)
            merged_center = (int(avg_x), int(avg_y))
        
        # è®¡ç®—åˆå¹¶åçš„è¾¹ç•Œæ¡†ï¼ˆåŒ…å«æ‰€æœ‰æˆ¿é—´çš„è¾¹ç•Œï¼‰
        all_bbox = [r['bbox'] for r in room_group]
        min_x = min(bbox[0] for bbox in all_bbox)
        min_y = min(bbox[1] for bbox in all_bbox)
        max_x = max(bbox[2] for bbox in all_bbox)
        max_y = max(bbox[3] for bbox in all_bbox)
        
        merged_width = max_x - min_x + 1
        merged_height = max_y - min_y + 1
        
        # åˆå¹¶æ–‡æœ¬æè¿°
        texts = [r['text'] for r in room_group]
        merged_text = ' + '.join(texts)
        
        # ä½¿ç”¨æœ€é«˜ç½®ä¿¡åº¦
        max_confidence = max(r['confidence'] for r in room_group)
        
        return {
            'center': merged_center,
            'bbox': (min_x, min_y, max_x, max_y),
            'pixels': merged_width * merged_height,
            'width': merged_width,
            'height': merged_height,
            'text': merged_text,
            'confidence': max_confidence,
        }

        return room_info

    def _print_room_coordinates(self, room_info, original_size):
        """æ‰“å°æˆ¿é—´åæ ‡è¯¦ç»†ä¿¡æ¯ï¼Œæ”¯æŒå¤šä¸ªåŒç±»å‹æˆ¿é—´"""
        print("\n" + "=" * 60)
        print("ğŸ“ æˆ¿é—´åæ ‡è¯¦ç»†ä¿¡æ¯")
        print("=" * 60)
        print(f"ğŸ“ å›¾åƒå°ºå¯¸: {original_size[0]} x {original_size[1]} (å®½ x é«˜)")
        print("-" * 60)

        total_rooms = 0
        for room_type, room_list in room_info.items():
            if len(room_list) > 0:
                for i, info in enumerate(room_list):
                    if info["pixels"] > 0:
                        center_x, center_y = info["center"]
                        min_x, min_y, max_x, max_y = info["bbox"]

                        # å¦‚æœæœ‰å¤šä¸ªåŒç±»å‹æˆ¿é—´ï¼Œæ˜¾ç¤ºç¼–å·
                        if len(room_list) > 1:
                            display_name = f"{room_type}{i+1}"
                        else:
                            display_name = room_type

                        print(f"ğŸ  {display_name}:")
                        print(f"   ğŸ“ ä¸­å¿ƒåæ ‡: ({center_x}, {center_y})")
                        print(
                            f"   ğŸ“ è¾¹ç•Œæ¡†: å·¦ä¸Š({min_x}, {min_y}) -> å³ä¸‹({max_x}, {max_y})"
                        )
                        print(f"   ğŸ“ å°ºå¯¸: {info['width']} x {info['height']} åƒç´ ")
                        print(f"   ğŸ“Š é¢ç§¯: {info['pixels']} åƒç´ ")
                        print(
                            f"   ğŸ“„ è¯†åˆ«æ–‡æœ¬: '{info['text']}' (ç½®ä¿¡åº¦: {info['confidence']:.3f})"
                        )
                        print(f"   ğŸ”— åæ ‡èŒƒå›´: X[{min_x}-{max_x}], Y[{min_y}-{max_y}]")
                        print("-" * 60)
                        total_rooms += 1

            # å¦‚æœè¯¥ç±»å‹æˆ¿é—´æœªæ£€æµ‹åˆ°
            if len(room_list) == 0:
                print(f"âŒ {room_type}: æœªæ£€æµ‹åˆ°")
                print("-" * 60)

        print("ğŸ’¡ åæ ‡ç³»è¯´æ˜:")
        print("   â€¢ åŸç‚¹(0,0)åœ¨å›¾åƒå·¦ä¸Šè§’")
        print("   â€¢ Xè½´å‘å³ä¸ºæ­£æ–¹å‘")
        print("   â€¢ Yè½´å‘ä¸‹ä¸ºæ­£æ–¹å‘")
        print("   â€¢ æ‰€æœ‰åæ ‡å•ä½ä¸ºåƒç´ ")
        print("=" * 60)
        print(f"\nğŸ“Š æ€»è®¡æ£€æµ‹åˆ° {total_rooms} ä¸ªæˆ¿é—´")
        print("=" * 60)

    def process(self, image_path, output_path=None):
        """å®Œæ•´å¤„ç†æµç¨‹ - ä½¿ç”¨å››å±‚æ™ºèƒ½å†³ç­–æ¶æ„"""
        try:
            # è®¾ç½®è¾“å‡ºè·¯å¾„
            if output_path is None:
                output_path = Path(image_path).stem

            # 1. åŠ è½½æ¨¡å‹
            self.load_model()

            # 2. å›¾åƒé¢„å¤„ç†
            img_array, original_size, original_img = self.preprocess_image(image_path)

            # 3-6. ä½¿ç”¨å››å±‚æ™ºèƒ½å†³ç­–æ¶æ„å¤„ç†
            enhanced, room_text_items = self.process_with_four_layer_architecture(
                img_array, original_img, original_size
            )

            # 7. ç”Ÿæˆç»“æœ
            result = self.generate_results(
                enhanced, original_img, original_size, output_path, room_text_items
            )

            # 8. æ˜¾ç¤ºæ‘˜è¦
            self._print_summary()

            return result

        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            raise

    def _print_summary(self):
        """æ‰“å°æ£€æµ‹æ‘˜è¦ - åŸºäºOCRéªŒè¯çš„çœŸå®æˆ¿é—´æ•°é‡"""
        # æˆ¿é—´æ ‡ç­¾åˆ°åç§°/å›¾æ ‡/é¢œè‰²çš„æ˜ å°„
        label_info = {
            7: ("å¨æˆ¿", "ğŸ³", "ç»¿è‰²"),
            2: ("å«ç”Ÿé—´", "ğŸš¿", "è“è‰²"),
            3: ("å®¢å…", "ğŸ ", "æ©™è‰²"),
            4: ("å§å®¤", "ğŸ›ï¸", "ç´«è‰²"),
            6: ("é˜³å°", "ğŸŒ", "é’è‰²"),
            8: ("ä¹¦æˆ¿", "ğŸ“š", "æ£•è‰²"),
        }

        # åŸºäºå®é™…æ£€æµ‹åˆ°çš„æˆ¿é—´åæ ‡ä¿¡æ¯ç»Ÿè®¡ï¼ˆé¿å…AIåˆ†å‰²è¯¯è¯†åˆ«ï¼‰
        if hasattr(self, 'last_room_info'):
            room_counts = {}
            for label, (name, _, _) in label_info.items():
                # ç»Ÿè®¡å®é™…éªŒè¯è¿‡çš„æˆ¿é—´æ•°é‡ï¼Œè€Œä¸æ˜¯AIåˆ†å‰²çš„è¿é€šåŸŸæ•°é‡
                room_type_map = {7: "å¨æˆ¿", 2: "å«ç”Ÿé—´", 3: "å®¢å…", 4: "å§å®¤", 6: "é˜³å°", 8: "ä¹¦æˆ¿"}
                room_type = room_type_map.get(label, "")
                if room_type and room_type in self.last_room_info:
                    # åªç»Ÿè®¡æœ‰æ•ˆæ£€æµ‹çš„æˆ¿é—´ï¼ˆåƒç´ >0çš„æˆ¿é—´ï¼‰
                    valid_rooms = [r for r in self.last_room_info[room_type] if r.get('pixels', 0) > 0]
                    room_counts[label] = len(valid_rooms)
                else:
                    room_counts[label] = 0
        else:
            # å›é€€åˆ°åŸæ¥çš„è¿é€šåŸŸç»Ÿè®¡æ–¹æ³•ï¼ˆä½†æ·»åŠ è­¦å‘Šï¼‰
            print("âš ï¸ è­¦å‘Šï¼šä½¿ç”¨AIåˆ†å‰²ç»“æœç»Ÿè®¡ï¼Œå¯èƒ½åŒ…å«è¯¯è¯†åˆ«")
            room_counts = {}
            for label, (name, _, _) in label_info.items():
                mask = self.last_enhanced == label
                pixel_count = np.count_nonzero(mask)
                if pixel_count > 0:
                    num, _ = cv2.connectedComponents(mask.astype(np.uint8))
                    count = num - 1  # å»é™¤èƒŒæ™¯
                else:
                    count = 0
                room_counts[label] = count

        total_rooms = sum(room_counts.values())
        summary_parts = [
            f"{room_counts[label]}ä¸ª{name}"
            for label, (name, _, _) in label_info.items()
        ]
        print(f"\nğŸ  æ£€æµ‹æ‘˜è¦ï¼ˆåŸºäºOCRéªŒè¯ï¼‰: {' + '.join(summary_parts)} = {total_rooms}ä¸ªæˆ¿é—´")

        # è¾“å‡ºå­˜åœ¨çš„æˆ¿é—´ç±»å‹åŠå…¶é¢œè‰²è¯´æ˜
        for label, (name, emoji, color) in label_info.items():
            if room_counts[label] > 0:
                print(f"{emoji} {name}æ£€æµ‹: {color}æ ‡è®°")
                
        # å¦‚æœå‘ç°AIåˆ†å‰²ä¸OCRéªŒè¯ç»“æœä¸ä¸€è‡´ï¼Œæä¾›é¢å¤–è¯´æ˜
        ai_room_counts = {}
        for label, (name, _, _) in label_info.items():
            mask = self.last_enhanced == label
            pixel_count = np.count_nonzero(mask)
            if pixel_count > 0:
                num, _ = cv2.connectedComponents(mask.astype(np.uint8))
                ai_count = num - 1
            else:
                ai_count = 0
            ai_room_counts[label] = ai_count
            
        # æ£€æŸ¥æ˜¯å¦æœ‰å·®å¼‚å¹¶æé†’
        for label, (name, _, _) in label_info.items():
            if ai_room_counts[label] != room_counts[label]:
                print(f"âš ï¸ æ³¨æ„ï¼š{name}çš„AIåˆ†å‰²æ£€æµ‹åˆ°{ai_room_counts[label]}ä¸ªåŒºåŸŸï¼Œä½†OCRéªŒè¯åç¡®è®¤ä¸º{room_counts[label]}ä¸ª")
                if ai_room_counts[label] > room_counts[label]:
                    print(f"   ğŸ’¡ å¯èƒ½å­˜åœ¨AIè¯¯è¯†åˆ«ï¼Œå»ºè®®æŸ¥çœ‹å›¾åƒä¸­æ˜¯å¦æœ‰{name}çš„é”™è¯¯è“è‰²æ ‡è®°")

    def __del__(self):
        """æ¸…ç†èµ„æº"""
        if hasattr(self, 'ai_engine') and hasattr(self.ai_engine, 'session') and self.ai_engine.session:
            self.ai_engine.session.close()

    def open_image_with_system_viewer(image_path):
        """ä½¿ç”¨ç³»ç»Ÿé»˜è®¤å›¾ç‰‡æŸ¥çœ‹å™¨æ‰“å¼€å›¾ç‰‡"""
        try:
            system = platform.system()
            if system == "Windows":
                os.startfile(image_path)
            elif system == "Darwin":  # macOS
                subprocess.run(["open", image_path])
            elif system == "Linux":
                subprocess.run(["xdg-open", image_path])
            else:
                print(f"âš ï¸ ä¸æ”¯æŒçš„æ“ä½œç³»ç»Ÿ: {system}ï¼Œæ— æ³•è‡ªåŠ¨æ‰“å¼€å›¾ç‰‡")
                return False
            
            print(f"ğŸ–¼ï¸ å·²ä½¿ç”¨ç³»ç»Ÿé»˜è®¤æŸ¥çœ‹å™¨æ‰“å¼€: {image_path}")
            return True
        except Exception as e:
            print(f"âŒ æ‰“å¼€å›¾ç‰‡å¤±è´¥: {e}")
            print(f"ğŸ“‚ è¯·æ‰‹åŠ¨æŸ¥çœ‹ç»“æœ: {image_path}")
            return False


def open_image_with_photos_app(image_path):
    """ä½¿ç”¨Windowsç…§ç‰‡åº”ç”¨æ‰“å¼€å›¾ç‰‡"""
    try:
        system = platform.system()
        if system == "Windows":
            # è·å–ç»å¯¹è·¯å¾„
            abs_path = os.path.abspath(image_path)
            print(f"ğŸ” å°è¯•æ‰“å¼€æ–‡ä»¶: {abs_path}")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(abs_path):
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {abs_path}")
                return False
            
            # æ–¹æ³•1: ä½¿ç”¨os.startfile (Windowsæ¨èæ–¹å¼)
            try:
                os.startfile(abs_path)
                print(f"ğŸ“¸ å·²ä½¿ç”¨ç³»ç»Ÿé»˜è®¤æŸ¥çœ‹å™¨ï¼ˆé€šå¸¸æ˜¯ç…§ç‰‡åº”ç”¨ï¼‰æ‰“å¼€: {os.path.basename(image_path)}")
                return True
            except Exception as e:
                print(f"âš ï¸ os.startfileå¤±è´¥: {e}")
                
                # æ–¹æ³•2: å°è¯•ä½¿ç”¨explorer
                try:
                    subprocess.run(["explorer", abs_path], check=True)
                    print(f"ğŸ“¸ å·²ä½¿ç”¨èµ„æºç®¡ç†å™¨æ‰“å¼€: {os.path.basename(image_path)}")
                    return True
                except subprocess.CalledProcessError:
                    print("âš ï¸ exploreræ–¹æ³•ä¹Ÿå¤±è´¥")
                    
                    # æ–¹æ³•3: å°è¯•PowerShell Invoke-Item
                    try:
                        subprocess.run([
                            "powershell.exe", 
                            "-Command", 
                            f"Invoke-Item '{abs_path}'"
                        ], check=True)
                        print(f"ï¿½ å·²ä½¿ç”¨PowerShellæ‰“å¼€: {os.path.basename(image_path)}")
                        return True
                    except subprocess.CalledProcessError as e:
                        print(f"âŒ PowerShellæ–¹æ³•ä¹Ÿå¤±è´¥: {e}")
                        return False
        else:
            print(f"âš ï¸ ç…§ç‰‡åº”ç”¨ä»…æ”¯æŒWindowsç³»ç»Ÿï¼Œå½“å‰ç³»ç»Ÿ: {system}")
            # å›é€€åˆ°ç³»ç»Ÿé»˜è®¤æŸ¥çœ‹å™¨
            return FloorplanProcessor.open_image_with_system_viewer(image_path)
    except Exception as e:
        print(f"âŒ æ‰“å¼€å›¾ç‰‡å¤±è´¥: {e}")
        print(f"ğŸ“‚ è¯·æ‰‹åŠ¨æŸ¥çœ‹ç»“æœ: {image_path}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="DeepFloorplan æˆ¿é—´æ£€æµ‹ - é‡æ„ç‰ˆæœ¬ (å¸¦åæ ‡è½´)"
    )
    parser.add_argument("image", help="è¾“å…¥å›¾åƒè·¯å¾„")
    parser.add_argument("--output", "-o", help="è¾“å‡ºæ–‡ä»¶åå‰ç¼€")
    parser.add_argument("--model", "-m", default="pretrained", help="æ¨¡å‹è·¯å¾„")

    args = parser.parse_args()

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not Path(args.image).exists():
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.image}")
        sys.exit(1)

    # åˆ›å»ºå¤„ç†å™¨å¹¶æ‰§è¡Œ
    processor = FloorplanProcessor(args.model)
    result = processor.process(args.image, args.output)
    
    # ç¡®å®šè¾“å‡ºæ–‡ä»¶è·¯å¾„
    output_base = args.output if args.output else Path(args.image).stem
    coordinate_result_path = f"output/{output_base}_coordinate_result.png"
    standard_result_path = f"output/{output_base}_result.png"
    
    print("\nğŸ‰ å¤„ç†å®Œæˆï¼")
    print("ğŸ“‚ è¾“å‡ºç›®å½•: output/")
    print("ğŸ–¼ï¸ ä¸»è¦ç»“æœ:")
    print(f"   ğŸ“Š å¸¦åæ ‡è½´ç»“æœ: {coordinate_result_path}")
    print(f"   ğŸ“¸ æ ‡å‡†ç»“æœ: {standard_result_path}")
    
    # è‡ªåŠ¨æ‰“å¼€ç”Ÿæˆçš„å›¾ç‰‡
    print("\nğŸ–¼ï¸ æ­£åœ¨æ‰“å¼€ç»“æœå›¾ç‰‡...")
    
    # ä¼˜å…ˆæ‰“å¼€å¸¦åæ ‡è½´çš„ç»“æœå›¾ï¼ˆæ›´è¯¦ç»†ï¼‰
    if os.path.exists(coordinate_result_path):
        if open_image_with_photos_app(coordinate_result_path):
            print("âœ… å·²ä½¿ç”¨ç…§ç‰‡åº”ç”¨æ‰“å¼€å¸¦åæ ‡è½´çš„ç»“æœå›¾")
        else:
            print("âš ï¸ æ— æ³•è‡ªåŠ¨æ‰“å¼€å›¾ç‰‡ï¼Œè¯·æ‰‹åŠ¨æŸ¥çœ‹ç»“æœæ–‡ä»¶")
    elif os.path.exists(standard_result_path):
        if open_image_with_photos_app(standard_result_path):
            print("âœ… å·²ä½¿ç”¨ç…§ç‰‡åº”ç”¨æ‰“å¼€æ ‡å‡†ç»“æœå›¾")
        else:
            print("âš ï¸ æ— æ³•è‡ªåŠ¨æ‰“å¼€å›¾ç‰‡ï¼Œè¯·æ‰‹åŠ¨æŸ¥çœ‹ç»“æœæ–‡ä»¶")
    else:
        print("âŒ æ‰¾ä¸åˆ°ç”Ÿæˆçš„ç»“æœå›¾ç‰‡æ–‡ä»¶")


if __name__ == "__main__":
    main()
