import os
import argparse
import numpy as np

# é…ç½®TensorFlowæ—¥å¿—çº§åˆ«ï¼Œå®Œå…¨é™éŸ³å†—é•¿è¾“å‡º
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # åªæ˜¾ç¤ºé”™è¯¯
import warnings
warnings.filterwarnings('ignore')

import tensorflow.compat.v1 as tf
import matplotlib.pyplot as plt
import matplotlib
import cv2
from scipy import ndimage

tf.logging.set_verbosity(tf.logging.ERROR)  # å‡å°‘TensorFlowæ—¥å¿—

# Configure Chinese font support for matplotlib
matplotlib.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False

# Disable TF 2.x behavior for compatibility
tf.disable_v2_behavior()

from PIL import Image
import numpy as np

# OCR utilities
from utils.ocr_enhanced import extract_room_text, fuse_ocr_and_segmentation, set_closet_enabled
from utils.rgb_ind_convertor import floorplan_fuse_map, floorplan_fuse_map_figure

def imread(path, mode='RGB'):
    """Read image using PIL"""
    img = Image.open(path)
    if mode == 'RGB':
        img = img.convert('RGB')
    elif mode == 'L':
        img = img.convert('L')
    return np.array(img)

def imsave(path, img):
    """Save image using PIL"""
    if img.dtype != np.uint8:
        img = (img * 255).astype(np.uint8)
    Image.fromarray(img).save(path)

def imresize(img, size):
    """Resize image using PIL"""
    # Convert to uint8 if needed
    if img.dtype != np.uint8:
        if img.max() <= 1.0:
            img = (img * 255).astype(np.uint8)
        else:
            img = img.astype(np.uint8)
    
    if len(img.shape) == 3:
        h, w, c = size if len(size) == 3 else (*size, img.shape[2])
        img_pil = Image.fromarray(img)
        img_resized = img_pil.resize((w, h))
        return np.array(img_resized)
    else:
        h, w = size
        img_pil = Image.fromarray(img)
        img_resized = img_pil.resize((w, h))
        return np.array(img_resized)
from matplotlib import pyplot as plt
import matplotlib
# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False  # æ­£ç¡®æ˜¾ç¤ºè´Ÿå·

# Force CPU usage - disable GPU 
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # Disable GPU

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# input image path
parser = argparse.ArgumentParser()

parser.add_argument('image_path', nargs='?', default='./demo/demo.jpg',
                    help='input image path')
parser.add_argument('--im_path', type=str, default=None,
                    help='input image path (alternative to positional argument)')
parser.add_argument('--enable_closet', action='store_true',
                    help='enable closet predictions (disabled by default)')
parser.add_argument('--disable_closet', action='store_true',
                    help='map closet predictions to background (deprecated, use --enable_closet instead)')


def simple_connected_components(mask):
    """Simple connected component labeling without scipy"""
    h, w = mask.shape
    labels = np.zeros_like(mask, dtype=int)
    current_label = 0
    
    def flood_fill(start_y, start_x, label):
        """Flood fill algorithm for connected components"""
        stack = [(start_y, start_x)]
        while stack:
            y, x = stack.pop()
            if (y < 0 or y >= h or x < 0 or x >= w or 
                labels[y, x] != 0 or not mask[y, x]):
                continue
            
            labels[y, x] = label
            # Add 4-connected neighbors
            stack.extend([(y+1, x), (y-1, x), (y, x+1), (y, x-1)])
    
    for y in range(h):
        for x in range(w):
            if mask[y, x] and labels[y, x] == 0:
                current_label += 1
                flood_fill(y, x, current_label)
    
    return labels, current_label

def apply_precise_kitchen_coordinates(floorplan, ocr_results, ori_shape):
    """ç²¾ç¡®åˆ†æOCRè¯†åˆ«çš„å¨æˆ¿æ–‡å­—ä½ç½®ï¼Œè¯¦ç»†è¾“å‡ºåæ ‡è½¬æ¢è¿‡ç¨‹"""
    if not ocr_results:
        return floorplan, []
    
    # æŸ¥æ‰¾å¨æˆ¿OCRç»“æœ
    kitchen_boxes = []
    for ocr_item in ocr_results:
        text = ocr_item['text'].lower()
        if any(keyword in text for keyword in ['å¨æˆ¿', 'kitchen', 'cook', 'çƒ¹é¥ª']):
            x, y, w, h = ocr_item['bbox']
            
            print(f"ğŸ” OCRå¨æˆ¿è¯†åˆ«è¯¦ç»†åˆ†æ:")
            print(f"   æ£€æµ‹åˆ°æ–‡å­—: '{ocr_item['text']}'")
            print(f"   ç½®ä¿¡åº¦: {ocr_item['confidence']:.3f}")
            print(f"   ğŸ¯ OCRåŸå§‹æ•°æ®åˆ†æ:")
            print(f"      è¾¹ç•Œæ¡†(x,y,w,h): ({x}, {y}, {w}, {h})")
            print(f"      æ–‡å­—åŒºåŸŸ: å·¦ä¸Šè§’({x}, {y}) -> å³ä¸‹è§’({x+w}, {y+h})")
            
            # è®¡ç®—OCRæ£€æµ‹åˆ°çš„"å¨æˆ¿"æ–‡å­—çš„ç²¾ç¡®ä¸­å¿ƒ
            ocr_center_x = x + w // 2
            ocr_center_y = y + h // 2
            
            print(f"   ğŸ“ OCRæ–‡å­—ä¸­å¿ƒè®¡ç®—:")
            print(f"      ä¸­å¿ƒX = {x} + {w}//2 = {ocr_center_x}")
            print(f"      ä¸­å¿ƒY = {y} + {h}//2 = {ocr_center_y}")
            print(f"      OCRæ–‡å­—ä¸­å¿ƒ: ({ocr_center_x}, {ocr_center_y}) [512x512åæ ‡ç³»]")
            
            # è½¬æ¢ä¸ºåŸå§‹å›¾åƒåæ ‡
            orig_center_x = int(ocr_center_x * ori_shape[1] / 512)
            orig_center_y = int(ocr_center_y * ori_shape[0] / 512)
            
            print(f"   ğŸ”„ åæ ‡ç³»è½¬æ¢:")
            print(f"      åŸå§‹å›¾åƒå°ºå¯¸: {ori_shape[1]} x {ori_shape[0]}")
            print(f"      512x512 -> åŸå§‹å›¾åƒè½¬æ¢æ¯”ä¾‹:")
            print(f"        Xæ¯”ä¾‹: 512 -> {ori_shape[1]} (Ã—{ori_shape[1]/512:.3f})")
            print(f"        Yæ¯”ä¾‹: 512 -> {ori_shape[0]} (Ã—{ori_shape[0]/512:.3f})")
            print(f"      è½¬æ¢ååŸå§‹å›¾åƒåæ ‡: ({orig_center_x}, {orig_center_y})")
            
            # åœ¨OCRæ£€æµ‹åˆ°çš„å¨æˆ¿æ–‡å­—ä½ç½®æ ‡è®°å¨æˆ¿
            radius = 20
            kitchen_pixels = 0
            for dy in range(-radius, radius+1):
                for dx in range(-radius, radius+1):
                    new_y = ocr_center_y + dy
                    new_x = ocr_center_x + dx
                    if (0 <= new_y < 512 and 0 <= new_x < 512 and 
                        dx*dx + dy*dy <= radius*radius):
                        floorplan[new_y, new_x] = 7  # å¨æˆ¿æ ‡ç­¾
                        kitchen_pixels += 1
            
            print(f"   âœ… åœ¨OCRæ–‡å­—ä¸­å¿ƒä½ç½®æ ‡è®°äº†{kitchen_pixels}ä¸ªåƒç´ ä¸ºå¨æˆ¿")
            print(f"   ğŸ“Š å¨æˆ¿æ–‡å­—è¯†åˆ«ç»“æœ:")
            print(f"      512x512åæ ‡: ({ocr_center_x}, {ocr_center_y})")
            print(f"      åŸå§‹å›¾åƒåæ ‡: ({orig_center_x}, {orig_center_y})")
            print(f"      è¿™å°±æ˜¯OCRç²¾ç¡®è¯†åˆ«çš„'å¨æˆ¿'ä¸¤å­—çš„ä¸­å¿ƒä½ç½®")
            
            kitchen_boxes.append({
                'center': (ocr_center_x, ocr_center_y),
                'original_center': (orig_center_x, orig_center_y),
                'bbox': (x, y, w, h),
                'text': ocr_item['text'],
                'confidence': ocr_item['confidence']
            })
    
    return floorplan, kitchen_boxes


def expand_kitchen_region_from_center(floorplan, center_x, center_y, original_shape, target_size=None):
    """ä»å¨æˆ¿ä¸­å¿ƒç‚¹å‘å››å‘¨æ‰©å±•ï¼Œå½¢æˆè§„åˆ™çš„çŸ©å½¢å¨æˆ¿åŒºåŸŸ"""
    print(f"ğŸ  æ™ºèƒ½å¨æˆ¿åŒºåŸŸæ‰©å±•: ä¸­å¿ƒ({center_x}, {center_y})")
    
    h, w = original_shape[:2]
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šç›®æ ‡å¤§å°ï¼Œæ ¹æ®å›¾åƒå¤§å°ä¼°ç®—åˆç†çš„å¨æˆ¿å¤§å°
    if target_size is None:
        # å¨æˆ¿é€šå¸¸å æ€»é¢ç§¯çš„8-15%
        total_area = h * w
        target_area = total_area * 0.12  # 12%çš„é¢ç§¯
        target_size = int(np.sqrt(target_area))
    
    # ç¡®ä¿å¨æˆ¿å¤§å°åˆç†ï¼ˆä¸èƒ½å¤ªå°ä¹Ÿä¸èƒ½å¤ªå¤§ï¼‰
    min_size = min(h, w) // 8  # æœ€å°å°ºå¯¸
    max_size = min(h, w) // 3  # æœ€å¤§å°ºå¯¸
    target_size = max(min_size, min(target_size, max_size))
    
    print(f"   ğŸ¯ ç›®æ ‡å¨æˆ¿å°ºå¯¸: {target_size}x{target_size} åƒç´ ")
    
    # åˆ›å»ºå¨æˆ¿æ©ç 
    kitchen_mask = np.zeros((h, w), dtype=bool)
    
    # è®¡ç®—çŸ©å½¢è¾¹ç•Œï¼ˆä»¥ä¸­å¿ƒç‚¹ä¸ºä¸­å¿ƒçš„æ­£æ–¹å½¢ï¼‰
    half_size = target_size // 2
    
    # ç¡®ä¿è¾¹ç•Œåœ¨å›¾åƒèŒƒå›´å†…
    left = max(0, center_x - half_size)
    right = min(w, center_x + half_size)
    top = max(0, center_y - half_size)
    bottom = min(h, center_y + half_size)
    
    # è°ƒæ•´è¾¹ç•Œï¼Œå°½é‡ä¿æŒæ­£æ–¹å½¢
    width = right - left
    height = bottom - top
    
    if width < height:
        # å®½åº¦ä¸å¤Ÿï¼Œå°è¯•æ‰©å±•å·¦å³
        needed = height - width
        if left > needed // 2:
            left = max(0, left - needed // 2)
        if right < w - needed // 2:
            right = min(w, right + needed // 2)
    elif height < width:
        # é«˜åº¦ä¸å¤Ÿï¼Œå°è¯•æ‰©å±•ä¸Šä¸‹
        needed = width - height
        if top > needed // 2:
            top = max(0, top - needed // 2)
        if bottom < h - needed // 2:
            bottom = min(h, bottom + needed // 2)
    
    # æ ‡è®°å¨æˆ¿åŒºåŸŸ
    kitchen_mask[top:bottom, left:right] = True
    
    # æ£€æŸ¥æ˜¯å¦ä¸å¢™å£å†²çªï¼Œå¦‚æœæ˜¯åˆ™æ”¶ç¼©åŒºåŸŸ
    conflict_pixels = 0
    for y in range(top, bottom):
        for x in range(left, right):
            if floorplan[y, x] in [9, 10]:  # å¢™å£
                kitchen_mask[y, x] = False
                conflict_pixels += 1
    
    # å¦‚æœå†²çªå¤ªå¤šï¼Œæ”¶ç¼©åŒºåŸŸ
    if conflict_pixels > (bottom - top) * (right - left) * 0.3:  # è¶…è¿‡30%å†²çª
        print(f"   âš ï¸ å¢™å£å†²çªè¿‡å¤š({conflict_pixels}åƒç´ )ï¼Œæ”¶ç¼©å¨æˆ¿åŒºåŸŸ")
        # æ”¶ç¼©åˆ°æ›´å°çš„åŒºåŸŸ
        new_half = target_size // 3
        left = max(0, center_x - new_half)
        right = min(w, center_x + new_half)
        top = max(0, center_y - new_half)
        bottom = min(h, center_y + new_half)
        
        kitchen_mask.fill(False)
        kitchen_mask[top:bottom, left:right] = True
        
        # å†æ¬¡æ£€æŸ¥å¢™å£å†²çª
        for y in range(top, bottom):
            for x in range(left, right):
                if floorplan[y, x] in [9, 10]:
                    kitchen_mask[y, x] = False
    
    expanded_pixels = np.sum(kitchen_mask)
    final_width = right - left
    final_height = bottom - top
    
    print(f"   âœ… å¨æˆ¿åŒºåŸŸç”Ÿæˆå®Œæˆ:")
    print(f"      åŒºåŸŸå¤§å°: {final_width}x{final_height} åƒç´ ")
    print(f"      æœ‰æ•ˆé¢ç§¯: {expanded_pixels} åƒç´ ")
    print(f"      åŒºåŸŸä½ç½®: ({left},{top}) åˆ° ({right},{bottom})")
    
    return kitchen_mask


def enhance_kitchen_detection(floorplan, ocr_results):
    """æ™ºèƒ½å¨æˆ¿æ£€æµ‹ï¼šä¼˜å…ˆä½¿ç”¨OCRï¼Œç¡®ä¿åªè¯†åˆ«ä¸€ä¸ªå¨æˆ¿ï¼Œå½¢æˆè§„åˆ™çš„çŸ©å½¢åŒºåŸŸ"""
    enhanced = floorplan.copy()
    h, w = enhanced.shape
    
    # é¦–å…ˆæ£€æŸ¥OCRæ˜¯å¦æ£€æµ‹åˆ°å¨æˆ¿
    kitchen_ocr_items = []
    if ocr_results:
        for ocr_item in ocr_results:
            text = ocr_item['text'].lower()
            if any(keyword in text for keyword in ['å¨æˆ¿', 'kitchen', 'cook', 'çƒ¹é¥ª']):
                kitchen_ocr_items.append(ocr_item)
                print(f"ğŸ³ OCRæ£€æµ‹åˆ°å¨æˆ¿æ–‡å­—: '{ocr_item['text']}' (ç½®ä¿¡åº¦: {ocr_item['confidence']:.3f})")
    
    # å¦‚æœOCRæ£€æµ‹åˆ°å¨æˆ¿ï¼Œä¼˜å…ˆä½¿ç”¨OCRç»“æœ
    if kitchen_ocr_items:
        print("âœ… ä½¿ç”¨OCRæ£€æµ‹çš„å¨æˆ¿ä½ç½®")
        
        # å¦‚æœæœ‰å¤šä¸ªå¨æˆ¿OCRç»“æœï¼Œé€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„
        best_kitchen = max(kitchen_ocr_items, key=lambda x: x['confidence'])
        x, y, w, h = best_kitchen['bbox']
        center_x = x + w // 2
        center_y = y + h // 2
        
        print(f"   ğŸ“ é€‰æ‹©æœ€å¯é çš„å¨æˆ¿: '{best_kitchen['text']}' (ç½®ä¿¡åº¦: {best_kitchen['confidence']:.3f})")
        print(f"   ğŸ¯ å¨æˆ¿ä¸­å¿ƒä½ç½®: ({center_x}, {center_y})")
        
        # ä»OCRä¸­å¿ƒç‚¹ç”Ÿæˆè§„åˆ™çš„å¨æˆ¿åŒºåŸŸ
        kitchen_mask = create_regular_kitchen_area(enhanced, center_x, center_y, h, w)
        enhanced[kitchen_mask] = 7  # å¨æˆ¿æ ‡ç­¾
        
        kitchen_pixels = np.sum(kitchen_mask)
        print(f"   âœ… ç”Ÿæˆè§„åˆ™å¨æˆ¿åŒºåŸŸ: {kitchen_pixels} åƒç´ ")
        
        return enhanced
    
    # å¦‚æœOCRæ²¡æœ‰æ£€æµ‹åˆ°å¨æˆ¿ï¼Œä½¿ç”¨ç©ºé—´åˆ†æï¼ˆé™åˆ¶åªè¯†åˆ«ä¸€ä¸ªï¼‰
    print("ğŸ“ OCRæœªæ£€æµ‹åˆ°å¨æˆ¿ï¼Œä½¿ç”¨ç©ºé—´åˆ†æï¼ˆé™åˆ¶è¯†åˆ«ä¸€ä¸ªå¨æˆ¿ï¼‰")
    
    # æŸ¥æ‰¾å®¢å…/é¤å…åŒºåŸŸ
    living_dining_mask = (enhanced == 3)
    
    if np.sum(living_dining_mask) == 0:
        print("âŒ æœªå‘ç°å®¢å…/é¤å…/å¨æˆ¿åŒºåŸŸ")
        return enhanced
    
    try:
        # è¿é€šç»„ä»¶åˆ†æ
        labeled_regions, num_regions = simple_connected_components(living_dining_mask)
        
        print(f"ğŸ” å‘ç° {num_regions} ä¸ªå®¢å…/é¤å…åŒºåŸŸ")
        
        region_stats = []
        
        for region_id in range(1, num_regions + 1):
            region_mask = (labeled_regions == region_id)
            region_area = np.sum(region_mask)
            
            # è·å–åŒºåŸŸè¾¹ç•Œ
            region_coords = np.where(region_mask)
            if len(region_coords[0]) == 0:
                continue
                
            min_y, max_y = np.min(region_coords[0]), np.max(region_coords[0])
            min_x, max_x = np.min(region_coords[1]), np.max(region_coords[1])
            region_height = max_y - min_y + 1
            region_width = max_x - min_x + 1
            
            # è®¡ç®—åŒºåŸŸç‰¹å¾
            aspect_ratio = max(region_width, region_height) / min(region_width, region_height)
            density = region_area / (region_width * region_height)
            relative_area = region_area / (h * w)
            
            region_stats.append({
                'id': region_id,
                'mask': region_mask,
                'area': region_area,
                'relative_area': relative_area,
                'aspect_ratio': aspect_ratio,
                'density': density,
                'center': ((min_x + max_x) // 2, (min_y + max_y) // 2),
                'bbox': (min_x, min_y, max_x, max_y)
            })
        
        # å¨æˆ¿é€‰æ‹©ç­–ç•¥ï¼šé€‰æ‹©åˆé€‚çš„åŒºåŸŸä½œä¸ºå¨æˆ¿
        kitchen_candidates = []
        
        for stats in region_stats:
            print(f"   åŒºåŸŸ{stats['id']}: é¢ç§¯={stats['relative_area']:.3f}, é•¿å®½æ¯”={stats['aspect_ratio']:.2f}, å¯†åº¦={stats['density']:.2f}")
            
            # æ›´ä¸¥æ ¼çš„å¨æˆ¿å€™é€‰æ¡ä»¶ï¼š
            # 1. é¢ç§¯è¦åˆé€‚ï¼ˆä¸èƒ½å¤ªå°ä¹Ÿä¸èƒ½å¤ªå¤§ï¼‰
            # 2. å½¢çŠ¶è¦ç›¸å¯¹è§„åˆ™
            # 3. å¯†åº¦è¦åˆç†
            # 4. ç»å¯¹é¢ç§¯è¦è¶³å¤Ÿå¤§
            absolute_area = stats['area']
            
            if (0.03 < stats['relative_area'] < 0.15 and  # é¢ç§¯åœ¨3%-15%ä¹‹é—´
                stats['aspect_ratio'] < 2.5 and          # ä¸å¤ªç‹­é•¿  
                stats['density'] > 0.6 and               # å¯†åº¦è¾ƒé«˜
                absolute_area > 500):                     # ç»å¯¹é¢ç§¯å¤§äº500åƒç´ 
                
                kitchen_candidates.append(stats)
                print(f"      âœ… å¨æˆ¿å€™é€‰åŒºåŸŸ (ç»å¯¹é¢ç§¯: {absolute_area})")
            else:
                reasons = []
                if stats['relative_area'] <= 0.03:
                    reasons.append("é¢ç§¯å¤ªå°")
                elif stats['relative_area'] >= 0.15:
                    reasons.append("é¢ç§¯å¤ªå¤§")
                if stats['aspect_ratio'] >= 2.5:
                    reasons.append("å½¢çŠ¶ç‹­é•¿")
                if stats['density'] <= 0.6:
                    reasons.append("å¯†åº¦ä½")
                if absolute_area <= 500:
                    reasons.append("ç»å¯¹é¢ç§¯ä¸è¶³")
                print(f"      âŒ ä¸ç¬¦åˆå¨æˆ¿ç‰¹å¾: {', '.join(reasons)}")
        
        # å¦‚æœæœ‰å€™é€‰åŒºåŸŸï¼Œé€‰æ‹©æœ€åˆé€‚çš„ä¸€ä¸ªä½œä¸ºå¨æˆ¿
        if kitchen_candidates:
            # æŒ‰é¢ç§¯å’Œå¯†åº¦çš„ç»¼åˆè¯„åˆ†æ’åº
            def kitchen_score(stats):
                # é¢ç§¯é€‚ä¸­çš„å¾—åˆ†æ›´é«˜ï¼Œå¯†åº¦é«˜çš„å¾—åˆ†æ›´é«˜
                area_score = 1.0 - abs(stats['relative_area'] - 0.08) / 0.08
                density_score = stats['density']
                shape_score = 1.0 / stats['aspect_ratio']  # è¶Šæ¥è¿‘æ­£æ–¹å½¢å¾—åˆ†è¶Šé«˜
                return area_score * 0.4 + density_score * 0.4 + shape_score * 0.2
            
            kitchen_candidates.sort(key=kitchen_score, reverse=True)
            chosen_kitchen = kitchen_candidates[0]
            
            print(f"   ğŸ¯ é€‰æ‹©åŒºåŸŸ{chosen_kitchen['id']}ä½œä¸ºå¨æˆ¿")
            print(f"      é¢ç§¯: {chosen_kitchen['relative_area']:.3f}, ç»å¯¹é¢ç§¯: {chosen_kitchen['area']}")
            print(f"      é•¿å®½æ¯”: {chosen_kitchen['aspect_ratio']:.2f}, å¯†åº¦: {chosen_kitchen['density']:.2f}")
            
            # ä»åŒºåŸŸä¸­å¿ƒç”Ÿæˆè§„åˆ™çš„å¨æˆ¿åŒºåŸŸ
            center_x, center_y = chosen_kitchen['center']
            kitchen_mask = create_regular_kitchen_area(enhanced, center_x, center_y, h, w)
            
            if np.sum(kitchen_mask) > 0:
                enhanced[kitchen_mask] = 7  # å¨æˆ¿æ ‡ç­¾
                kitchen_pixels = np.sum(kitchen_mask)
                print(f"   âœ… ç”Ÿæˆè§„åˆ™å¨æˆ¿åŒºåŸŸ: {kitchen_pixels} åƒç´ ")
            else:
                print(f"   âŒ æ— æ³•åœ¨è¯¥åŒºåŸŸç”Ÿæˆæœ‰æ•ˆçš„å¨æˆ¿")
        else:
            print("   âš ï¸ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å¨æˆ¿å€™é€‰åŒºåŸŸ")
                
    except Exception as e:
        print(f"âš ï¸ ç©ºé—´åˆ†æå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    return enhanced


def create_regular_kitchen_area(floorplan, center_x, center_y, img_h, img_w):
    """ä»ä¸­å¿ƒç‚¹åˆ›å»ºè§„åˆ™çš„çŸ©å½¢å¨æˆ¿åŒºåŸŸï¼Œä¸¥æ ¼é™åˆ¶åœ¨æˆ¿é—´è¾¹ç•Œå†…"""
    h, w = floorplan.shape
    
    print(f"      ğŸ  æ™ºèƒ½ç”Ÿæˆå¨æˆ¿åŒºåŸŸ: ä¸­å¿ƒ({center_x}, {center_y})")
    
    # é¦–å…ˆæ£€æŸ¥ä¸­å¿ƒç‚¹æ˜¯å¦åœ¨æœ‰æ•ˆåŒºåŸŸï¼ˆéå¢™å£ï¼‰
    if floorplan[center_y, center_x] in [9, 10]:
        print(f"      âš ï¸ ä¸­å¿ƒç‚¹åœ¨å¢™å£ä¸Šï¼Œå¯»æ‰¾é™„è¿‘çš„æœ‰æ•ˆåŒºåŸŸ")
        # å¯»æ‰¾é™„è¿‘çš„éå¢™å£åŒºåŸŸ
        found_valid = False
        for radius in range(1, 10):
            for dy in range(-radius, radius+1):
                for dx in range(-radius, radius+1):
                    new_y, new_x = center_y + dy, center_x + dx
                    if (0 <= new_y < h and 0 <= new_x < w and 
                        floorplan[new_y, new_x] not in [9, 10]):
                        center_x, center_y = new_x, new_y
                        found_valid = True
                        break
                if found_valid:
                    break
            if found_valid:
                break
        
        if not found_valid:
            print(f"      âŒ æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„å¨æˆ¿ä¸­å¿ƒç‚¹")
            return np.zeros((h, w), dtype=bool)
    
    print(f"      âœ… ä½¿ç”¨ä¸­å¿ƒç‚¹: ({center_x}, {center_y})")
    
    # ä½¿ç”¨æ³›æ´ªç®—æ³•æ‰¾åˆ°åŒ…å«ä¸­å¿ƒç‚¹çš„è¿é€šåŒºåŸŸ
    def flood_fill_room(start_x, start_y):
        """æ‰¾åˆ°åŒ…å«èµ·å§‹ç‚¹çš„å®Œæ•´æˆ¿é—´åŒºåŸŸ"""
        visited = np.zeros((h, w), dtype=bool)
        room_mask = np.zeros((h, w), dtype=bool)
        stack = [(start_x, start_y)]
        
        while stack:
            x, y = stack.pop()
            if (x < 0 or x >= w or y < 0 or y >= h or 
                visited[y, x] or floorplan[y, x] in [9, 10]):
                continue
            
            visited[y, x] = True
            room_mask[y, x] = True
            
            # æ·»åŠ 4è¿é€šçš„é‚»å±…
            stack.extend([(x+1, y), (x-1, y), (x, y+1), (x, y-1)])
        
        return room_mask
    
    # è·å–åŒ…å«å¨æˆ¿ä¸­å¿ƒçš„å®Œæ•´æˆ¿é—´
    room_mask = flood_fill_room(center_x, center_y)
    room_pixels = np.sum(room_mask)
    
    if room_pixels < 100:  # å¦‚æœæˆ¿é—´å¤ªå°ï¼Œä¸é€‚åˆåšå¨æˆ¿
        print(f"      âŒ æˆ¿é—´å¤ªå°({room_pixels}åƒç´ )ï¼Œä¸é€‚åˆåšå¨æˆ¿")
        return np.zeros((h, w), dtype=bool)
    
    print(f"      ğŸ“ å‘ç°æˆ¿é—´åŒºåŸŸ: {room_pixels} åƒç´ ")
    
    # è®¡ç®—æˆ¿é—´çš„è¾¹ç•Œæ¡†
    room_coords = np.where(room_mask)
    min_y, max_y = np.min(room_coords[0]), np.max(room_coords[0])
    min_x, max_x = np.min(room_coords[1]), np.max(room_coords[1])
    room_width = max_x - min_x + 1
    room_height = max_y - min_y + 1
    
    print(f"      ğŸ“ æˆ¿é—´è¾¹ç•Œ: ({min_x},{min_y}) åˆ° ({max_x},{max_y}), å°ºå¯¸{room_width}x{room_height}")
    
    # æ ¹æ®æˆ¿é—´å¤§å°ç¡®å®šå¨æˆ¿å°ºå¯¸ï¼ˆä¸èƒ½è¶…è¿‡æˆ¿é—´çš„80%ï¼‰
    max_kitchen_width = int(room_width * 0.8)
    max_kitchen_height = int(room_height * 0.8)
    
    # è®¡ç®—ç†æƒ³çš„å¨æˆ¿å°ºå¯¸
    total_area = h * w
    target_area = min(total_area * 0.06, room_pixels * 0.7)  # å¨æˆ¿æœ€å¤šå æ€»é¢ç§¯6%æˆ–æˆ¿é—´70%
    target_size = int(np.sqrt(target_area))
    
    # é™åˆ¶å¨æˆ¿å¤§å°
    min_size = 20
    target_size = max(min_size, min(target_size, min(max_kitchen_width, max_kitchen_height)))
    
    print(f"      ï¿½ ç›®æ ‡å¨æˆ¿å°ºå¯¸: {target_size}x{target_size}")
    
    # åœ¨æˆ¿é—´å†…åˆ›å»ºä»¥ä¸­å¿ƒç‚¹ä¸ºä¸­å¿ƒçš„å¨æˆ¿åŒºåŸŸ
    half_size = target_size // 2
    
    # ç¡®ä¿å¨æˆ¿åŒºåŸŸåœ¨æˆ¿é—´è¾¹ç•Œå†…
    kitchen_left = max(min_x, center_x - half_size)
    kitchen_right = min(max_x + 1, center_x + half_size)
    kitchen_top = max(min_y, center_y - half_size)
    kitchen_bottom = min(max_y + 1, center_y + half_size)
    
    # è°ƒæ•´ä¸ºæ­£æ–¹å½¢ï¼ˆåœ¨æˆ¿é—´è¾¹ç•Œå†…ï¼‰
    kitchen_width = kitchen_right - kitchen_left
    kitchen_height = kitchen_bottom - kitchen_top
    
    if kitchen_width < kitchen_height:
        # å°è¯•æ‰©å±•å®½åº¦
        needed = kitchen_height - kitchen_width
        if kitchen_left - needed//2 >= min_x:
            kitchen_left -= needed//2
        elif kitchen_right + needed//2 <= max_x + 1:
            kitchen_right += needed//2
    elif kitchen_height < kitchen_width:
        # å°è¯•æ‰©å±•é«˜åº¦
        needed = kitchen_width - kitchen_height
        if kitchen_top - needed//2 >= min_y:
            kitchen_top -= needed//2
        elif kitchen_bottom + needed//2 <= max_y + 1:
            kitchen_bottom += needed//2
    
    # åˆ›å»ºå¨æˆ¿æ©ç ï¼Œåªåœ¨æˆ¿é—´åŒºåŸŸå†…
    kitchen_mask = np.zeros((h, w), dtype=bool)
    
    for y in range(kitchen_top, kitchen_bottom):
        for x in range(kitchen_left, kitchen_right):
            if room_mask[y, x]:  # åªåœ¨æˆ¿é—´åŒºåŸŸå†…
                kitchen_mask[y, x] = True
    
    actual_width = kitchen_right - kitchen_left
    actual_height = kitchen_bottom - kitchen_top
    actual_pixels = np.sum(kitchen_mask)
    
    print(f"      âœ… å¨æˆ¿åŒºåŸŸç”Ÿæˆå®Œæˆ:")
    print(f"         è¾¹ç•Œ: ({kitchen_left},{kitchen_top}) åˆ° ({kitchen_right},{kitchen_bottom})")
    print(f"         å°ºå¯¸: {actual_width}x{actual_height}")
    print(f"         æœ‰æ•ˆåƒç´ : {actual_pixels}")
    
    return kitchen_mask

def ind2rgb(ind_im, enable_closet=True):
        # Use the appropriate color map based on closet setting
        if enable_closet:
            color_map = floorplan_fuse_map_figure
        else:
            # Create a modified map without closet
            color_map = floorplan_fuse_map_figure.copy()
            color_map[1] = color_map[3]  # Map closet to living room color
        
        rgb_im = np.zeros((ind_im.shape[0], ind_im.shape[1], 3))

        for i, rgb in color_map.items():
                rgb_im[(ind_im==i)] = rgb

        return rgb_im

def main(args):
        # Default behavior: closet is disabled unless explicitly enabled
        enable_closet = args.enable_closet
        # Support legacy --disable_closet flag for backward compatibility
        if args.disable_closet:
            enable_closet = False
        set_closet_enabled(enable_closet)

        # Handle image path - support both positional and --im_path argument
        image_path = args.im_path if args.im_path else args.image_path

        # load input
        im = imread(image_path, mode='RGB')
        # Keep original size for better OCR
        original_im = im.copy()
        
        print(f"ğŸ–¼ï¸ å›¾åƒå¤„ç†æµç¨‹è¯¦ç»†åˆ†æ:")
        print(f"   ğŸ“ åŸå§‹å›¾åƒå°ºå¯¸: {original_im.shape[1]} x {original_im.shape[0]} (å®½xé«˜)")
        
        # Resize image for network inference
        im = imresize(im, (512, 512))
        print(f"   ğŸ”„ ç¥ç»ç½‘ç»œè¾“å…¥: 512 x 512 (å›ºå®šå°ºå¯¸)")
        print(f"   ğŸ’¡ ä¸ºä»€ä¹ˆè¦è½¬æ¢åˆ°512x512ï¼Ÿ")
        print(f"      - DeepFloorplanç¥ç»ç½‘ç»œæ¨¡å‹è®­ç»ƒæ—¶ä½¿ç”¨çš„æ˜¯512x512è¾“å…¥")
        print(f"      - æ‰€æœ‰çš„ç¥ç»ç½‘ç»œæ¨ç†éƒ½åœ¨512x512åæ ‡ç³»ä¸­è¿›è¡Œ")
        print(f"      - æœ€ç»ˆç»“æœéœ€è¦è½¬æ¢å›åŸå§‹å›¾åƒå°ºå¯¸ç”¨äºæ˜¾ç¤º")
        
        # For OCR, use larger, enhanced image
        from PIL import Image, ImageEnhance
        ocr_img = Image.fromarray(original_im)
        # Enlarge for better OCR
        ocr_img = ocr_img.resize((ocr_img.width * 2, ocr_img.height * 2), Image.LANCZOS)
        print(f"   ğŸ” OCRå¤„ç†å›¾åƒ: {ocr_img.width} x {ocr_img.height} (æ”¾å¤§2å€)")
        print(f"   ğŸ’¡ ä¸ºä»€ä¹ˆOCRè¦æ”¾å¤§2å€ï¼Ÿ")
        print(f"      - æé«˜OCRè¯†åˆ«å°æ–‡å­—çš„å‡†ç¡®æ€§")
        print(f"      - å¢å¼ºæ–‡å­—çš„æ¸…æ™°åº¦å’Œå¯¹æ¯”åº¦")
        
        # Enhance contrast
        enhancer = ImageEnhance.Contrast(ocr_img)
        ocr_img = enhancer.enhance(2.5)
        # Enhance sharpness
        enhancer = ImageEnhance.Sharpness(ocr_img)
        ocr_img = enhancer.enhance(2.0)
        ocr_im = np.array(ocr_img)
        
        print(f"   ğŸ“Š åæ ‡è½¬æ¢å…³ç³»:")
        print(f"      åŸå§‹å›¾åƒ -> 512x512: ç¼©æ”¾æ¯”ä¾‹ X={512/original_im.shape[1]:.3f}, Y={512/original_im.shape[0]:.3f}")
        print(f"      512x512 -> åŸå§‹å›¾åƒ: ç¼©æ”¾æ¯”ä¾‹ X={original_im.shape[1]/512:.3f}, Y={original_im.shape[0]/512:.3f}")
        print(f"      âš ï¸ å…³é”®: Xæ¯”ä¾‹={original_im.shape[1]/512:.3f} å°±æ˜¯æ‚¨çœ‹åˆ°çš„1.131!")
        print(f"      ğŸ“ è®¡ç®—: {original_im.shape[1]} Ã· 512 = {original_im.shape[1]/512:.3f}")
        
        # Extract textual room labels using OCR with enhanced image
        ocr_results = extract_room_text(ocr_im)
        # Scale OCR bounding boxes to match segmentation size (512x512)
        if ocr_results:
                scale_x = im.shape[1] / ocr_im.shape[1]
                scale_y = im.shape[0] / ocr_im.shape[0]
                print(f"   ğŸ”„ OCRåæ ‡è½¬æ¢åˆ°512x512:")
                print(f"      OCRå›¾åƒ({ocr_im.shape[1]}x{ocr_im.shape[0]}) -> 512x512")
                print(f"      è½¬æ¢æ¯”ä¾‹: X={scale_x:.3f}, Y={scale_y:.3f}")
                for item in ocr_results:
                        x, y, w, h = item['bbox']
                        x = int(x * scale_x)
                        y = int(y * scale_y)
                        w = int(w * scale_x)
                        h = int(h * scale_y)
                        item['bbox'] = (x, y, w, h)
        
        # Convert to float and normalize for network inference
        im = im.astype(np.float32) / 255.

        # æ£€æµ‹GPUå¯ç”¨æ€§å¹¶é…ç½®TensorFlow
        gpu_available = len(tf.config.experimental.list_physical_devices('GPU')) > 0 if hasattr(tf.config, 'experimental') else False
        if not gpu_available:
            try:
                # TF 1.xçš„GPUæ£€æµ‹æ–¹æ³•
                from tensorflow.python.client import device_lib
                local_devices = device_lib.list_local_devices()
                gpu_available = any(device.device_type == 'GPU' for device in local_devices)
            except:
                gpu_available = False
        
        print(f"ğŸ’» è®¾å¤‡çŠ¶æ€: {'GPUå¯ç”¨' if gpu_available else 'CPUæ¨¡å¼'}")
        
        # Create tensorflow session with optimized configuration
        config = tf.ConfigProto(
                allow_soft_placement=True,
                log_device_placement=False
        )
        # Enable GPU memory growth to avoid allocation issues
        if gpu_available:
            config.gpu_options.allow_growth = True
            print("ğŸš€ ä½¿ç”¨GPUåŠ é€Ÿ")
        else:
            # Disable GPU if not available
            print("ğŸ”§ ä½¿ç”¨CPUè®¡ç®—")
            
        with tf.Session(config=config) as sess:
                
                # initialize
                sess.run(tf.group(tf.global_variables_initializer(),
                                        tf.local_variables_initializer()))

                # restore pretrained model
                saver = tf.train.import_meta_graph('./pretrained/pretrained_r3d.meta')
                saver.restore(sess, './pretrained/pretrained_r3d')

                # get default graph
                graph = tf.get_default_graph()

                # restore inputs & outpus tensor
                x = graph.get_tensor_by_name('inputs:0')
                room_type_logit = graph.get_tensor_by_name('Cast:0')
                room_boundary_logit = graph.get_tensor_by_name('Cast_1:0')

                # infer results
                [room_type, room_boundary] = sess.run([room_type_logit, room_boundary_logit],\
                                                                feed_dict={x:im.reshape(1,512,512,3)})
                room_type, room_boundary = np.squeeze(room_type), np.squeeze(room_boundary)

                # merge results
                floorplan = room_type.copy()
                floorplan[room_boundary==1] = 9
                floorplan[room_boundary==2] = 10
                
                # Use OCR labels to refine room categories
                floorplan = fuse_ocr_and_segmentation(floorplan, ocr_results)
                
                # æ™ºèƒ½å¨æˆ¿æ£€æµ‹ - åªè¯†åˆ«ä¸€ä¸ªå¨æˆ¿ï¼Œå½¢æˆè§„åˆ™åŒºåŸŸ
                floorplan = enhance_kitchen_detection(floorplan, ocr_results)
                
                # è·å–å¨æˆ¿ä½ç½®ç”¨äºå¯è§†åŒ–æ ‡è®°
                kitchen_boxes = []
                if ocr_results:
                    for ocr_item in ocr_results:
                        text = ocr_item['text'].lower()
                        if any(keyword in text for keyword in ['å¨æˆ¿', 'kitchen', 'cook', 'çƒ¹é¥ª']):
                            x, y, w, h = ocr_item['bbox']
                            ocr_center_x = x + w // 2
                            ocr_center_y = y + h // 2
                            orig_center_x = int(ocr_center_x * original_im.shape[1] / 512)
                            orig_center_y = int(ocr_center_y * original_im.shape[0] / 512)
                            
                            kitchen_boxes.append({
                                'center': (ocr_center_x, ocr_center_y),
                                'original_center': (orig_center_x, orig_center_y),
                                'bbox': (x, y, w, h),
                                'text': ocr_item['text'],
                                'confidence': ocr_item['confidence']
                            })
                            # åªè¦ç¬¬ä¸€ä¸ªå¨æˆ¿
                            break
                
                # Handle closet disable
                if not enable_closet:
                        floorplan[floorplan==1] = 0
                floorplan_rgb = ind2rgb(floorplan, enable_closet)
                
                # ğŸ¯ æ·»åŠ å¨æˆ¿ä½ç½®çš„çº¢è‰²æ ‡è®°å’Œåæ ‡ç½‘æ ¼
                if kitchen_boxes:
                    # è½¬æ¢ä¸ºåŸå§‹å›¾åƒå°ºå¯¸
                    original_h, original_w = original_im.shape[:2]
                    floorplan_original_size = cv2.resize(floorplan_rgb, (original_w, original_h), interpolation=cv2.INTER_NEAREST)
                    
                    # æ·»åŠ æ›´æ˜æ˜¾çš„åæ ‡ç½‘æ ¼ (æ¯25åƒç´ ä¸€æ¡ç»†çº¿ï¼Œæ¯100åƒç´ ä¸€æ¡ç²—çº¿)
                    for x in range(0, original_w, 25):
                        thickness = 2 if x % 100 == 0 else 1
                        color = (0, 0, 255) if x % 100 == 0 else (128, 128, 128)  # çº¢è‰²ä¸»çº¿ï¼Œç°è‰²ç»†çº¿
                        cv2.line(floorplan_original_size, (x, 0), (x, original_h), color, thickness)
                    for y in range(0, original_h, 25):
                        thickness = 2 if y % 100 == 0 else 1
                        color = (0, 0, 255) if y % 100 == 0 else (128, 128, 128)  # çº¢è‰²ä¸»çº¿ï¼Œç°è‰²ç»†çº¿
                        cv2.line(floorplan_original_size, (0, y), (original_w, y), color, thickness)
                    
                    # æ·»åŠ åæ ‡æ ‡æ³¨ (æ¯50åƒç´ )
                    for x in range(0, original_w, 50):
                        cv2.putText(floorplan_original_size, str(x), (x+2, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
                    for y in range(0, original_h, 50):
                        cv2.putText(floorplan_original_size, str(y), (5, y+20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
                    
                    # æ ‡è®°OCRè¯†åˆ«çš„å¨æˆ¿æ–‡å­—ä¸­å¿ƒä½ç½®
                    for kitchen_info in kitchen_boxes:
                        # OCRè¯†åˆ«çš„å¨æˆ¿æ–‡å­—ä¸­å¿ƒä½ç½®ï¼ˆç»¿è‰² - è¿™å°±æ˜¯"å¨æˆ¿"ä¸¤å­—çš„ç²¾ç¡®ä¸­å¿ƒï¼‰
                        ocr_x, ocr_y = kitchen_info['original_center']
                        cv2.rectangle(floorplan_original_size, 
                                    (ocr_x-30, ocr_y-30), 
                                    (ocr_x+30, ocr_y+30), 
                                    (0, 255, 0), 4)
                        cv2.circle(floorplan_original_size, (ocr_x, ocr_y), 8, (0, 255, 0), -1)
                        
                        # OCRä½ç½®æ ‡æ³¨
                        ocr_text = f"OCRå¨æˆ¿æ–‡å­—ä¸­å¿ƒ({ocr_x},{ocr_y})"
                        cv2.putText(floorplan_original_size, ocr_text, 
                                  (ocr_x+35, ocr_y-20), 
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                        
                        # æ·»åŠ ç™½è‰²èƒŒæ™¯
                        text_size = cv2.getTextSize(ocr_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]
                        cv2.rectangle(floorplan_original_size,
                                    (ocr_x+33, ocr_y-35),
                                    (ocr_x+37+text_size[0], ocr_y-15),
                                    (255, 255, 255), -1)
                        cv2.putText(floorplan_original_size, ocr_text, 
                                  (ocr_x+35, ocr_y-20), 
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                        
                        print(f"ğŸ¯ OCRè¯†åˆ«çš„å¨æˆ¿æ–‡å­—ä¸­å¿ƒ: ç»¿è‰²æ¡†({ocr_x}, {ocr_y})")
                        print(f"ï¿½ è¿™æ˜¯'å¨æˆ¿'ä¸¤ä¸ªå­—çš„ç²¾ç¡®ä¸­å¿ƒä½ç½®")
                        
                        # æ·»åŠ å›¾ä¾‹è¯´æ˜
                        legend_y = 30
                        cv2.putText(floorplan_original_size, "ç»¿è‰²=OCRè¯†åˆ«å¨æˆ¿æ–‡å­—ä¸­å¿ƒ", 
                                  (10, legend_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                        cv2.putText(floorplan_original_size, "è¿™æ˜¯'å¨æˆ¿'ä¸¤å­—çš„ç²¾ç¡®ä½ç½®", 
                                  (10, legend_y + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                    
                    # ä¿å­˜å¸¦æ ‡è®°çš„ç»“æœ
                    marked_filename = image_path.replace('.jpg', '_marked.png').replace('.png', '_marked.png')
                    imsave(marked_filename, floorplan_original_size)
                    print(f"âœ… å¸¦å¨æˆ¿æ ‡è®°çš„ç»“æœå·²ä¿å­˜: {marked_filename}")
                else:
                    # æ²¡æœ‰å¨æˆ¿æ—¶ï¼Œä¹Ÿæ·»åŠ åæ ‡ç½‘æ ¼ä¾¿äºåˆ†æ
                    original_h, original_w = original_im.shape[:2]
                    floorplan_original_size = cv2.resize(floorplan_rgb, (original_w, original_h), interpolation=cv2.INTER_NEAREST)
                    
                    # æ·»åŠ åæ ‡ç½‘æ ¼
                    for x in range(0, original_w, 25):
                        thickness = 2 if x % 100 == 0 else 1
                        color = (0, 0, 255) if x % 100 == 0 else (128, 128, 128)
                        cv2.line(floorplan_original_size, (x, 0), (x, original_h), color, thickness)
                    for y in range(0, original_h, 25):
                        thickness = 2 if y % 100 == 0 else 1
                        color = (0, 0, 255) if y % 100 == 0 else (128, 128, 128)
                        cv2.line(floorplan_original_size, (0, y), (original_w, y), color, thickness)
                    
                    # æ·»åŠ åæ ‡æ ‡æ³¨
                    for x in range(0, original_w, 50):
                        cv2.putText(floorplan_original_size, str(x), (x+2, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
                    for y in range(0, original_h, 50):
                        cv2.putText(floorplan_original_size, str(y), (5, y+20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

                # plot results with coordinate axes
                plt.figure(figsize=(18, 8))
                plt.subplot(131)
                plt.imshow(im)
                plt.title('åŸå§‹å›¾ç‰‡')
                plt.axis('on')  # æ˜¾ç¤ºåæ ‡è½´
                plt.grid(True, alpha=0.3)
                
                plt.subplot(132)
                plt.imshow(floorplan_rgb/255.)
                plt.title('æˆ·å‹åˆ†æç»“æœ (ç»¿è‰²=å¨æˆ¿)')
                plt.axis('on')  # æ˜¾ç¤ºåæ ‡è½´
                plt.grid(True, alpha=0.3)
                
                # ç¬¬ä¸‰ä¸ªå­å›¾ï¼šæ˜¾ç¤ºå¸¦æ ‡è®°çš„ç»“æœ
                if kitchen_boxes:
                    plt.subplot(133)
                    plt.imshow(floorplan_original_size)
                    plt.title('å¨æˆ¿æ ‡è®°ç»“æœ (çº¢è‰²=å¨æˆ¿ä½ç½®)')
                    plt.axis('on')  # æ˜¾ç¤ºåæ ‡è½´
                    plt.grid(True, alpha=0.3)
                    
                    # åœ¨å›¾ä¸Šæ ‡æ³¨å¨æˆ¿åæ ‡
                    for kitchen_info in kitchen_boxes:
                        orig_x, orig_y = kitchen_info['original_center']
                        plt.plot(orig_x, orig_y, 'ro', markersize=8, label=f"å¨æˆ¿({orig_x},{orig_y})")
                        plt.annotate(f"{kitchen_info['text']}\n({orig_x},{orig_y})", 
                                   (orig_x, orig_y), 
                                   xytext=(10, -10), 
                                   textcoords='offset points',
                                   bbox=dict(boxstyle='round,pad=0.3', facecolor='red', alpha=0.7),
                                   fontsize=10, color='white')
                    plt.legend()
                
                # Save result
                output_name = os.path.basename(image_path).split('.')[0] + '_result.png'
                plt.savefig(output_name, dpi=300, bbox_inches='tight')
                print(f"ğŸ“¸ ç»“æœå·²ä¿å­˜: {output_name}")
                
                plt.show()

if __name__ == '__main__':
        FLAGS, unparsed = parser.parse_known_args()
        main(FLAGS)
